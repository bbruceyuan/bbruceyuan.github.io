import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as r,b as t,e as a,d as l,w as i,a as p,r as s,o as m}from"./app-Q4Ay_VEF.js";const c={};function d(h,e){const n=s("RouteLink");return m(),r("div",null,[e[3]||(e[3]=t("h2",{id:"更新",tabindex:"-1"},[t("a",{class:"header-anchor",href:"#更新"},[t("span",null,"更新")])],-1)),e[4]||(e[4]=t("ul",null,[t("li",null,"2024 年 05 月 19 日 00:13:48"),t("li",null,"从大模型视角完全没有必要做分词了，从学习角度可以再考虑看该文章。")],-1)),e[5]||(e[5]=t("h2",{id:"背景",tabindex:"-1"},[t("a",{class:"header-anchor",href:"#背景"},[t("span",null,"背景")])],-1)),t("p",null,[e[1]||(e[1]=a('20年3月6号本人写了一篇文章，"')),l(n,{to:"/post/1.html"},{default:i(()=>e[0]||(e[0]=[a("2020年了，分词算法真的没用了吗？")])),_:1}),e[2]||(e[2]=a('"，起了这么一个标题是因为我个人看到很多的学术界的模型都不在进行底层的分词，且有很多新入门的同学真的就认为分词一点必要都没有了。昨天虽然举了一个例子，但是确实是我的想象，因为我也没有在百度阿里实习，所以不知道他们真正是怎么做的。'))]),e[6]||(e[6]=p('<p>因此在上一篇文章中，主要是介绍最简单的分词模型，也就是最大匹配算法，那么在深度学习时代，这样的简单算法还能用的上吗？答案是显然能用的上的，因为在去年<a href="https://www.datafountain.cn/competitions/361/ranking?isRedance=0&amp;sch=1433&amp;stage=B" target="_blank" rel="noopener noreferrer">2019年CCF-BDCI新实体发现赛道</a>，我们就用上了昨天提到的最大匹配算法，并且我们团队获得了第一名的好成绩，在这里首先感谢一下带我飞的队友，鞠躬！</p><p>那么接下来，我讲从为什么，我们要用这个算法开始讲起？</p><h2 id="深度学习不能只会调参" tabindex="-1"><a class="header-anchor" href="#深度学习不能只会调参"><span>深度学习不能只会调参</span></a></h2><p>本人作为一名初级调参仔，在实验室的搬砖流程一般是：在老师布置了任务之后，将Github中的开源代码跑一跑，调一调参数，然后结果还行就任务结束了。但是这样的算法工程师真的有竞争力吗？</p><p>那么要怎么做才算是竞争力呢？我也不知道，但是我知道至少要有以下两个能力？</p><ul><li>代码能力要过关。只有代码能力过关才能快速实现自己的想法，才有验证的机会。</li><li>要根据问题对数据有足够的分析。对数据的理解能决定模型效果的上限。再次以上面的BDCI比赛为例，我们能够超过第二名两个点的原因就是在于，我们通过对数据的分析，设计更合理的模型。</li><li>分析错误的能力？</li></ul><p>第三点我认为是很多人忽视的一点。因为初入门的人好像认为只要模型足够复杂，足够新，足够大，那么就能解决问题，但是在真实场景下，你写的模型很有可能不work，那么这个时候你要怎么办？这个问题大家先停下来思考几分钟。</p><h2 id="错例分析" tabindex="-1"><a class="header-anchor" href="#错例分析"><span>错例分析</span></a></h2><p>针对上面提出的问题，错例分析是一个非常有用的手段。那么我们先回到上面这个比赛的问题，简化之后就变成了一个实体识别(NER)任务。这是一个非常基础的问题，和分词很像。这个比赛大部分人用的模型都差不多(这里不具体介绍NER有那些模型)，结果差距也不是很大，想要拉开与其他队伍的差距，就要对数据进行深入的分析。其中，错误分析非常重要。</p><blockquote><p>任务：识别模型中出现的金融实体 输入：<strong>xxxxxx, 京东方科技集团昨日发表简，xxxxx</strong> 输出：<strong>京东方科技集团</strong></p></blockquote><p>怎么能发现模型有没有错，通过观察直接分错的例子很有效，但是<strong>混淆矩阵</strong>能从统计的角度错误主要集中发生在什么地方，比如实体识别，可能通过标签(BIO/BMES)混淆矩阵确定错误发生在什么地方，在比赛中我们发现模型预测错误主要发生在边界，然后通过分析具体的错误实例，我们发现模型很容易出现的问题是，多预测一两个字或者少预测一两个字。</p><h2 id="使用分词算法纠正模型错误" tabindex="-1"><a class="header-anchor" href="#使用分词算法纠正模型错误"><span>使用分词算法纠正模型错误</span></a></h2><p>针对上一个句子，假设模型预测出的实体是 “<strong>东方科技集团</strong>”，因此预测出来的结果是要了一个字的，实际上应该是 京东方科技集团，那么我们要怎么做才能补全这个实体。</p><p>这个问题是不是就变成了“后向最大匹配问题”，东方和京东方都是词表里面的词，因为很容易就通过前向匹配算法进行补齐。同理，假设模型预测出的实体是 “<strong>京东方科技集</strong>”，因此预测出来的结果少了一个字，因此可以通过前向最大匹配进行补全。</p><p>但当然你肯定会说，这东西不会过长或者过短吗？有可能会。那么我们是怎么处理这种情况的呢？设置两个字典，一个字典是常见的字典，另外一个是根据训练集样本统计的高频前后缀词。这样就可以在分词的同时判断置信度。如果前向或者后向匹配到了高频前后缀词，则把词补全，就可以得到补全后的实体。</p><p>同理，如果模型预测的比实际实体字数要多，同样也可以根据分词结果把多了字的去掉。</p><p>具体实现就可以参考上一篇文章。说说最终效果，通过词的前后缀最大匹配，在当初比赛的提交分数上，F1值能够提升0.5个百分点。提升的效果数值上不算大，但是这样已经能帮助我们稳住榜上第一的成绩。</p><h2 id="后记" tabindex="-1"><a class="header-anchor" href="#后记"><span>后记</span></a></h2><p>读者：这篇文章真的是在写分词算法的应用实例吗？</p><p>我：用到了分词算法就算。不接受反驳！（误</p>',20))])}const y=o(c,[["render",d],["__file","2.html.vue"]]),f=JSON.parse('{"path":"/post/2.html","title":"深度学习时代，分词算法的真实应用实例","lang":"zh-CN","frontmatter":{"title":"深度学习时代，分词算法的真实应用实例","id":2,"date":"2020-03-07T20:10:00.000Z","description":"分词算法，最大匹配，分词应用实例。","keywords":["分词算法","分词算法应用"],"tag":["分词","算法妙用"],"category":["算法妙用"],"image":"blog_imgs/1/1_1_head.png","permalink":"/post/2.html","head":[["meta",{"property":"og:url","content":"https://yuanchaofa.com/post/2.html"}],["meta",{"property":"og:site_name","content":"chaofa用代码打点酱油"}],["meta",{"property":"og:title","content":"深度学习时代，分词算法的真实应用实例"}],["meta",{"property":"og:description","content":"分词算法，最大匹配，分词应用实例。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-09-30T10:32:36.000Z"}],["meta",{"property":"article:tag","content":"分词"}],["meta",{"property":"article:tag","content":"算法妙用"}],["meta",{"property":"article:published_time","content":"2020-03-07T20:10:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-09-30T10:32:36.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"深度学习时代，分词算法的真实应用实例\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2020-03-07T20:10:00.000Z\\",\\"dateModified\\":\\"2024-09-30T10:32:36.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Chaofa Yuan\\",\\"url\\":\\"https://yuanchaofa.com\\"}]}"]]},"headers":[{"level":2,"title":"更新","slug":"更新","link":"#更新","children":[]},{"level":2,"title":"背景","slug":"背景","link":"#背景","children":[]},{"level":2,"title":"深度学习不能只会调参","slug":"深度学习不能只会调参","link":"#深度学习不能只会调参","children":[]},{"level":2,"title":"错例分析","slug":"错例分析","link":"#错例分析","children":[]},{"level":2,"title":"使用分词算法纠正模型错误","slug":"使用分词算法纠正模型错误","link":"#使用分词算法纠正模型错误","children":[]},{"level":2,"title":"后记","slug":"后记","link":"#后记","children":[]}],"git":{"createdTime":1662801658000,"updatedTime":1727692356000,"contributors":[{"name":"Mr.Hope","email":"mister-hope@outlook.com","commits":2},{"name":"bbruceyuan","email":"bbruceyuan@tencent.com","commits":1},{"name":"bbruceyuan","email":"bruceyuan@123@gmail.com","commits":1},{"name":"bbruceyuan","email":"chaofa.yuan@bytedance.com","commits":1},{"name":"chaofa.yuan","email":"chaofa.yuan@bytedance.com","commits":1}]},"readingTime":{"minutes":5.12,"words":1535},"filePathRelative":"post/技术/2.深度学习时代，分词算法的真实应用实例.md","localizedDate":"2020年3月7日"}');export{y as comp,f as data};
