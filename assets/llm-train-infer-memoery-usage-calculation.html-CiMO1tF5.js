import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as n,a as t,o as m}from"./app-BSIteuMx.js";const e="/blog_imgs/20241006094016066.png",l={};function p(i,a){return m(),n("div",null,a[0]||(a[0]=[t('<h2 id="阅读完本文可以收获什么" tabindex="-1"><a class="header-anchor" href="#阅读完本文可以收获什么"><span>阅读完本文可以收获什么？</span></a></h2><ol><li>训练和推理的时候，占用显存的内容到底有哪里？</li><li>xB 的模型，预估推理需要多少显存？</li><li>要全参数训练一个 xB 的模型，需要多少显存？</li><li>为什么混合精度训练可以节约显存？</li><li>使用 deepspeed 后，每个卡占用的显存是多少？</li></ol><h2 id="基础知识" tabindex="-1"><a class="header-anchor" href="#基础知识"><span>基础知识</span></a></h2><ul><li>1 Byte = 8 bits, 1 KB = 1024 Bytes, 1 MB = 1024 KB, 1 GB = 1024 MB</li><li>1 float64 = 8 Bytes = 64 bits, 这是双精度浮点数</li><li>1 float32 = 4 Bytes = 32 bits，这是单精度浮点数，也称为 fp32</li><li>1 float16 = 2 Bytes = 16 bits，这是半精度浮点数，也称为 fp16</li><li>1 bf16 = 2 Bytes = 16 bits，这是 Brain Floating Point 格式，也称为 bf16</li></ul><h2 id="显存占用" tabindex="-1"><a class="header-anchor" href="#显存占用"><span>显存占用</span></a></h2><p>强烈推荐阅读大佬的分析，本文强参考于 https://zhuanlan.zhihu.com/p/624740065</p><h3 id="推理" tabindex="-1"><a class="header-anchor" href="#推理"><span>推理</span></a></h3><p>模型推理一共有两部分内容会占用 GPU 显存，<strong>模型参数和 KV cache</strong>。</p><ul><li>其中假设模型的参数是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span>，那么推理时候占用的显存是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">2 \\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">2Φ</span></span></span></span>，这是因为现在 HuggingFace 中大部分模型的参数都保存为 BF16，如果没有特殊的必要，不会用 fp32 加载。</li><li>KV cache，假设输入序列的长度为 s ，输出序列的长度为 n ，以float16来保存KV cache，那么<strong>KV cache的峰值显存占用大小为</strong>  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mo stretchy="false">(</mo><mi>s</mi><mo>+</mo><mi>n</mi><mo stretchy="false">)</mo><mi>h</mi><mo>∗</mo><mi>l</mi><mo>∗</mo><mn>2</mn><mo>∗</mo><mn>2</mn><mo>=</mo><mn>4</mn><mi>b</mi><mi>l</mi><mi>h</mi><mo stretchy="false">(</mo><mi>s</mi><mo>+</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">b(s+n)h∗l∗2∗2=4blh(s+n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">b</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">n</span><span class="mclose">)</span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">4</span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span> 。这里第一个2 表示K/V cache，第二个2表示float16占2个bytes。</li></ul><p>粗略的预估，模型推理需要的内存为： <strong>1.2 倍的模型参数内存</strong> = <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.2</mn><mo>×</mo><mn>2</mn><mi mathvariant="normal">Φ</mi><mo>=</mo><mn>2.4</mn><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">1.2 \\times 2 \\Phi = 2.4 \\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">2Φ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">2.4Φ</span></span></span></span>，以 7B 模型为例，那么推理需要的内存大概是： 16.8 GB。 相对精确的预估：按照上面的公式进行计算</p><blockquote><p>注意⚠️：推理的时候并不需要保存激活值，看到有的博客说需要保存激活值是错的。</p></blockquote><h3 id="训练" tabindex="-1"><a class="header-anchor" href="#训练"><span>训练</span></a></h3><p>一般来说，现在都用混合精度训练，因此所有的分析都按照混合精度训练进行分析，而且按照 AdamW 优化起进行分析。训练的时候 GPU 显存占用一共包括 4 个部分：模型参数，梯度，优化器状态，激活值。 假设模型参数为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">\\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Φ</span></span></span></span>。</p><ul><li>模型参数：fp32 参数 + bf16 参数 = <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>4</mn><mo>+</mo><mn>2</mn><mo stretchy="false">)</mo><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">(4 + 2 )\\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mclose">)</span><span class="mord">Φ</span></span></span></span> = <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn><mi mathvariant="normal">Φ</mi><mtext> </mtext><mi>b</mi><mi>y</mi><mi>t</mi><mi>e</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">6\\Phi \\, bytes</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord">6Φ</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">t</span><span class="mord mathnormal">es</span></span></span></span> 。</li><li>梯度分为两种情况：是否开启 gradient accumulation <ul><li>开启梯度累积：要同时保持 fp32 和 bf16 = <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn><mi mathvariant="normal">Φ</mi><mtext> </mtext><mi>b</mi><mi>y</mi><mi>t</mi><mi>e</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">6\\Phi \\, bytes</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord">6Φ</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">t</span><span class="mord mathnormal">es</span></span></span></span></li><li>没有开启梯度累积：保持 bf16 即可，占用显存为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi mathvariant="normal">Φ</mi><mtext> </mtext><mi>b</mi><mi>y</mi><mi>t</mi><mi>e</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">2\\Phi \\, bytes</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord">2Φ</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">t</span><span class="mord mathnormal">es</span></span></span></span>，但反向传播需要变成 fp32 计算，因此峰值还是需要 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">4\\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">4Φ</span></span></span></span>。</li></ul></li><li>优化器 <ul><li>一节动量 fp32 和二阶动量 fp32，一共为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>4</mn><mo>+</mo><mn>4</mn><mo stretchy="false">)</mo><mi mathvariant="normal">Φ</mi><mo>=</mo><mn>8</mn><mi mathvariant="normal">Φ</mi><mtext> </mtext><mi>b</mi><mi>y</mi><mi>t</mi><mi>e</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">(4 + 4) \\Phi = 8\\Phi \\, bytes</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">4</span><span class="mclose">)</span><span class="mord">Φ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord">8Φ</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">t</span><span class="mord mathnormal">es</span></span></span></span></li></ul></li><li>激活值（bf16）: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>34</mn><mi>b</mi><mi>s</mi><mi>h</mi><mo>+</mo><mn>5</mn><mi>b</mi><msup><mi>s</mi><mn>2</mn></msup><mi>a</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>l</mi><mtext> </mtext><mi>b</mi><mi>y</mi><mi>t</mi><mi>e</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">(34bsh + 5bs^2a)\\ast l \\, bytes</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">34</span><span class="mord mathnormal">b</span><span class="mord mathnormal">s</span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord">5</span><span class="mord mathnormal">b</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">t</span><span class="mord mathnormal">es</span></span></span></span></li></ul><p>因此在训练中，单卡需要的内存为：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mn>20</mn><mi mathvariant="normal">Φ</mi><mo>+</mo><mo stretchy="false">(</mo><mn>34</mn><mi>b</mi><mi>s</mi><mi>h</mi><mo>+</mo><mn>5</mn><mi>b</mi><msup><mi>s</mi><mn>2</mn></msup><mi>a</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>l</mi></mrow><annotation encoding="application/x-tex"> 20 \\Phi + (34bsh + 5bs^2a)\\ast l </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord">20Φ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">34</span><span class="mord mathnormal">b</span><span class="mord mathnormal">s</span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord">5</span><span class="mord mathnormal">b</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span></span></p><h4 id="假设使用-deepspeed-训练" tabindex="-1"><a class="header-anchor" href="#假设使用-deepspeed-训练"><span>假设使用 DeepSpeed 训练</span></a></h4><p>如果使用 DeepSpeed，那么应该怎么计算每张卡需要的显存呢？</p><ul><li>ZeRO1，切分优化器 <ul><li>(一阶动量 + 二阶动量 + fp32 参数副本) / 卡数 + 梯度 + bf16 参数 + 激活值 <ul><li>需要注意：fp32 参数保存在优化器</li></ul></li></ul></li><li>ZeRO2，切分梯度 <ul><li>(一阶动量 + 二阶动量 + fp32 参数副本 + 梯度) / 卡数 + bf16 参数 + 激活值</li></ul></li><li>ZeRO3，切分模型参数 - (一阶动量 + 二阶动量 + fp32 参数副本 + 梯度 + bf16 参数） / 卡数 + 激活值</li></ul><p>具体可以看图（图是按照 Zero-offload 说的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>16</mn><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">16\\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">16Φ</span></span></span></span> 预估的，但是 ZeRO-Infinity 说需要 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>20</mn><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">20\\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">20Φ</span></span></span></span>，但是差别应该不是特别大）：</p><p><img src="'+e+'" alt="大模型训练推理时候的显存占用计算-20241006094016066.webp" loading="lazy"></p><h2 id="faq" tabindex="-1"><a class="header-anchor" href="#faq"><span>FAQ</span></a></h2><ul><li><p>疑问 1 🤔：除去 kvcache 和激活值，模型参数部分到底占用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>16</mn><mi mathvariant="normal">Φ</mi><mtext>  </mtext><mi>o</mi><mi>r</mi><mtext>  </mtext><mn>18</mn><mi mathvariant="normal">Φ</mi><mtext>  </mtext><mi>o</mi><mi>r</mi><mtext>  </mtext><mn>20</mn><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">16\\Phi \\; or \\; 18\\Phi \\; or \\; 20\\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">16Φ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">or</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">18Φ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">or</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">20Φ</span></span></span></span> 是比较有争议的并且<a href="https://github.com/huggingface/accelerate/issues/2659" target="_blank" rel="noopener noreferrer">非常让人疑惑</a>，为什么会出现这个情况？</p><ul><li>试图解答： <ol><li>英伟达论文和 deepspeed 的实现中，都是按照 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>20</mn><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">20\\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">20Φ</span></span></span></span>实现的，也就是说会同时复制一份fp32 的梯度，防止梯度精度不足问题，因此其实按照 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>20</mn><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">20 \\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">20Φ</span></span></span></span> 预估不会有太大的问题。<strong>（推荐按照这种方式预估）</strong></li><li>那为什么又有人说 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>18</mn><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">18\\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">18Φ</span></span></span></span> 呢？因为模型前向和反向的时候，梯度确实是 bf16，但是更新模型参数的时候还需要把梯度从 bf16 变换到 fp32，那么这个时候梯度在峰值的时候应该是需要 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">4\\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">4Φ</span></span></span></span>，因此整体为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>18</mn><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">18 \\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">18Φ</span></span></span></span> 。</li><li>为什么有人说是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>16</mn><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">16\\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">16Φ</span></span></span></span> 呢？很显而易见没有考虑到上面的，毕竟很多<a href="https://github.com/microsoft/DeepSpeed/issues/1137" target="_blank" rel="noopener noreferrer">图和 paper</a> 里面，都没有写需要复制一份 fp32 的梯度，但实际上是需要的，代码更有说服力，包括 <a href="https://github.com/huggingface/accelerate/blob/main/src/accelerate/commands/estimate.py#L215-L247" target="_blank" rel="noopener noreferrer">accelerate</a> 都是按照 fp32 计算的，因此哪怕没有开梯度累积，也需要 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>18</mn><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">18\\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">18Φ</span></span></span></span>。</li></ol></li></ul></li><li><p>疑问 2 🤔：既然做混合精度训练，需要同时保存参数的 bf16 和 fp32 副本，参数内存占用为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>20</mn><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">20\\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">20Φ</span></span></span></span>，为什么还说混合精度训练可以节约内存呢？</p><ul><li>试图回答：如果用单精度训练，AdamW 优化起下面，参数内存占用为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>4</mn><mo>+</mo><mn>4</mn><mo>+</mo><mn>4</mn><mo>+</mo><mn>4</mn><mo stretchy="false">)</mo><mi mathvariant="normal">Φ</mi><mo>=</mo><mn>16</mn><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">(4 + 4 + 4 + 4)\\Phi = 16 \\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">4</span><span class="mclose">)</span><span class="mord">Φ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">16Φ</span></span></span></span>，但是显存占用还有一个大头是激活值，激活值从 fp32 -&gt; bf16，这里可以节约大量内存，而且混合精度在前向反向计算的时候更快。</li></ul></li><li><p>疑问 3 🤔: bf16 和 fp16 的关系？</p><ul><li>fp16 有更高的精度，因为小数位比较多</li><li>bf16 在保持相对精度的同时(&lt; fp16)，提供了更大的数值范围</li></ul></li><li><p>疑问 4 🤔: bf16 和 fp16 有什么好处？</p><ul><li>节省带宽</li><li>节约内存</li></ul></li><li><p>疑问 5 🤔: 模型参数量和存储大小的关系?</p><ul><li>一般来说，现在说模型大小，都值得是模型的参数量。一般都是指里面有多少参数。</li><li>但是也偶尔有人指的是模型保存之后在 disk 的中大小。</li><li>这里的换算关系很简单， <ul><li>单精度模型：1B 参数模型 = 1e9 * 4 = 4GB</li><li>半精度模型：1B 参数模型 = 1e9 * 2 = 2 GB，如果是 0.5B 模型参数 = 0.5e9 * 2 = 1GB <ul><li>以 <a href="https://huggingface.co/Qwen/Qwen2-0.5B-Instruct" target="_blank" rel="noopener noreferrer">Qwen/Qwen2-0.5B-Instruct</a> 为例，保存为 bf16 = 2bytes，那么模型的大小为 998 MB ~= 1 GB</li></ul></li></ul></li></ul></li></ul><h2 id="参考" tabindex="-1"><a class="header-anchor" href="#参考"><span>参考</span></a></h2><ul><li>https://blog.eleuther.ai/transformer-math/#total-inference-memory</li><li>https://zhuanlan.zhihu.com/p/624740065</li></ul><h2 id="交个朋友🤣" tabindex="-1"><a class="header-anchor" href="#交个朋友🤣"><span>交个朋友🤣</span></a></h2><p>最后欢迎关注我，基本全网同名 <a href="https://yuanchaofa.com/" target="_blank" rel="noopener noreferrer">chaofa用代码打点酱油</a></p><ul><li>公众号： <img src="https://yuanchaofa.com/llms-zero-to-hero/chaofa-wechat-official-account.png" alt="chaofa用代码打点酱油" loading="lazy"></li><li><a href="https://space.bilibili.com/12420432" target="_blank" rel="noopener noreferrer">B站-chaofa用代码打点酱油</a></li><li><a href="https://www.youtube.com/@bbruceyuan" target="_blank" rel="noopener noreferrer">YouTube-chaofa用代码打点酱油</a></li><li><a href="https://chaofa.notion.site/11a569b3ecce49b2826d679f5e2fdb54" target="_blank" rel="noopener noreferrer">chaofa 的 notion 简介</a></li></ul>',28)]))}const o=s(l,[["render",p],["__file","llm-train-infer-memoery-usage-calculation.html.vue"]]),h=JSON.parse('{"path":"/post/llm-train-infer-memoery-usage-calculation.html","title":"LLM 大模型训练-推理显存占用分析","lang":"zh-CN","frontmatter":{"title":"LLM 大模型训练-推理显存占用分析","date":"2024-10-06T09:41:20.000Z","tag":["LLM","transformer"],"description":"根据模型的参数大小，预估模型训练和推理过程中的显存占用情况，包括参数占用显存大小、优化器占用显存大小...KV Cache 和 中间激活值的计算方式","publish":true,"permalink":"/post/llm-train-infer-memoery-usage-calculation.html","head":[["meta",{"property":"og:url","content":"https://yuanchaofa.com/post/llm-train-infer-memoery-usage-calculation.html"}],["meta",{"property":"og:site_name","content":"chaofa用代码打点酱油"}],["meta",{"property":"og:title","content":"LLM 大模型训练-推理显存占用分析"}],["meta",{"property":"og:description","content":"根据模型的参数大小，预估模型训练和推理过程中的显存占用情况，包括参数占用显存大小、优化器占用显存大小...KV Cache 和 中间激活值的计算方式"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://yuanchaofa.com/blog_imgs/20241006094016066.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2026-01-01T09:17:42.000Z"}],["meta",{"property":"article:tag","content":"LLM"}],["meta",{"property":"article:tag","content":"transformer"}],["meta",{"property":"article:published_time","content":"2024-10-06T09:41:20.000Z"}],["meta",{"property":"article:modified_time","content":"2026-01-01T09:17:42.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"LLM 大模型训练-推理显存占用分析\\",\\"image\\":[\\"https://yuanchaofa.com/blog_imgs/20241006094016066.png\\",\\"https://yuanchaofa.com/llms-zero-to-hero/chaofa-wechat-official-account.png\\"],\\"datePublished\\":\\"2024-10-06T09:41:20.000Z\\",\\"dateModified\\":\\"2026-01-01T09:17:42.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Chaofa Yuan\\",\\"url\\":\\"https://yuanchaofa.com\\"}]}"]]},"headers":[{"level":2,"title":"阅读完本文可以收获什么？","slug":"阅读完本文可以收获什么","link":"#阅读完本文可以收获什么","children":[]},{"level":2,"title":"基础知识","slug":"基础知识","link":"#基础知识","children":[]},{"level":2,"title":"显存占用","slug":"显存占用","link":"#显存占用","children":[{"level":3,"title":"推理","slug":"推理","link":"#推理","children":[]},{"level":3,"title":"训练","slug":"训练","link":"#训练","children":[{"level":4,"title":"假设使用 DeepSpeed 训练","slug":"假设使用-deepspeed-训练","link":"#假设使用-deepspeed-训练","children":[]}]}]},{"level":2,"title":"FAQ","slug":"faq","link":"#faq","children":[]},{"level":2,"title":"参考","slug":"参考","link":"#参考","children":[]},{"level":2,"title":"交个朋友🤣","slug":"交个朋友🤣","link":"#交个朋友🤣","children":[]}],"git":{"createdTime":1728183719000,"updatedTime":1767259062000,"contributors":[{"name":"bbruceyuan","email":"bruceyuan123@gmail.com","commits":1}]},"readingTime":{"minutes":5.76,"words":1729},"filePathRelative":"post/LLM/大模型训练-推理显存占用分析.md","localizedDate":"2024年10月6日"}');export{o as comp,h as data};
