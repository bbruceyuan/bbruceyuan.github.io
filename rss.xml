<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xsl" href="https://yuanchaofa.com/rss.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <atom:link href="https://yuanchaofa.com/rss.xml" rel="self" type="application/rss+xml"/>
    <title>chaofa用代码打点酱油</title>
    <link>https://yuanchaofa.com/</link>
    <description>做了一个播客叫做打点酱油，平常写 Python, 对 NLP、计算广告、大模型感兴趣，尝试做一些有意义的事情</description>
    <language>zh-CN</language>
    <pubDate>Thu, 15 Jan 2026 15:34:36 GMT</pubDate>
    <lastBuildDate>Thu, 15 Jan 2026 15:34:36 GMT</lastBuildDate>
    <generator>@vuepress/plugin-feed</generator>
    <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
    <category>hands-on-code</category>
    <category>月度总结</category>
    <category>paper-reading</category>
    <item>
      <title>DPO 算法原理与代码实现：让 LLM 对齐变得简单</title>
      <link>https://yuanchaofa.com/post/hands-on-dpo-direct-preference-optimization.html</link>
      <guid>https://yuanchaofa.com/post/hands-on-dpo-direct-preference-optimization.html</guid>
      <source url="https://yuanchaofa.com/rss.xml">DPO 算法原理与代码实现：让 LLM 对齐变得简单</source>
      <description>DPO 让 LLM 对齐训练变得像 SFT 一样简单。本文从 RLHF 痛点讲起，手撕 DPO Loss 核心代码，用 trl 跑通完整训练流程。Bonus 包含稳定性分析和数学推导，一篇搞定 DPO。本文是「动手学大模型」系列第12章 Part2 的配套博客。</description>
      <category>hands-on-code</category>
      <pubDate>Sat, 10 Jan 2026 15:07:00 GMT</pubDate>
      <content:encoded><![CDATA[<h2>0. 阅读收获 (takeaway)</h2>
<p>本文目标是搞懂 DPO（Direct Preference Optimization）算法，阅读完本文你将获得：</p>
<ul>
<li>理解 DPO 的核心思想：为什么 DPO 可以替代 RLHF 中的 PPO</li>
<li>掌握 DPO 与 RLHF 的关键区别：从 4 个模型到 2 个模型</li>
<li>手撕 DPO Loss：理解损失函数到底在算什么</li>
<li>Bonus 1：为什么 DPO 比 PPO 训练更稳定</li>
<li>Bonus 2：DPO 损失函数的完整数学推导</li>
<li>源代码位于 <a href="https://github.com/bbruceyuan/Hands-On-Large-Language-Models-CN/" target="_blank" rel="noopener noreferrer">Github -动手学习大模型-中文版-第 12.1章——动手学习 DPO</a></li>
</ul>
<blockquote>
<p>本文代码运行于：<a href="https://featurize.cn/srx/gthYt2" target="_blank" rel="noopener noreferrer">Featurize GPU 算力云平台</a>，不喜欢看文字的同学可以看 <a href="https://space.bilibili.com/12420432" target="_blank" rel="noopener noreferrer">B站视频-chaofa用代码打点酱油</a>，<a href="https://www.youtube.com/@bbruceyuan" target="_blank" rel="noopener noreferrer">YouTube-chaofa用代码打点酱油</a>，视频号：chaofa用代码打点酱油</p>
</blockquote>
<h2>1. 为什么需要 DPO？</h2>
<p>在聊 DPO 之前，我们先快速回顾一下 LLM 训练的三个阶段（参考 OpenAI InstructGPT)：</p>
<ol>
<li><strong>预训练（Pre-training）</strong>：在海量文本上训练，让模型学会"说话"</li>
<li><strong>监督微调（SFT）</strong>：用高质量的指令数据微调，让模型学会"听话"</li>
<li><strong>对齐（Alignment）</strong>：让模型的输出符合人类偏好，学会"说人话"</li>
</ol>
<p>假设读者对于前两个步骤已经有所了解，这篇文章的重点是第三步"对齐"。</p>
<h3>1.1 RLHF 的问题</h3>
<p>OpenAI 在训练 ChatGPT 的时候用的是 RLHF（Reinforcement Learning from Human Feedback），整个流程大概是这样的：</p>
<p><img src="/blog_imgs/ppo-vs-dpo.png" alt="DPO 原论文中的 RLHF vs DPO 流程对比" loading="lazy"></p>
<p>RLHF 确实有效，但问题也很明显：</p>
<ol>
<li><strong>需要 4 个模型</strong>：Actor（待训练）、Reference（冻结的 SFT 模型）、Reward Model（奖励模型）、Critic（价值函数）</li>
<li><strong>PPO 算法复杂</strong>：超参数一堆，训练不稳定，调参调到怀疑人生</li>
<li><strong>资源消耗大</strong>：4 个模型同时跑，显存吃不消</li>
</ol>
<blockquote>
<p>之前在 <a href="https://yuanchaofa.com/post/deepseek-r1-paper-reading-notes.html" target="_blank" rel="noopener noreferrer">DeepSeek-R1 论文解读</a> 里也提到过，DPO 是 RLHF 的一种替代方案，但 DeepSeek 最终还是用了 GRPO（一种改进的 PPO）。不过对于大多数场景来说，DPO 已经够用了。</p>
</blockquote>
<h3>1.2 DPO 的卖点</h3>
<p>DPO 的核心思路是：<strong>既然 RLHF 这么麻烦，能不能把强化学习的部分去掉，直接用监督学习的方式来做对齐？</strong></p>
<p>答案是可以的。DPO 的作者通过一系列数学推导（后面 Bonus 部分会讲），证明了可以把 RLHF 的优化目标转换成一个简单的损失函数，只需要 2 个模型就能搞定：</p>
<ul>
<li><strong>Actor</strong>：待训练的模型 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">\pi_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li>
<li><strong>Reference</strong>：冻结的 SFT 模型 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mrow><mi>r</mi><mi>e</mi><mi>f</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\pi_{ref}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">re</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></li>
</ul>
<p>不需要单独训练 Reward Model，也不需要 PPO 那套复杂的东西。训练过程和 SFT 差不多，非常稳定。</p>
<h2>2. DPO 的核心思想</h2>
<h3>2.1 偏好数据长什么样？</h3>
<p>DPO 需要的数据格式很简单，就是一个 prompt 配上两个回答：一个好的（chosen），一个差的（rejected）。</p>
<div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># DPO 偏好数据示例</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">{</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">    "prompt"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"介绍一下 chaofa用代码打点酱油 这个博主"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">    "chosen"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"chaofa用代码打点酱油 是一位专注于大模型技术的博主，他在 B站、YouTube 等平台分享 LLM 相关的技术内容，包括动手学大模型系列教程。他的内容特点是注重代码实现和原理讲解，帮助读者从零理解大模型的各种技术细节。"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">    "rejected"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"不知道，没听说过，说不定是个弱智。"</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">}</span></span></code></pre>
<div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>简单说就是：同一个问题，告诉模型哪个回答是好的，哪个是不好的。这种数据可以通过人工标注获得，也可以用更强的模型（比如 gemini/claude/gpt）来生成。</p>
<blockquote>
<p>TRICK: 非同源模型的数据训练的时候，可以先用 "chosen" 数据 SFT，不然可能导致 chosen 和 rejected 概率都变低。</p>
</blockquote>
<h3>2.2 DPO 想做什么？</h3>
<p>DPO 的目标其实就两个：</p>
<ol>
<li><strong>让模型更喜欢生成 chosen 回答</strong>：提高 chosen 的生成概率</li>
<li><strong>不要偏离原来的 SFT 模型太远</strong>：保持模型的基本能力，防止"忘记"之前学到的东西</li>
</ol>
<p>第二点很重要，如果只追求第一点，模型可能会为了迎合偏好数据而变得很奇怪（比如每个回答都很长、很啰嗦）。所以需要用参考模型来"拉住"它。</p>
<h3>2.3 DPO 损失函数</h3>
<p>好了，到了最核心的部分。DPO 的损失函数长这样：</p>
<p v-pre="" class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="script">L</mi><mrow><mi mathvariant="normal">D</mi><mi mathvariant="normal">P</mi><mi mathvariant="normal">O</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>π</mi><mi>θ</mi></msub><mo separator="true">;</mo><msub><mi>π</mi><mrow><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">f</mi></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><msub><mi mathvariant="double-struck">E</mi><mrow><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>w</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>l</mi></msub><mo stretchy="false">)</mo><mo>∼</mo><mi>D</mi></mrow></msub><mrow><mo fence="true">[</mo><mi>log</mi><mo>⁡</mo><mi>σ</mi><mo fence="false" stretchy="true" minsize="1.8em" maxsize="1.8em">(</mo><mi>β</mi><mi>log</mi><mo>⁡</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>w</mi></msub><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><msub><mi>π</mi><mrow><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">f</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>w</mi></msub><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>−</mo><mi>β</mi><mi>log</mi><mo>⁡</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>l</mi></msub><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><msub><mi>π</mi><mrow><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">f</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>l</mi></msub><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo fence="false" stretchy="true" minsize="1.8em" maxsize="1.8em">)</mo><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">
\mathcal{L}_{\mathrm{DPO}}(\pi_\theta; \pi_{\mathrm{ref}}) = - \mathbb{E}_{(x,y_w,y_l) \sim D} \left[ \log \sigma\Big(\beta \log \frac{\pi_\theta(y_w \mid x)}{\pi_{\mathrm{ref}}(y_w \mid x)} - \beta \log \frac{\pi_\theta(y_l \mid x)}{\pi_{\mathrm{ref}}(y_l \mid x)}\Big) \right]
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">DPO</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.07778em;">ref</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="mord">−</span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em;"><span style="top:-2.357em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span><span class="mrel mtight">∼</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">[</span></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mord"><span class="delimsizing size2">(</span></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.07778em;">ref</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.07778em;">ref</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="delimsizing size2">)</span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">]</span></span></span></span></span></span></span></p>
<p>这个公式看起来贼复杂，但逻辑其实很清晰。首先看公式里面的核心部分，是在比较两个东西：</p>
<ul>
<li><span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>w</mi></msub><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><msub><mi>π</mi><mrow><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">f</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>w</mi></msub><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\log \frac{\pi_\theta(y_w \mid x)}{\pi_{\mathrm{ref}}(y_w \mid x)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.53em;vertical-align:-0.52em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.07778em;">ref</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em;"><span style="top:-2.357em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mrel mtight">∣</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em;"><span style="top:-2.357em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mrel mtight">∣</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>：当前模型相对于参考模型，在 <strong>chosen</strong> 回答上的对数概率变化</li>
<li><span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>l</mi></msub><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><msub><mi>π</mi><mrow><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">f</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>l</mi></msub><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\log \frac{\pi_\theta(y_l \mid x)}{\pi_{\mathrm{ref}}(y_l \mid x)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.53em;vertical-align:-0.52em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.07778em;">ref</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span><span class="mrel mtight">∣</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span><span class="mrel mtight">∣</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>：当前模型相对于参考模型，在 <strong>rejected</strong> 回答上的对数概率变化</li>
</ul>
<p>我们希望前者大于后者。也就是说，模型在 chosen 上的"提升幅度"要大于在 rejected 上的"提升幅度"。</p>
<p><span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span> 是一个超参数，用来控制"偏离参考模型的惩罚力度"。<span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span> 越大，模型越不敢偏离参考模型；<span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span> 越小，模型越"激进"。一般从 0.1 开始试。</p>
<p><span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span> 就是 sigmoid 函数，把差值映射到 (0, 1) 区间，然后取 log 变成 loss。</p>
<blockquote>
<p>Q: 这个公式是怎么推导出来的？为什么这样设计就能达到我们的目标？这些问题留到 Bonus 部分再说。现在只要理解"DPO 在做什么"就够了。</p>
</blockquote>
<h2>3. 手撕 DPO Loss</h2>
<p>理解了原理之后，我们来看看代码怎么写。其实 DPO 的核心代码非常简单，比公式看起来简单多了。</p>
<h3>3.1 计算序列的 log 概率</h3>
<p>首先，我们需要一个函数来计算模型在某个序列上的 log 概率。</p>
<p>对于语言模型来说，生成一个序列的概率就是每个 token 条件概率的乘积。取 log 之后，乘积变成求和：</p>
<p v-pre="" class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>log</mi><mo>⁡</mo><mi>π</mi><mo stretchy="false">(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mi>t</mi></munder><mi>log</mi><mo>⁡</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mi>t</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>y</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">
\log \pi(y|x) = \sum_t \log P(y_t | y_{&lt;t}, x)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord">∣</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.3em;vertical-align:-1.25em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.9em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span></p>
<div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> torch</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> torch.nn.functional </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> F</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF"> compute_log_probs</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic">    logits</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">:</span><span style="--shiki-light:#986801;--shiki-dark:#ABB2BF"> torch.Tensor</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic">       # (batch, seq_len, vocab_size)</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic">    labels</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">:</span><span style="--shiki-light:#986801;--shiki-dark:#ABB2BF"> torch.Tensor</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic">       # (batch, seq_len)</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic">    mask</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">:</span><span style="--shiki-light:#986801;--shiki-dark:#ABB2BF"> torch.Tensor          </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># (batch, seq_len)，标记哪些位置需要计算</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">) -&gt; torch.Tensor:</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">    """</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">    计算序列的对数概率</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">    注意：这里只计算 response 部分的概率，prompt 部分不算</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">    """</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic">    # 获取每个位置的 log softmax</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">    log_probs </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> F.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF">log_softmax</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(logits, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">dim</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic">    # 取出对应 label 的 log 概率</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic">    # gather 操作：从 vocab_size 维度取出 labels 对应的概率</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">    per_token_log_probs </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF">gather</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">        log_probs,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">        dim</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">        index</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">labels.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF">unsqueeze</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">    ).</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF">squeeze</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic">    # 只计算 mask=1 的位置（response 部分）</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">    masked_log_probs </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> per_token_log_probs </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">*</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> mask</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic">    # 求和得到整个序列的 log 概率</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">    return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> masked_log_probs.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF">sum</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">dim</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">)</span></span></code></pre>
<div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3>3.2 DPO Loss 核心实现</h3>
<p>有了计算 log 概率的函数，DPO Loss 的实现就很直接了：</p>
<div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF"> dpo_loss</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic">    policy_chosen_logps</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">:</span><span style="--shiki-light:#986801;--shiki-dark:#ABB2BF"> torch.Tensor</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic">    # 当前模型在 chosen 上的 log 概率</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic">    policy_rejected_logps</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">:</span><span style="--shiki-light:#986801;--shiki-dark:#ABB2BF"> torch.Tensor</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic">  # 当前模型在 rejected 上的 log 概率</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic">    ref_chosen_logps</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">:</span><span style="--shiki-light:#986801;--shiki-dark:#ABB2BF"> torch.Tensor</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic">       # 参考模型在 chosen 上的 log 概率</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic">    ref_rejected_logps</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">:</span><span style="--shiki-light:#986801;--shiki-dark:#ABB2BF"> torch.Tensor</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic">     # 参考模型在 rejected 上的 log 概率</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic">    beta</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">:</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2"> float</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2"> =</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66"> 0.1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">) -&gt; torch.Tensor:</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">    """</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">    DPO Loss 的核心实现</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">    代码比公式简单多了吧？</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">    """</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic">    # 计算 log ratio：当前模型相对于参考模型的变化</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">    chosen_log_ratios </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> policy_chosen_logps </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">-</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> ref_chosen_logps</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">    rejected_log_ratios </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> policy_rejected_logps </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">-</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> ref_rejected_logps</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic">    # 核心：我们希望 chosen 的 ratio 大于 rejected 的 ratio</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">    logits </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> beta </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">*</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> (chosen_log_ratios </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">-</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> rejected_log_ratios)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic">    # 用 logsigmoid 更数值稳定（等价于 -log(sigmoid(logits))）</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">    losses </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2"> -</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">F.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF">logsigmoid</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(logits)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">    return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> losses.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF">mean</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">()</span></span></code></pre>
<div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>就这么简单。核心就三行：</p>
<ol>
<li>计算 chosen 的 log ratio</li>
<li>计算 rejected 的 log ratio</li>
<li>用 sigmoid + log 算 loss</li>
</ol>
<blockquote>
<p>完整的训练代码涉及数据处理、模型加载等，这里就不展开了。可以参考 <a href="https://github.com/huggingface/trl" target="_blank" rel="noopener noreferrer">trl 源码</a>。</p>
</blockquote>
<h2>4. 用 trl 跑一下 DPO 训练</h2>
<p>手写 DPO Loss 是为了理解原理，实际训练的话直接用 trl 就好了。trl 是 Hugging Face 出的强化学习库，DPO 训练用起来很简单。</p>
<div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> datasets </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> Dataset</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> transformers </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> AutoModelForCausalLM, AutoTokenizer</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> trl </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> DPOConfig, DPOTrainer</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># 1. 准备模型</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">model_name </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379"> "Qwen/Qwen2.5-0.5B-Instruct"</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic">  # 用小模型演示</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">model </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> AutoModelForCausalLM.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(model_name)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">tokenizer </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> AutoTokenizer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(model_name)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># 参考模型（就是 SFT 后的模型，这里直接用同一个）</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">ref_model </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> AutoModelForCausalLM.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(model_name)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># 2. 准备数据（trl 需要的格式）</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">train_data </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> Dataset.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF">from_dict</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">({</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">    "prompt"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">: [</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">        "介绍一下 chaofa用代码打点酱油 这个博主"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">        "DPO 和 RLHF 哪个更适合入门？"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">    ],</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">    "chosen"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">: [</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">        "chaofa用代码打点酱油 是一位专注于大模型技术的博主，在 B站、YouTube 分享 LLM 相关教程，内容注重代码实现和原理讲解，帮助读者从零理解大模型技术。"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">        "建议先学 DPO，原理更简单，训练也更稳定。可以看 chaofa用代码打点酱油 的动手学大模型系列，有详细的代码实现。"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">    ],</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">    "rejected"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">: [</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">        "没听说过，应该是个小透明吧。"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">        "都差不多，随便选一个。"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">    ],</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">})</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># 3. 配置训练参数</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">training_args </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF"> DPOConfig</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    output_dir</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"./dpo_output"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    beta</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">0.1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,                    </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># DPO 的温度参数</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    learning_rate</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">5e-7</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,          </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># DPO 通常用比较小的学习率</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    per_device_train_batch_size</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    num_train_epochs</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    logging_steps</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">10</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    bf16</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># 4. 创建 Trainer 并训练</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">trainer </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF"> DPOTrainer</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    model</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">model,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    ref_model</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">ref_model,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    args</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">training_args,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    train_dataset</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">train_data,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    tokenizer</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">tokenizer,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">trainer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF">train</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">()</span></span></code></pre>
<div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>关键参数说一下：</p>
<ul>
<li><code>beta</code>：前面说过，控制偏离参考模型的惩罚力度，一般从 0.1 开始试</li>
<li><code>learning_rate</code>：DPO 通常用比较小的学习率，5e-7 到 5e-6 左右</li>
</ul>
<h2>5. Bonus 1：为什么 DPO 比 PPO 训练更稳定？</h2>
<p>很多人说"DPO 比 PPO 更稳定"，但到底为什么呢？这个问题其实可以从几个角度来理解：</p>
<h3>5.1 Off-policy vs On-policy</h3>
<p>PPO 是一种 <strong>on-policy</strong> 的强化学习算法，DPO 是 <strong>off-policy</strong> 的，它直接用离线的偏好数据来训练，训练过程和 SFT 差不多。</p>
<ul>
<li>on policy 每一次样本都是采样出来的，梯度可能会随时发生变化，梯度方差大；数据分布随着模型的更新会发生变化，上一轮学好的参数可能不适用下一轮，reward 比较稀疏（SFT/DPO 是 Token 级别的监督信号)。</li>
</ul>
<h3>5.2 不需要 Reward Model 和 Critic</h3>
<p>PPO 在 RLHF 中需要：</p>
<ul>
<li>一个 Reward Model 来打分（这个模型本身就可能有问题，比如 reward hacking）</li>
<li>一个 Critic（Value Function）来估计优势函数（这个网络的训练也不简单）</li>
</ul>
<p>这些额外的模型都会引入噪声和不稳定因素。DPO 把 Reward Model 直接"吸收"到了损失函数里，不需要单独训练，少了很多可能出错的地方。</p>
<h3>5.3 超参数敏感度</h3>
<p>PPO 有很多超参数需要调：</p>
<ul>
<li>clip ratio（裁剪系数）</li>
<li>GAE lambda</li>
<li>学习率、batch size、epoch 数</li>
<li>KL 惩罚系数</li>
<li>...</li>
</ul>
<p>这些参数之间还有复杂的相互作用，调参调到怀疑人生是常有的事。DPO 的核心超参数就一个 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span>，最多再加上学习率。简单很多。</p>
<blockquote>
<p>备注：这里说的"稳定"。PPO/GRPO 调好了效果可能更好，但训练成本也更高。对于大多数场景来说，DPO 是一个性价比很高的选择。</p>
</blockquote>
<h2>6. Bonus 2：DPO 数学推导</h2>
<blockquote>
<p>这部分是给想深入理解的同学看的，跳过也不影响使用 DPO。</p>
</blockquote>
<p>DPO 的 Loss 不是凭空设计出来的，而是从 RLHF 的优化目标一步步推导出来的。</p>
<h3>6.1 RLHF 的优化目标</h3>
<p>RLHF 想要做的事情是：最大化奖励，同时不要偏离参考模型太远。用公式表示：</p>
<p v-pre="" class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munder><mrow><mi>max</mi><mo>⁡</mo></mrow><mi>π</mi></munder><mtext>  </mtext><msub><mi mathvariant="double-struck">E</mi><mrow><mi>x</mi><mo>∼</mo><mi mathvariant="script">D</mi><mo separator="true">,</mo><mtext> </mtext><mi>y</mi><mo>∼</mo><mi>π</mi><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></msub><mo fence="false" stretchy="true" minsize="1.8em" maxsize="1.8em">[</mo><mi>r</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo fence="false" stretchy="true" minsize="1.8em" maxsize="1.8em">]</mo><mo>−</mo><mi>β</mi><mtext> </mtext><msub><mi mathvariant="double-struck">D</mi><mrow><mi mathvariant="normal">K</mi><mi mathvariant="normal">L</mi></mrow></msub><mo fence="false" stretchy="true" minsize="1.8em" maxsize="1.8em">[</mo><mi>π</mi><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo><mtext> </mtext><mi mathvariant="normal">∥</mi><mtext> </mtext><msub><mi>π</mi><mrow><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">f</mi></mrow></msub><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo><mo fence="false" stretchy="true" minsize="1.8em" maxsize="1.8em">]</mo></mrow><annotation encoding="application/x-tex">
\max_{\pi} \; \mathbb{E}_{x \sim \mathcal{D},\, y \sim \pi(y \mid x)} \Big[ r(x,y) \Big] - \beta\, \mathbb{D}_{\mathrm{KL}}\Big[ \pi(y \mid x) \,\|\, \pi_{\mathrm{ref}}(y \mid x) \Big]
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.85em;vertical-align:-0.7em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.4306em;"><span style="top:-2.4em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">π</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mrel mtight">∼</span><span class="mord mathcal mtight" style="margin-right:0.02778em;">D</span><span class="mpunct mtight">,</span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mrel mtight">∼</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">π</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mrel mtight">∣</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span><span class="mord"><span class="delimsizing size2">[</span></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mord"><span class="delimsizing size2">]</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathbb">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">KL</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="delimsizing size2">[</span></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">∥</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.07778em;">ref</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mord"><span class="delimsizing size2">]</span></span></span></span></span></span></p>
<p>其中：</p>
<ul>
<li><span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">r(x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span> 是奖励函数（需要单独训练一个 Reward Model）</li>
<li>KL 散度用来约束模型不要偏离参考模型太远</li>
<li><span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span> 控制约束的强度</li>
</ul>
<h3>6.2 最优策略的形式</h3>
<p>这个优化问题有一个解析解。<strong>我们先假设存在这样一个最优策略</strong> <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>π</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">\pi^*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span>，（具体推导可以参考 DPO 原论文附录，但我没看懂直接抄过来了），可以得到最优策略满足：</p>
<p v-pre="" class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>π</mi><mo>∗</mo></msup><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mi>Z</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><msub><mi>π</mi><mrow><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">f</mi></mrow></msub><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo><mi>exp</mi><mo>⁡</mo><mo fence="false" stretchy="true" minsize="1.8em" maxsize="1.8em">(</mo><mfrac><mn>1</mn><mi>β</mi></mfrac><mi>r</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo fence="false" stretchy="true" minsize="1.8em" maxsize="1.8em">)</mo></mrow><annotation encoding="application/x-tex">
\pi^*(y \mid x) = \frac{1}{Z(x)} \pi_{\mathrm{ref}}(y \mid x) \exp\Big(\frac{1}{\beta} r(x,y)\Big)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2574em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.07778em;">ref</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2019em;vertical-align:-0.8804em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">exp</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mord"><span class="delimsizing size2">)</span></span></span></span></span></span></p>
<p>其中 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mo>∑</mo><mi>y</mi></msub><msub><mi>π</mi><mrow><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">f</mi></mrow></msub><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo><mi>exp</mi><mo>⁡</mo><mo fence="false" stretchy="true" minsize="1.8em" maxsize="1.8em">(</mo><mfrac><mn>1</mn><mi>β</mi></mfrac><mi>r</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo fence="false" stretchy="true" minsize="1.8em" maxsize="1.8em">)</mo></mrow><annotation encoding="application/x-tex">Z(x) = \sum_y \pi_{\mathrm{ref}}(y \mid x) \exp\Big(\frac{1}{\beta} r(x,y)\Big)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1858em;vertical-align:-0.4358em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.0017em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.07778em;">ref</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">exp</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05278em;">β</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4811em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mord"><span class="delimsizing size2">)</span></span></span></span></span> 是归一化常数（配分函数），保证概率和为 1。</p>
<blockquote>
<p>备注：</p>
<ul>
<li>它说的是：最优策略在参考策略的基础上，根据奖励大小进行"加权"。奖励高的回答概率会指数级增大，奖励低的会被抑制。<span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span> 控制这个"加权"的激进程度。</li>
<li>这个最优策略就是我们要学习的「模型参数」</li>
</ul>
</blockquote>
<h3>6.3 反解奖励函数</h3>
<p>从上面的式子，我们可以反过来把奖励函数用策略来表示：</p>
<p v-pre="" class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>r</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mi>β</mi><mi>log</mi><mo>⁡</mo><mfrac><mrow><msup><mi>π</mi><mo>∗</mo></msup><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><msub><mi>π</mi><mrow><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">f</mi></mrow></msub><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>+</mo><mi>β</mi><mi>log</mi><mo>⁡</mo><mi>Z</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">
r(x,y) = \beta \log \frac{\pi^*(y \mid x)}{\pi_{\mathrm{ref}}(y \mid x)} + \beta \log Z(x)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.07778em;">ref</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span></p>
<p>这告诉我们：<strong>奖励函数可以用"当前策略和参考策略的 log 概率比"来表示</strong>。</p>
<h3>6.4 Bradley-Terry 偏好模型</h3>
<p>在有偏好数据的时候，我们通常用 Bradley-Terry 模型来建模"哪个回答更好"：</p>
<p v-pre="" class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mi>w</mi></msub><mo>≻</mo><msub><mi>y</mi><mi>l</mi></msub><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">[</mo><mi>r</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>w</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">[</mo><mi>r</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>w</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>+</mo><mi>exp</mi><mo>⁡</mo><mo stretchy="false">[</mo><mi>r</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>l</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow></mfrac><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>w</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>r</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>l</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">
P(y_w \succ y_l \mid x) = \frac{\exp[r(x, y_w)]}{\exp[r(x, y_w)] + \exp[r(x, y_l)]} = \sigma(r(x, y_w) - r(x, y_l))
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≻</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">exp</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)]</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop">exp</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)]</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">exp</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)]</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">))</span></span></span></span></span></p>
<p><span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>w</mi></msub></mrow><annotation encoding="application/x-tex">y_w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是 chosen 的样本， <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">y_l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是 rejected 的样本。<span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>w</mi></msub></mrow><annotation encoding="application/x-tex">y_w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 被偏好的概率取决于两个回答的奖励之差。</p>
<h3>6.5 代入得到 DPO Loss</h3>
<p>现在把 6.3 中的奖励函数代入 Bradley-Terry 模型。关键观察是：<span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><mi>Z</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\log Z(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span> 在两个回答中是一样的，相减的时候会消掉！</p>
<p v-pre="" class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>r</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>w</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>r</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>l</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>β</mi><mi>log</mi><mo>⁡</mo><mfrac><mrow><msup><mi>π</mi><mo>∗</mo></msup><mo stretchy="false">(</mo><msub><mi>y</mi><mi>w</mi></msub><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><msub><mi>π</mi><mrow><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">f</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>w</mi></msub><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>−</mo><mi>β</mi><mi>log</mi><mo>⁡</mo><mfrac><mrow><msup><mi>π</mi><mo>∗</mo></msup><mo stretchy="false">(</mo><msub><mi>y</mi><mi>l</mi></msub><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><msub><mi>π</mi><mrow><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">f</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>l</mi></msub><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">
r(x, y_w) - r(x, y_l) = \beta \log \frac{\pi^*(y_w \mid x)}{\pi_{\mathrm{ref}}(y_w \mid x)} - \beta \log \frac{\pi^*(y_l \mid x)}{\pi_{\mathrm{ref}}(y_l \mid x)}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.07778em;">ref</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.07778em;">ref</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>前面提到，我们把 <strong>待训练的模型 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">\pi_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 认为是最优策略 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>π</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">\pi^*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span></strong>。</p>
<p>最终，最大化偏好数据的似然（等价于最小化负对数似然），就得到了 DPO Loss：</p>
<p v-pre="" class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="script">L</mi><mrow><mi mathvariant="normal">D</mi><mi mathvariant="normal">P</mi><mi mathvariant="normal">O</mi></mrow></msub><mo>=</mo><mo>−</mo><msub><mi mathvariant="double-struck">E</mi><mrow><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>w</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>l</mi></msub><mo stretchy="false">)</mo></mrow></msub><mrow><mo fence="true">[</mo><mi>log</mi><mo>⁡</mo><mi>σ</mi><mo fence="false" stretchy="true" minsize="1.8em" maxsize="1.8em">(</mo><mi>β</mi><mi>log</mi><mo>⁡</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>w</mi></msub><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><msub><mi>π</mi><mrow><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">f</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>w</mi></msub><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>−</mo><mi>β</mi><mi>log</mi><mo>⁡</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>l</mi></msub><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><msub><mi>π</mi><mrow><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">f</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>l</mi></msub><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo fence="false" stretchy="true" minsize="1.8em" maxsize="1.8em">)</mo><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">
\mathcal{L}_{\mathrm{DPO}} = - \mathbb{E}_{(x,y_w,y_l)} \left[ \log \sigma\Big(\beta \log \frac{\pi_\theta(y_w \mid x)}{\pi_{\mathrm{ref}}(y_w \mid x)} - \beta \log \frac{\pi_\theta(y_l \mid x)}{\pi_{\mathrm{ref}}(y_l \mid x)}\Big) \right]
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">DPO</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="mord">−</span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em;"><span style="top:-2.357em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">[</span></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mord"><span class="delimsizing size2">(</span></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.07778em;">ref</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.07778em;">ref</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="delimsizing size2">)</span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">]</span></span></span></span></span></span></span></p>
<p>这就是我们在第 2 节看到的 DPO Loss。</p>
<h2>7. 总结</h2>
<p>一句话总结：<strong>DPO 用监督学习的方式实现了 RLHF 的效果，把 4 个模型简化成 2 个，训练更稳定、资源消耗更低</strong>。</p>
<p>DPO 的局限性：</p>
<ul>
<li>依赖偏好数据的质量，数据不好效果就不好</li>
<li>对 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span> 参数比较敏感，需要调参</li>
</ul>
<p>后续还有一些 DPO 的变体，比如 IPO（Identity Preference Optimization）、KTO（Kahneman-Tversky Optimization）等，以后有机会再聊（其实就是大概率没有机会了，醒醒吧，2026 年了）。</p>
<h2>8. 参考资料</h2>
<ol>
<li><a href="https://arxiv.org/abs/2305.18290" target="_blank" rel="noopener noreferrer">DPO 原论文: Direct Preference Optimization</a></li>
<li><a href="https://huggingface.co/docs/trl" target="_blank" rel="noopener noreferrer">trl 库文档</a></li>
</ol>
<h2>其他</h2>
<p>最后欢迎关注我，基本全网同名 <a href="https://yuanchaofa.com/" target="_blank" rel="noopener noreferrer">chaofa用代码打点酱油</a></p>
<ul>
<li>公众号： <img src="https://yuanchaofa.com/llms-zero-to-hero/chaofa-wechat-official-account.png" alt="chaofa用代码打点酱油" loading="lazy"></li>
<li><a href="https://space.bilibili.com/12420432" target="_blank" rel="noopener noreferrer">B站-chaofa用代码打点酱油</a></li>
<li><a href="https://www.youtube.com/@bbruceyuan" target="_blank" rel="noopener noreferrer">YouTube-chaofa用代码打点酱油</a></li>
<li><a href="https://chaofa.notion.site/11a569b3ecce49b2826d679f5e2fdb54" target="_blank" rel="noopener noreferrer">chaofa 的 notion 简介</a></li>
</ul>
]]></content:encoded>
      <enclosure url="https://yuanchaofa.com/blog_imgs/ppo-vs-dpo.png" type="image/png"/>
    </item>
    <item>
      <title>从零手写 RoPE 位置编码：原理、PyTorch 源码实现与可视化理解</title>
      <link>https://yuanchaofa.com/post/hands-on-rope-position-embedding.html</link>
      <guid>https://yuanchaofa.com/post/hands-on-rope-position-embedding.html</guid>
      <source url="https://yuanchaofa.com/rss.xml">从零手写 RoPE 位置编码：原理、PyTorch 源码实现与可视化理解</source>
      <description>深入讲解 RoPE 旋转位置编码的核心原理与 PyTorch 实现。从 2D 旋转矩阵推导相对位置编码，逐行手写代码实现 LLaMA Qwen 风格 RoPE，附热力图可视化帮助理解。适合想彻底搞懂 RoPE 位置编码的开发者。</description>
      <category>hands-on-code</category>
      <pubDate>Thu, 01 Jan 2026 16:57:20 GMT</pubDate>
      <content:encoded><![CDATA[<h2>0. 阅读收获 (takeaway)</h2>
<p>本文旨在彻底搞懂 RoPE（Rotary Position Embedding）位置编码，阅读完本文你将获得：</p>
<ul>
<li>理解 RoPE 的核心思想：为什么用"旋转"来编码位置信息</li>
<li>掌握 RoPE 的数学原理：从旋转矩阵到三角函数证明</li>
<li>从零手写 RoPE 实现：逐行代码讲解，可直接运行</li>
<li>bonus：可视化理解 RoPE：通过热力图和动画直观感受旋转编码</li>
</ul>
<blockquote>
<p>本文代码运行于： <a href="https://featurize.cn/srx/gthYt2" target="_blank" rel="noopener noreferrer">Featurize GPU 算力云平台</a>，有 GPU 使用需求的同学希望能使用<a href="https://featurize.cn/srx/gthYt2" target="_blank" rel="noopener noreferrer">我的邀请链接注册</a></p>
<p>待更新：不喜欢看文字的同学可以看 <a href="https://space.bilibili.com/12420432" target="_blank" rel="noopener noreferrer">B站视频-chaofa用代码打点酱油</a>, <a href="https://www.youtube.com/@bbruceyuan" target="_blank" rel="noopener noreferrer">YouTube-chaofa用代码打点酱油</a>，或视频号：chaofa用代码打点酱油</p>
</blockquote>
<h2>1. 为什么需要位置编码？</h2>
<p>在 Transformer 架构中，<a href="https://yuanchaofa.com/hands-on-code/from-self-attention-to-multi-head-self-attention.html" target="_blank" rel="noopener noreferrer">Self-Attention 机制</a>本身是<strong>位置无关</strong>的。公式如下：</p>
<p v-pre="" class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Attention</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mrow><mo fence="true">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo fence="true">)</mo></mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Attention</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4684em;vertical-align:-0.95em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183em;"><span style="top:-2.2528em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8572em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8172em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1828em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span></p>
<p><code>softmax</code> 中 QK 的乘积就是重要性权重，什么意思呢？</p>
<div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># 假设我们有两个句子</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">sentence1 </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379"> "朝发 写 代码"</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">sentence2 </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379"> "代码 写 朝发"</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># 对于纯 Self-Attention 来说，这两个句子的表示是一样的！</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># 从公式看 Attention 只关心 token 之间的权重关系，不关心它们的顺序</span></span></code></pre>
<div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这显然是不对的。语言是有顺序的，顺序不同意思完全不同。因此，我们需要<strong>位置编码</strong>（Position Encoding, PE）来告诉模型每个 token 在序列中的位置。</p>
<h3>1.1 绝对位置编码 vs 相对位置编码</h3>
<p>用一个例子来理解这两种编码方式的区别：</p>
<div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>句子: "朝发 写 代码"</span></span>
<span class="line"><span>位置:   0  1  2</span></span></code></pre>
<div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0"><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>绝对位置编码</strong>：给每个位置一个固定编号</p>
<div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>"朝发" → 位置 0 → PE_0</span></span>
<span class="line"><span>"写"   → 位置 1 → PE_1</span></span>
<span class="line"><span>"代码" → 位置 2 → PE_2</span></span>
<span class="line"><span>备注：PE_0 表示第一个位置的 embedding</span></span></code></pre>
<div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>相对位置编码</strong>：关注两个 token 之间的距离</p>
<div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>计算 "朝发" 和 "代码" 的关系时：</span></span>
<span class="line"><span>→ 不关心它们分别在位置 0 和 2</span></span>
<span class="line"><span>→ 只关心它们相距 2 个位置</span></span></code></pre>
<div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>同理：计算 "朝发" 和 "写" 之间的相对位置是 (1 - 0) = 1。</p>
<p>使用相对位置编码就是希望捕获 Token 之间位置的相对关系，保持（某些）语义的不变性，下面 「朝发」和「代码」之间的关系是一样的，尽管绝对位置不同：</p>
<div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>句子 A: "朝发 写 代码"</span></span>
<span class="line"><span>句子 B: "今天 朝发 写 代码"</span></span></code></pre>
<div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0"><div class="line-number"></div><div class="line-number"></div></div></div><h2>2. RoPE 的核心思想</h2>
<p>RoPE（Rotary Position Embedding，旋转位置编码）的核心思想非常优雅，可以阅读<a href="https://www.spaces.ac.cn/archives/8265" target="_blank" rel="noopener noreferrer">苏神 RoPE blog</a>：</p>
<blockquote>
<p><strong>通过旋转变换为向量注入位置信息，使得两个向量的内积只依赖于它们的相对位置。</strong></p>
</blockquote>
<p>这句话怎么理解呢？让我们一步步拆解看。</p>
<h3>2.1 从 2D 旋转说起</h3>
<p>假设我们在二维平面上有一个向量 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x, y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span>，将它旋转角度 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> 后得到新向量：</p>
<p v-pre="" class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mo fence="true">(</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msup><mi>x</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msup><mi>y</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>cos</mi><mo>⁡</mo><mi>θ</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mi>sin</mi><mo>⁡</mo><mi>θ</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>sin</mi><mo>⁡</mo><mi>θ</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>cos</mi><mo>⁡</mo><mi>θ</mi></mrow></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mrow><mo fence="true">(</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>x</mi></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>y</mi></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">
\begin{pmatrix} x' \\ y' \end{pmatrix} = \begin{pmatrix} \cos\theta &amp; -\sin\theta \\ \sin\theta &amp; \cos\theta \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.95em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">cos</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">sin</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.95em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">sin</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">cos</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.95em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">x</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.95em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span></span></span></span></span></p>
<p>这就是经典的 2D 旋转矩阵。下面用一张图来直观理解：</p>
<p><img src="https://cfcdn.yuanchaofa.com/blog/2025/20260101165342.png" alt="2D 向量旋转示意图" loading="lazy"></p>
<p>从图中可以看到：蓝色向量 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x, y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span> 绕原点逆时针旋转角度 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> 后，变成红色向量 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msup><mi>x</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo separator="true">,</mo><msup><mi>y</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x', y')</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。</p>
<h3>2.2 RoPE 的目标与解决方案</h3>
<p><strong>目标</strong>：我们希望找到一个位置编码函数 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span>，使得 query 向量 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">q</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{q}_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathbf">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 key 向量 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">k</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{k}_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathbf">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的内积只依赖于它们的相对位置 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>m</mi><mo>−</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(m-n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>：</p>
<p v-pre="" class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">⟨</mo><msub><mi>f</mi><mi>q</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">q</mi><mo separator="true">,</mo><mi>m</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><msub><mi>f</mi><mi>k</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">k</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">)</mo><mo stretchy="false">⟩</mo><mo>=</mo><mi>g</mi><mo stretchy="false">(</mo><mi mathvariant="bold">q</mi><mo separator="true">,</mo><mi mathvariant="bold">k</mi><mo separator="true">,</mo><mi>m</mi><mo>−</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">
\langle f_q(\mathbf{q}, m), f_k(\mathbf{k}, n) \rangle = g(\mathbf{q}, \mathbf{k}, m-n)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mopen">⟨</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathbf">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">m</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathbf">k</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">n</span><span class="mclose">)⟩</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathbf">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathbf">k</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span></span></p>
<p>也就是说，无论 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">m</span></span></span></span> 和 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> 的绝对值是多少，只要 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>−</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m-n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> 相同，内积结果就相同。</p>
<p><strong>解决方案</strong>：RoPE 发现，这个函数 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span> 就是<strong>旋转函数</strong>！（实际上是可以通过求解出来的，可以参考：<a href="https://www.spaces.ac.cn/archives/8265" target="_blank" rel="noopener noreferrer">Transformer升级之路：2、博采众长的旋转式位置编码</a>），这里我们假设「知道了这么一个函数」，然后我们去证明它符合我们的需求。</p>
]]></content:encoded>
      <enclosure url="https://cfcdn.yuanchaofa.com/blog/2025/20260101165342.png" type="image/png"/>
    </item>
    <item>
      <title>Keep Looking, Don&amp;apos;t Settle：重听乔布斯演讲（25-11-月度小结）</title>
      <link>https://yuanchaofa.com/blog/2025-11-month-summary.html</link>
      <guid>https://yuanchaofa.com/blog/2025-11-month-summary.html</guid>
      <source url="https://yuanchaofa.com/rss.xml">Keep Looking, Don&amp;apos;t Settle：重听乔布斯演讲（25-11-月度小结）</source>
      <description>重听乔布斯斯坦福演讲，发现真正的主题不是&amp;quot;Stay hungry, Stay foolish&amp;quot;，而是&amp;quot;寻找你的热爱&amp;quot;（You’ve got to find what you love）。So keep looking. Don&amp;apos;t settle。</description>
      <category>月度总结</category>
      <pubDate>Sat, 06 Dec 2025 22:52:00 GMT</pubDate>
      <content:encoded><![CDATA[<h2>Keep Looking, Don't Settle</h2>
<p>这个月突然又偶然又听了一遍那场著名的「乔布斯在斯坦福毕业演讲」，最有名的一句话莫过于「Stay hungry. Stay foolish」。</p>
<p><img src="https://cfcdn.yuanchaofa.com/blog/2025/1765035529290.webp" alt="‘You’ve got to find what you love,’ Jobs says|388x258" loading="lazy"></p>
<p>看这个 blog 的人应该每个人都听过好多遍，我也一样，但这次听真正击中的我并不是这句话，而是第二个创业故事中提到的「Keep Looking, Don't Settle」。</p>
<p>纯英文演讲我并没有 GET 到多少东西，我又翻了一遍原文，才知道原来我一直理解错了这个演讲的主题，主题并不是告诉我们要【<strong>永远保持学习和探索的热情</strong>，即这句最广为流传的 Stay hungry. Stay foolish】，真正的文章标题是：「<a href="https://news.stanford.edu/stories/2005/06/youve-got-find-love-jobs-says" target="_blank" rel="noopener noreferrer"><strong>You’ve got to find what you love</strong></a>」，原来这篇文章的主题一直都是寻找自己的热爱。</p>
<p>第一次这个演讲应该是初三的时候，那时候觉得很热血很受鼓舞，15 年后的今天重看有完全不一样的感觉，<strong>我觉得好感动</strong>，我觉得说出这样的话真的很让人感动。</p>
<blockquote>
<p>I’m convinced that the only thing that kept me going was that I loved what I did. You’ve got to find what you love—and that is as true for work as it is for your lovers. Your work is going to fill a large part of your life, and the only way to be truly satisfied is to do what you believe is great work. And the only way to do great work is to love what you do.
<br><br>
If you haven’t found it yet, keep looking—and don’t settle. As with all matters of the heart, you’ll know when you find it. And like any great relationship, it just gets better and better as the years roll on. So keep looking. Don’t settle.</p>
</blockquote>
<p>我想，尝试过寻找方向的你们一定很懂这里的话有多感人，<strong>So keep looking. Don't settle</strong>.</p>
<h2>工作</h2>
<p>回看了一下 11 月记录的 Flomo，这个月的工作压力依然非常的巨大，这里有很多原因造成的：</p>
<ul>
<li>任务真的太难了（某个非常复杂的生成场景）。尽管已经通过一些方式优化最终完成了交付，但也仅仅是可以使用，真正离达到好用还有很明显的差距。</li>
<li>标准难以定义。可执行和执行好两个完全不同的维度，尤其是这个好很难在任务中很好的定义出来，虽然有隐隐的优化方向，但是前面已经在「可执行」上花费了太多的力气导致「执行好」的进度并没有如我自己想象中的那般快。</li>
<li>项目进展管理一直做的不太好。从今年 2 月份开始一人做一个方向，到后面两三个人一起做，我要负责整个项目的多人进展时，就会明显感觉自己在这方面的能力有所欠缺，自己也会有明显的畏难情绪。整体虽然有进步但是离目标还差太远了。</li>
</ul>
<p>这个月未其实有个我挺喜欢的任务要做，但是真的太耗费我晚上与周末的时间了，有娃之后的我真的顶不住，我周末只想陪娃一会和休息了，不想周末再卷了，想放弃了。难道这又是到了最关键的时候就开始泄气吗？毕竟已经念头通达了。</p>
<h2>破产之路</h2>
<p>本月出现巨额亏损，核心是因为我重仓了 FIGMA，亏成了麻瓜，我为什么要在阿里起飞之际卖出画成 FIGMA 啊，怎么买不买中概都是亏钱啊。</p>
<p>OK，好吧，我从现在开始，我就定投纳斯达克和标普 500，慢慢彻底不玩个股了，这样的我五年后还会亏钱吗？Looking my eyes, answer me!!!!</p>
]]></content:encoded>
      <enclosure url="https://cfcdn.yuanchaofa.com/blog/2025/1765035529290.webp" type="image/webp"/>
    </item>
    <item>
      <title>Kimi-K2 和 Kimi-K2-Thinking 深度解读：从预训练优化到 Agentic 能力训练的完整流程（含MuonClip优化、Agentic 数据合成等）</title>
      <link>https://yuanchaofa.com/post/kimi-k2-and-kimi-k2-thinking-notes.html</link>
      <guid>https://yuanchaofa.com/post/kimi-k2-and-kimi-k2-thinking-notes.html</guid>
      <source url="https://yuanchaofa.com/rss.xml">Kimi-K2 和 Kimi-K2-Thinking 深度解读：从预训练优化到 Agentic 能力训练的完整流程（含MuonClip优化、Agentic 数据合成等）</source>
      <description>深度解读 Kimi K2 和 K2 Thinking 技术细节：MuonClip 优化方案、大规模 Agentic 数据合成 pipeline、通用强化学习的 Self-Judging 机制，以及 200-300 步工具调用的 Test-Time Scaling。从预训练到后训练，揭秘月之暗面如何打造 SOTA 开源 Thinking 模型。</description>
      <category>paper-reading</category>
      <pubDate>Sun, 09 Nov 2025 17:26:00 GMT</pubDate>
      <content:encoded><![CDATA[<h2>0. 背景</h2>
<p>月之暗面发布的 <strong><a href="https://moonshotai.github.io/Kimi-K2/thinking.html" target="_blank" rel="noopener noreferrer">Kimi K2 Thinking</a></strong>，在 Humanity's Last Exam (HLE) 上达到了 44.9% 的成绩，在多个基准测试中表现优异，不过榜单简单看一眼即可；让我比较惊喜的是，K2 Thinking 可以执行 200-300 步连续的工具调用，有类似于 <code>claude</code> 一样的长程规划和自适应推理能力。</p>
<p>但是，K2 Thinking 的官方 blog 只展示了 benchmark 数据和 demo，并没有透露具体的技术细节。作为一个大模型从业者，看到 Twitter/知乎大家都在聊这个模型，所以我就比较好奇「模型的训练方法」以及「给我们工作学习中的启发」。</p>
<p>好在今年早些时候发布了 <strong>Kimi K2</strong> 的完整<a href="https://arxiv.org/abs/2507.20534" target="_blank" rel="noopener noreferrer">技术报告</a>和 <a href="https://moonshotai.github.io/Kimi-K2/" target="_blank" rel="noopener noreferrer">技术 blog</a>。而 <strong>K2 Thinking 和 K2 师出同源</strong>，只是在 K2 的基础上增加了 thinking 能力，更强的工具调用能力，通过 test-time scaling 实现一个更强的 Thinking Agent。因此，通过深入研究 K2 的技术细节，我们就能理解 K2 Thinking 是如何炼成的。</p>
<p>我是朝发（CHAOFA）这篇文章会从 K2 的技术报告出发，结合 K2 Thinking 的特点，了解这个 SOTA 开源 thinking 模型是怎么训出来的。<strong>核心关注三个问题</strong>：</p>
<ol>
<li><strong>预训练阶段</strong>：如何用 MuonClip 优化器实现更高的 token 效率？</li>
<li><strong>后训练阶段</strong>：如何通过大规模 Agentic 数据合成和通用强化学习，让模型学会使用工具？</li>
<li><strong>Test-Time Scaling</strong>：如何让模型在推理时进行长程思考和工具调用？</li>
</ol>
<blockquote>
<p>历史上此比较相关文章：</p>
<ul>
<li><a href="https://yuanchaofa.com/post/kimi-k1.5-paper-reading-notes.html" target="_blank" rel="noopener noreferrer">深度解读 Kimi-K1.5，真正了解 RL 数据是怎么筛选的</a></li>
<li><a href="https://yuanchaofa.com/post/deepseek-r1-paper-reading-notes.html" target="_blank" rel="noopener noreferrer">自顶向下方式深度解读 DeepSeek-R1，内含大量细节</a></li>
<li><a href="https://yuanchaofa.com/post/slow-fast-thinking-from-qwen3-thinking-mixed-to-adacot-to-adathinking.html" target="_blank" rel="noopener noreferrer">自适应快慢思考推理模型（Adaptive Reasoning Model）：Qwen3混合思考-&gt;字节AdaCoT-&gt;清华AdaptThinking</a></li>
</ul>
</blockquote>
<blockquote>
<p>如果不喜欢看文字可以看视频解读，<a href="https://www.bilibili.com/video/BV1yikRBvEwy/" target="_blank" rel="noopener noreferrer">B 站-chaofa用代码打点酱油</a>和 <a href="https://www.youtube.com/@bbruceyuan" target="_blank" rel="noopener noreferrer">YouTube</a></p>
<p><a href="https://www.bilibili.com/video/BV1yikRBvEwy/" target="_blank" rel="noopener noreferrer">算法视角深度解读 Kimi K2 和 K2 Thinking，从预训练优化到 Agentic 能力训练的完整流程（含MuonClip优化、Agentic 数据 --bilibili</a></p>
</blockquote>
<h2>1. 整体架构：从 K2 到 K2 Thinking</h2>
<p><img src="https://cfcdn.yuanchaofa.com/blog/2025/20251109144342.png" alt="image.png|700x366" loading="lazy"></p>
<blockquote>
<p>Archiecture from: <a href="https://x.com/rasbt/status/1986511951141441648?s=20" target="_blank" rel="noopener noreferrer">Sebastian Raschka</a></p>
</blockquote>
<p>先来看一下上面的整体结构图，然后在深入技术细节之前，我们有必要先理解 K2 和 K2 Thinking 的关系。</p>
<h3>1.1 K2：Open Agentic Intelligence 的基座</h3>
<p>Kimi K2 是一个 <a href="https://yuanchaofa.com/llms-zero-to-hero/the-way-of-moe-model-evolution.html" target="_blank" rel="noopener noreferrer">MoE (Mixture-of-Experts)</a> 模型，拥有 <strong>32B 激活参数和 1T 总参数</strong>。它在非 thinking 模型中，在前沿知识、数学和编码任务上达到了 SOTA 性能。</p>
<p>K2 的核心特点是<strong>有比较强的 Agentic 能力</strong>。什么是 Agentic 任务？就是模型不仅要回答问题，还要主动使用工具、执行操作、完成复杂的多步骤任务。比如：</p>
<ul>
<li>用 Python 分析数据、生成可视化网页</li>
<li>在命令行中编辑文件、运行命令</li>
<li>通过搜索和浏览器收集信息、验证假设、构建答案</li>
</ul>
<p>K2 发布了两个版本：</p>
<ul>
<li>Kimi-K2-Base：基础模型，适合研究者/开发者/企业用户进行微调</li>
<li>Kimi-K2-Instruct：后训练模型，适合直接使用，是一个非推理模式（Non-Reasoning Model）</li>
</ul>
<h3>1.2 K2 Thinking：加入 Test-Time Scaling</h3>
<p>Kimi K2 Thinking 是在 K2 的基础上，通过额外的训练，让模型具备了 thinking 能力。它的核心特点是：</p>
<ol>
<li>边思考边使用工具：模型在推理过程中，会进行 <code>think → search → browse → think → code</code> 的循环，动态生成和验证假设</li>
<li>长程推理：可以执行 200-300 步连续的工具调用，保持推理的连贯性。（这点是让人比较惊喜的）</li>
<li>Test-Time Scaling：通过增加推理时的 thinking tokens 和工具调用步数，提升模型性能</li>
</ol>
<p>从架构上看，<code>K2 Thinking = K2 + Thinking Ability + Test-Time Scaling</code>。因此，<strong>理解 K2 的训练方法，就能理解 K2 Thinking 的 80%</strong>。</p>
<p>下面我们按照训练流程，依次讲解预训练、后训练和 test-time scaling 的关键技术。</p>
<h2>2. 预训练</h2>
<h3>2.1 基于 MuonClip 优化器的 Token 效率优化</h3>
<p>预训练是 Agentic Intelligence 的关键基础，它建立了让强化学习探索变得可行、高效和可泛化的先验知识。但是，正如 Ilya Sutskever 所说，数据是有限的"化石燃料"，其增长速度远远落后于算力的增长。这使得<strong>预训练阶段的 token 利用效率</strong>成为 AI scaling laws 中的新关键系数。</p>
<h4>2.1.1 为什么需要更好的优化器？</h4>
<p>给定一个大致有限的预训练数据集和固定的模型配置，更 token 高效的优化器能产生更多的智能。Moonshot 之前的工作 <a href="https://github.com/MoonshotAI/Moonlight" target="_blank" rel="noopener noreferrer">Moonlight</a> 已经证明，<a href="https://kellerjordan.github.io/posts/muon/" target="_blank" rel="noopener noreferrer">Muon</a> 优化器在 LLM 训练中显著优于广泛使用的 AdamW 优化器，即“相同配置训练下有更低的 loss”。</p>
<p>K2 的设计目标是进一步扩展 Moonlight，它采用了类似 DeepSeek-V3 的架构。基于 scaling-law 分析，他们做了两点改进（看图更清晰）：</p>
<ul>
<li>减少了 attention heads 的数量，以提高长上下文效率。</li>
<li>增加了 MoE 的稀疏性，以获得更高的 token 效率</li>
</ul>
<blockquote>
<p>原文这么写的：Based on scaling-law analysis, we reduce the number of heads for long-context efficiency, and increase MoE sparsity for greater token efficiency。</p>
</blockquote>
<p>但在扩展过程中，他们遇到了一个持续的挑战：<strong>由 attention logits 爆炸引起的训练不稳定</strong>。这个问题在使用 Muon 时更频繁，而在 AdamW 中较少。现有的解决方案（如 Qwen3 用的 query-key normalization）都不够充分（防止数值溢出）。</p>
<h4>2.1.2 MuonClip：直接控制 Attention Logits</h4>
<p>为了解决这个问题，kimi 提出了 MuonClip 优化器，它通过 <strong>qk-clip 技术</strong>改进了 Muon。</p>
<p><strong>核心思想</strong>：qk-clip 通过在 Muon 更新后<strong>直接重新缩放 query 和 key 投影的权重矩阵</strong>，从源头控制 attention logits 的规模，从而稳定训练。（注意：这里是更新完之后，所以不会改变这一次更新的 forward/backward 操作，影响的是下一步）。</p>
<p>具体来说，query 和 key 投影按如下方式缩放：</p>
<p v-pre="" class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>q</mi><mi>i</mi></msub><mo>=</mo><msup><mi>η</mi><mi>α</mi></msup><msub><mi>W</mi><mi>q</mi></msub><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">
q_i = \eta^{\alpha} W_q x_i
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0005em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">η</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7144em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p v-pre="" class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>k</mi><mi>i</mi></msub><mo>=</mo><msup><mi>η</mi><mrow><mn>1</mn><mo>−</mo><mi>α</mi></mrow></msup><msub><mi>W</mi><mi>k</mi></msub><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">
k_i = \eta^{1-\alpha} W_k x_i
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0585em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">η</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> 是一个平衡超参数，因此 attention logit 变为：</p>
<p v-pre="" class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><msup><mi>η</mi><mi>α</mi></msup><msub><mi>q</mi><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mi mathvariant="normal">⊤</mi></msup><mo stretchy="false">(</mo><msup><mi>η</mi><mrow><mn>1</mn><mo>−</mo><mi>α</mi></mrow></msup><msub><mi>k</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>η</mi><mtext> </mtext><msubsup><mi>q</mi><mi>i</mi><mi mathvariant="normal">⊤</mi></msubsup><msub><mi>k</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">
(\eta^{\alpha} q_i)^\top (\eta^{1-\alpha} k_j) = \eta\, q_i^\top k_j
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1852em;vertical-align:-0.2861em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">η</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7144em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">η</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1852em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">η</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-2.453em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>自适应因子 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>η</mi></mrow><annotation encoding="application/x-tex">\eta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">η</span></span></span></span>（阈值为 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span>）在每一步之后根据该步的最大 attention logit 设置：</p>
<p v-pre="" class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>η</mi><mo>=</mo><mi>min</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mi>t</mi><mstyle scriptlevel="0" displaystyle="true"><munder><mrow><mi>max</mi><mo>⁡</mo></mrow><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></munder><mo fence="true" stretchy="true" minsize="1.2em" maxsize="1.2em">(</mo><msubsup><mi>q</mi><mi>i</mi><mi mathvariant="normal">⊤</mi></msubsup><msub><mi>k</mi><mi>j</mi></msub><mo fence="true" stretchy="true" minsize="1.2em" maxsize="1.2em">)</mo></mstyle></mfrac><mo separator="true">,</mo><mn>1</mn><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">
\eta = \min\left(\frac{t}{\displaystyle\max_{i,j}\bigl(q_i^\top k_j\bigr)}, 1\right)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">η</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.7029em;vertical-align:-1.6529em;"></span><span class="mop">min</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.05em;"><span class="pstrut" style="height:5.6em;"></span><span style="width:0.875em;height:3.600em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.875em" height="3.600em" viewBox="0 0 875 3600"><path d="M863,9c0,-2,-2,-5,-6,-9c0,0,-17,0,-17,0c-12.7,0,-19.3,0.3,-20,1
c-5.3,5.3,-10.3,11,-15,17c-242.7,294.7,-395.3,682,-458,1162c-21.3,163.3,-33.3,349,
-36,557 l0,84c0.2,6,0,26,0,60c2,159.3,10,310.7,24,454c53.3,528,210,
949.7,470,1265c4.7,6,9.7,11.7,15,17c0.7,0.7,7,1,19,1c0,0,18,0,18,0c4,-4,6,-7,6,-9
c0,-2.7,-3.3,-8.7,-10,-18c-135.3,-192.7,-235.5,-414.3,-300.5,-665c-65,-250.7,-102.5,
-544.7,-112.5,-882c-2,-104,-3,-167,-3,-189
l0,-92c0,-162.7,5.7,-314,17,-454c20.7,-272,63.7,-513,129,-723c65.3,
-210,155.3,-396.3,270,-559c6.7,-9.3,10,-15.3,10,-18z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em;"><span></span></span></span></span></span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2921em;"><span style="top:-2.2109em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.4306em;"><span style="top:-2.3723em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8638em;"><span></span></span></span></span></span><span class="mopen"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-2.453em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing size1">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.6529em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.05em;"><span class="pstrut" style="height:5.6em;"></span><span style="width:0.875em;height:3.600em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.875em" height="3.600em" viewBox="0 0 875 3600"><path d="M76,0c-16.7,0,-25,3,-25,9c0,2,2,6.3,6,13c21.3,28.7,42.3,60.3,
63,95c96.7,156.7,172.8,332.5,228.5,527.5c55.7,195,92.8,416.5,111.5,664.5
c11.3,139.3,17,290.7,17,454c0,28,1.7,43,3.3,45l0,9
c-3,4,-3.3,16.7,-3.3,38c0,162,-5.7,313.7,-17,455c-18.7,248,-55.8,469.3,-111.5,664
c-55.7,194.7,-131.8,370.3,-228.5,527c-20.7,34.7,-41.7,66.3,-63,95c-2,3.3,-4,7,-6,11
c0,7.3,5.7,11,17,11c0,0,11,0,11,0c9.3,0,14.3,-0.3,15,-1c5.3,-5.3,10.3,-11,15,-17
c242.7,-294.7,395.3,-681.7,458,-1161c21.3,-164.7,33.3,-350.7,36,-558
l0,-144c-2,-159.3,-10,-310.7,-24,-454c-53.3,-528,-210,-949.7,
-470,-1265c-4.7,-6,-9.7,-11.7,-15,-17c-0.7,-0.7,-6.7,-1,-18,-1z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span> 是预设的阈值。这是一个通用技术，可能适用于其他稳定化场景。这里其实还有一些其他的细节，比如 每个 head 有不同的 <span v-pre="" class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>η</mi></mrow><annotation encoding="application/x-tex">\eta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">η</span></span></span></span>。</p>
<h4>2.1.3 实验结果：零训练尖峰</h4>
<p>实验表明，MuonClip 有效地防止了 logit 爆炸，同时保持了下游任务性能。在实践中，K2 使用 MuonClip 在 15.5T tokens 上进行预训练，实现了零训练尖峰（zero loss spike），证明了 MuonClip 是大规模 LLM 训练的稳健解决方案。</p>
<p><img src="https://cfcdn.yuanchaofa.com/blog/2025/20251109161151.png" alt="image.png|700x420" loading="lazy"></p>
<p>从 loss 曲线可以看出，MuonClip 的训练过程非常平滑，没有出现任何不稳定的情况。这为后续的 Agentic 能力训练打下了坚实的基础。</p>
<p><strong>小结</strong>：MuonClip 优化器通过 qk-clip 技术，在保持 Muon 高 token 效率的同时，解决了训练不稳定问题，使得在同等条件下获得比 AdamW 更低的 loss，使得 K2 能够在有限的数据上训练出更强的基础模型。</p>
<h3>2.2 文本的改写优化</h3>
<p>K2 相比 K1.5 的一个关键进步是引入了<strong>合成数据生成策略</strong>来提高 token 利用率。核心思想是：通过精心设计的改写 pipeline，在不引入显著过拟合的情况下，扩大高质量 tokens 的数量。改写（Rephrasing） 就是数据合成的一种方式，主要是为了提高「高质量数据的占比」，尤其是「知识领域」和「数学领域」。：</p>
<h4>2.2.1 知识领域数据改写</h4>
<p>在知识密集型文本上进行预训练面临一个权衡：单次 epoch 不足以全面吸收知识，而多次 epoch 重复会导致收益递减并增加过拟合风险。为了提高高质量知识 tokens 的利用率，K2 提出了一个合成改写框架，每个语料库最多改写两次，包含三个关键组件：</p>
<p><strong>A. 风格和视角多样化的提示（Style- and perspective-diverse prompting）</strong></p>
<p>通过精心设计的 prompts，引导大语言模型以不同的风格和视角生成原文的忠实改写。这样做的好处是：</p>
<ul>
<li>增强语言多样性</li>
<li>保持事实完整性</li>
<li>避免简单的同义词替换</li>
</ul>
<p><strong>B. 分块自回归生成（Chunk-wise autoregressive generation）</strong></p>
<p>为了在长文档中保持全局连贯性并避免信息丢失，采用基于分块的自回归改写策略，一图胜千言：</p>
<p><img src="https://cfcdn.yuanchaofa.com/blog/2025/20251109163028.png" alt="image.png|700x344" loading="lazy"></p>
<p><strong>C. 保真度验证（Fidelity verification）</strong></p>
<p>为了确保原文和改写内容之间的一致性，进行保真度检查，比较每个改写段落与其源文本的语义对齐。这是训练前的初步质量控制步骤。</p>
<h4>2.2.2 数学领域数据改写</h4>
<p>为了增强数学推理能力，K2 采用了两种策略：</p>
<p><strong>A. "学习笔记"风格改写</strong></p>
<p>将高质量的数学文档改写成"学习笔记"风格，遵循 <a href="https://arxiv.org/abs/2501.01926" target="_blank" rel="noopener noreferrer">SwallowMath</a> 中引入的方法。这种风格更接近人类学习数学的方式，包含：</p>
<ul>
<li>逐步推导过程</li>
<li>关键概念解释</li>
<li>示例和练习</li>
</ul>
<p><strong>B. 多语言翻译</strong></p>
<p>将其他语言的高质量数学材料翻译成英语，以增加数据多样性。这样可以：</p>
<ul>
<li>利用非英语世界的优质数学资源</li>
<li>增加数学表达的多样性</li>
<li>扩大训练数据规模</li>
</ul>
<p><strong>小结</strong>：通过针对知识和数学领域的专门改写技术，K2 在不显著增加过拟合风险的情况下，大幅提高了高质量 tokens 的利用率。这种受控的数据增强策略是 K2 预训练成功的关键因素之一。</p>
<h2>3. 后训练(重点)</h2>
<p>K2 的增强 Agentic 能力源于两个重要方面：</p>
<ul>
<li><strong>大规模 Agentic 数据合成</strong></li>
<li><strong>通用强化学习</strong></li>
</ul>
<h3>3.1 大规模 Agentic 数据合成：教会模型使用工具</h3>
<p>为了教会模型复杂的工具使用能力，kimi 是基于<strong>大规模模拟真实世界的工具使用场景</strong>，构建了数据 pipeline。</p>
<h4>3.1.1 数据合成流程</h4>
<p>这个管道的核心思想是：<strong>系统地演化数百个领域，包含数千个工具</strong>（包括真实的 MCP 工具和合成工具），然后生成数百个具有不同工具集的 agents。</p>
<p><img src="https://cfcdn.yuanchaofa.com/blog/2025/20251109175053.png" alt="image.png|700x232" loading="lazy"></p>
<p>辅助看这个图：</p>
<p><img src="https://cfcdn.yuanchaofa.com/blog/2025/20251109163203.png" alt="image.png|700x233" loading="lazy"></p>
<p>具体流程如下：</p>
<ol>
<li>定义领域和工具：涵盖各种真实场景，如数据分析、网页开发、系统管理等</li>
<li>生成任务：所有任务都是基于 rubric 的（有明确的评分标准），确保一致的评估</li>
<li>模拟交互：Agents 与模拟环境和用户 agents 交互，创建真实的多轮工具使用场景</li>
<li>LLM 评判(LLM as judge)：根据任务 rubrics 评估模拟结果，过滤出高质量的训练数据</li>
</ol>
<p>这个可扩展的 pipeline 生成了<strong>多样化、高质量的数据</strong>，为大规模拒绝采样和强化学习铺平了道路。</p>
<h4>3.1.2 为什么这个方法有效？</h4>
<p>传统的工具使用训练依赖于人工标注的数据，成本高、规模小、多样性有限。而 k2 的方法通过<strong>自动化合成</strong>，可以：</p>
<ul>
<li>无限扩展：只要定义新的领域和工具，就能生成新的训练数据</li>
<li>保证质量：通过 rubric-based 评估和 LLM judge，确保数据质量</li>
<li>覆盖长尾场景：可以模拟各种罕见但重要的工具使用场景</li>
</ul>
<h3>3.2 通用强化学习：不可验证奖励</h3>
<p>传统的强化学习主要应用于<strong>可验证奖励</strong>的任务，比如数学题（答案对错明确）和竞赛编程（能否通过测试用例）。但对于<strong>不可验证奖励</strong>的任务（如写研究报告、创意写作），传统 RL 就无能为力了。</p>
<blockquote>
<p>是不是突然想起了 <a href="https://yuanchaofa.com/post/deepseek-grm-paper-reading-notes.html" target="_blank" rel="noopener noreferrer">DeepSeek-GRM（通用奖励模型）</a>。</p>
</blockquote>
<h4>3.2.1 Self-Judging 机制</h4>
<p>核心思想是：<strong>模型作为自己的评判者</strong>，为不可验证的任务提供可扩展的、基于 rubric 的反馈。</p>
<p>具体做法：</p>
<ol>
<li>对于不可验证的任务，模型生成多个候选答案</li>
<li>模型自己根据 rubric 评估这些答案，给出分数</li>
<li>使用这些分数作为奖励信号，进行强化学习</li>
</ol>
<blockquote>
<p>但这里有个问题：模型的自我评估准确吗？这不还是 LLM as Judge 那一套吗？</p>
</blockquote>
<h4>3.2.2 用可验证奖励改进 Critic</h4>
<p>kimi 的解决方案是：<strong>在可验证奖励的 on-policy rollouts 中，持续更新 critic</strong>，使 critic 在最新策略上不断提高评估准确性。</p>
<p>这可以看作是<strong>用可验证奖励来改进不可验证奖励的估计</strong>。通过这种方式，模型的自我评估能力会随着训练不断提升，从而支持更广泛的任务。</p>
<p><strong>小结</strong>：通过大规模 Agentic 数据合成和通用强化学习，K2 学会了在各种场景下使用工具，并且能够处理可验证和不可验证的任务。这为 K2 Thinking 的长程推理能力打下了基础。</p>
<h2>4. K2 Thinking</h2>
<p>K2 Thinking 在 K2 的基础上，增加了 <strong>thinking 能力</strong>、<strong>更强的工具调用能力</strong>和 <strong>test-time scaling</strong>。这使得模型能够在推理时进行长程思考和工具调用，从而解决更复杂的问题。</p>
<h3>4.1 什么是 Test-Time Scaling？</h3>
<p>Test-Time Scaling 是指<strong>在推理时增加计算量，以提升模型性能</strong>。对于 K2 Thinking，这体现在两个方面：</p>
<ol>
<li>增加 thinking tokens：模型在生成答案前，会先生成大量的思考过程（类似 OpenAI o1，这其实就是 Long-CoT，这种技术在 Kimi-k1.5 就已经开始做了）</li>
<li>增加工具调用步数：模型可以执行 200-300 步连续的工具调用，进行长程规划（这是新增的，为了 Agentic 能力的提升）</li>
</ol>
<p>这两者结合，使得 K2 Thinking 能够解决需要深度推理和多步操作的复杂问题。</p>
<h3>4.2 边思考边使用工具：Interleaved Reasoning</h3>
<p>K2 Thinking 的核心能力是<strong>边思考边使用工具</strong>。它会进行动态的 <code>think → search → browse → think → code</code> 循环，这个循环可以重复数百次，直到找到答案：</p>
<ol>
<li>Think：分析问题，生成假设</li>
<li>Search：搜索相关信息</li>
<li>Browse：浏览网页，提取关键信息</li>
<li>Think：验证假设，调整策略</li>
<li>Code：编写代码，执行计算</li>
</ol>
<h3>4.3 简要看看 benchmark</h3>
<h4>4.3.1 Agentic Search：超越人类基线</h4>
<p>在 BrowseComp benchmark 上，K2 Thinking 达到了 <strong>60.2%</strong> 的成绩，显著超越了 <strong>29.2%</strong> 的人类基线。</p>
<p>BrowseComp 是一个挺具有挑战性的 benchmark，旨在评估模型<strong>持续浏览、搜索和推理难以找到的真实世界网络信息</strong>的能力。</p>
<h4>4.3.2 Agentic Coding：构建完整的应用</h4>
<p>K2 Thinking 在编码任务上也表现出色：</p>
<p><img src="https://cfcdn.yuanchaofa.com/blog/2025/20251109164955.png" alt="image.png|700x469" loading="lazy"></p>
<p>从官网看，K2 Thinking 可以<strong>从单个 prompt 构建完整的应用</strong>，包括：</p>
<ul>
<li>组件密集的网站</li>
<li>Word 克隆应用</li>
<li>交互式数据分析工具</li>
</ul>
<h3>4.4 小结</h3>
<p>通过 test-time scaling，K2 Thinking 能够在推理时进行长程思考和工具调用，从而解决需要深度推理和多步操作的复杂问题。这使得它在 Agentic Reasoning、Agentic Search 和 Agentic Coding 任务上都达到了 SOTA 性能。（有点 claude 那味道了）</p>
<h2>5. 技术细节对比：K2 vs K2 Thinking</h2>
<p>让我们总结一下 K2 和 K2 Thinking 的关键区别：</p>
<p>| 维度 | K2 (Instruct) | K2 Thinking |
|</p>
]]></content:encoded>
      <enclosure url="https://cfcdn.yuanchaofa.com/blog/2025/20251109144342.png" type="image/png"/>
    </item>
    <item>
      <title>影视飓风TIM成功背后：一个程序员对自媒体商业化的深度复盘（25年10月月度小结）</title>
      <link>https://yuanchaofa.com/blog/2025-10-month-summary.html</link>
      <guid>https://yuanchaofa.com/blog/2025-10-month-summary.html</guid>
      <source url="https://yuanchaofa.com/rss.xml">影视飓风TIM成功背后：一个程序员对自媒体商业化的深度复盘（25年10月月度小结）</source>
      <description>深度解析影视飓风TIM的成功路径，从精力管理、数据驱动、商业变现到家庭支持四个维度，反思自媒体发展困境。一个技术博主的真实思考：如何在理想主义与商业化之间找到平衡？来自一线技术从业者的深度思考，为内容创作者提供实用启发</description>
      <category>月度总结</category>
      <pubDate>Sun, 02 Nov 2025 20:52:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>我是朝发（chaofa），这是我 25 年第 9 次月度总结，希望还能坚持下去。</p>
<p>从信息传播角度，现在是一个好的社会，很多的大佬也愿意出来讲话，无论是播客还是文章，都很容易被传播到，从而得以瞥见他们的想法。这让我们看到很多。我有时候很感激，有时候又时长感慨：他们的成功真的可以复制吗？</p>
<p>罗永浩的播客是一个挺好的东西，我几乎是每一期都听的，10 月份<a href="https://www.xiaoyuzhoufm.com/episode/68e74f521bef327f3d7ddcd7" target="_blank" rel="noopener noreferrer">和影视飓风 TIM 的采访</a>让我很是羡慕，<a href="https://zh.wikipedia.org/zh-sg/%E5%BD%B1%E8%A7%86%E9%A3%93%E9%A3%8E" target="_blank" rel="noopener noreferrer">潘天鸿</a>。96 年，还不到 30 岁，但现在已经彻底成功<sup class="footnote-ref"><a href="#footnote1">[1]</a><a class="footnote-anchor" id="footnote-ref1"></a></sup><a class="footnote-anchor" id="footnote-ref1">。老罗和他的对话还挺有意思的，但我主要是聊四个东西对我的启发：</a></p><a class="footnote-anchor" id="footnote-ref1">
<ul>
<li>TIM 超强的能量</li>
<li>极致的数据化驱动</li>
<li>商业化道路的选择</li>
<li>TIM 家庭的支持</li>
</ul>
<p><img src="https://cfcdn.yuanchaofa.com/blog/2025/20251102204745.webp" alt="20251102204745" loading="lazy"></p>
</a><h2><a class="footnote-anchor" id="footnote-ref1"></a><a class="header-anchor" href="#tim-的精力与野心"><span>TIM 的精力与野心</span></a></h2>
<p>我觉得 TIM 给我的感觉就是另外一个维度的雷军，是那种特别努力的人。这种被称得上“努力”的人，不仅有着天生好的精力和体力，还配有强大的意志和成功欲望，这些可能都不是后天能够锻炼出来或者培养出来的东西<sup class="footnote-ref"><a href="#footnote2">[2]</a><a class="footnote-anchor" id="footnote-ref2"></a></sup><a class="footnote-anchor" id="footnote-ref2">。我真的非常佩服 TIM 的精力，他几乎是每一期真人出镜，且有大量的口播，考虑到更新频率以及「影视飓风」那么大体量公司管理和沟通的事情，他必然是全情投入其中，不容其他人丝毫地质疑他的努力。</a></p><a class="footnote-anchor" id="footnote-ref2">
</a><p><a class="footnote-anchor" id="footnote-ref2">在对谈中，有一个词出现的频率特别高「野兽先生，Mr. Beast」，TIM 的对标账号是世界第一网红「野兽先生」，尽管这不是我所喜欢的风格<sup class="footnote-ref"></sup></a><a href="#footnote3">[3]</a><a class="footnote-anchor" id="footnote-ref3">，但是我觉得这主要是他的野心太大了。「大众流量」、「声誉口碑」他全都要，并且要靠「流量变现」养活其他的探索与尝试，所以他选择了这种已经被证明的道路。野兽先生无疑是成功的，想要获得巨大的影响力这也是一个最好的办法，毕竟他要养着「<strong>冲击奥斯卡短片</strong>」的团队，靠着矩阵账号的方式，打造着目前中国（可能是）最成功的自媒体账号。</a></p><a class="footnote-anchor" id="footnote-ref3">
</a><h2><a class="footnote-anchor" id="footnote-ref3"></a><a class="header-anchor" href="#影视飓风数据驱动方式"><span>影视飓风数据驱动方式</span></a></h2>
<p>影视飓风很早之前就有一期飞书的广告视频，讲「<a href="https://www.bilibili.com/video/BV1itK3zsEx2/" target="_blank" rel="noopener noreferrer">影视飓风是如何通过数据驱动的方式增长</a>」。作为任何一个「互联网行业从业者」，应该对此完全的不陌生，里面说的所有内容都是在职场中被宣贯无数次的准则，但是要真正在自己的生活或者「自己的事业」上落实这些道理却有巨大的挑战。很多时候，我们就是无法跨越这种「知道」和「做到」的巨大鸿沟。</p>
<p>就以我自己为例，作为一个曾经在中文最大的互联网公司的广告相关从业者，我自然知道「点击率」、「留存」以及「各种漏斗指标」对于一个视频的影响，但是我自己做「B 站/YouTube/小红书<a href="https://space.bilibili.com/12420432" target="_blank" rel="noopener noreferrer">大模型教学视频（chaofa 用代码打点酱油）</a>」的时候，我总是带有一种「类似于理想主义的天真」，希望别人能认真看下去<sup class="footnote-ref"><a href="#footnote4">[4]</a><a class="footnote-anchor" id="footnote-ref4"></a></sup><a class="footnote-anchor" id="footnote-ref4">，从而收获真正的价值，所以我一直想要筛选掉那些「并不是想真正学习的人」，于是我通过「不剪辑、不配字幕、封面不设计、口播不写稿等」一系列愚蠢至极的操作把真正想学习的人筛选出来了，事实上我好像部分成功了，<strong>我成功筛选出了「高学历、高收入、低付费意愿」的能够自我学习和进化的人士</strong>，一方面为此感到欣慰，一方面又「</a><a href="https://yuanchaofa.com/blog/2025-09-month-summary.html" target="_blank" rel="noopener noreferrer">因为自己的思想的转变</a>」而感觉有点想笑。</p>
<h2>商业化道路选择</h2>
<p>自媒体似乎很光鲜亮丽，尤其是被「各种网红的造富神话」的冲击之后，现在越来越多的年轻人将「当网红」作为自己的最佳的职业选择<sup class="footnote-ref"><a href="#footnote5">[5]</a><a class="footnote-anchor" id="footnote-ref5"></a></sup><a class="footnote-anchor" id="footnote-ref5">。但大多数人只要自己尝试之后，才会发现实际上是很难赚钱的（除了那些教别人做自媒体的），或者说很难赚到自己「付出同样精力打工上班」赚到的钱。</a></p><a class="footnote-anchor" id="footnote-ref5">
</a><p><a class="footnote-anchor" id="footnote-ref5">核心原因是自媒体赛道的变现问题，前段时间</a><a href="https://cj.sina.com.cn/articles/view/5061312402/12dad7f9202002j354" target="_blank" rel="noopener noreferrer">王自如限高做绿皮火车吃泡面</a>的新闻就可见一斑（毕竟也是曾经的顶流）。这里主要有两个原因：</p>
<ul>
<li>内容行业无法规模化。TIM 在大多数影视飓风的视频中都是自己作为核心要素出镜，也就是说他是整个账号最核心的资产，所以注定了他们的视频无法做到「批量复制」，因此相对于其他的商业模式上限会更低（哪怕是一些主流的科技媒体）。</li>
<li>靠广告挣钱很难做到「独立客观第三方」。播客中也提到了「自媒体能不能站着把钱挣了」？就连影视飓风这样的账号都很难，更不用说各种「脚部、脚底部」账号，因此到了某个层面，一定会降低公信力，从而出现信任危机与拐点。</li>
</ul>
<p>而 TIM 的选择是通过卖货，即现在大多数账号的首要变现方式一样（包括像 <a href="https://space.bilibili.com/208130286" target="_blank" rel="noopener noreferrer">B 站的大物是也</a>等）也都是通过卖货来变现的，只是可能 TIM 这种自建电商品牌的方式更正规军一点，并且在很早开始尝试，而很多账号可能还在犹豫、彷徨、迷茫，而影视飓风已经带着 TIM 的同款内裤把钱赚了个够。</p>
<p>回到我的账号——<a href="https://space.bilibili.com/12420432" target="_blank" rel="noopener noreferrer">chaofa用代码打点酱油</a>，变现效率可能说是奇差，刚刚提到的「高学历、高收入、低付费意愿」的人其实就是我自己（我的同事、我的同学们），我也是属于那种付费意愿比较低的人🤣，思想正在转变中。想要卖货是不可能了，但是我发现「<a href="https://x.com/bbruceyuan/status/1983585794095984645?s=46" target="_blank" rel="noopener noreferrer">网络上很多盗版我视频</a>的人」，在我视频不到40 的情况下盗版视频可能有近百个了，因此我的视频绝对是有价值的，所以我一定要快点写书，等写完书我就可以尝试卖课了（严肃脸😠），也许是 26 年底，也许是永远不会（懒惰可能会占领智商的高地）。</p>
<h2>家庭的支持</h2>
<p>很多人都说 TIM 的成功当然也离不开家庭的支持，这里指的是那份底气和关键性的指导，他可以有足够的尝试，可以自由的探索。这是显然的，毕竟做成这样缺失路上任何一环都不会有现在的「影视飓风」，不过这可能是最不重要的，因为他真的很强，没有这样的家庭他也能成功，只是可能不一定有现在成功<sup class="footnote-ref"><a href="#footnote6">[6]</a><a class="footnote-anchor" id="footnote-ref6"></a></sup><a class="footnote-anchor" id="footnote-ref6">。但是无论如何，他的成功都是自己争取得到的，其他的东西只是景上添花，就算不是 29 岁，39 岁的 TIM 也一定会走上人生巅峰。RESPECT！</a></p><a class="footnote-anchor" id="footnote-ref6">
</a><h2><a class="footnote-anchor" id="footnote-ref6"></a><a class="header-anchor" href="#关注我"><span>关注我</span></a></h2>
<p>最后欢迎来探讨对世界的认知，基本全网同名 <a href="https://yuanchaofa.com/" target="_blank" rel="noopener noreferrer">chaofa用代码打点酱油</a> (推荐)</p>
<ul>
<li><a href="https://yuanchaofa.com/llms-zero-to-hero/chaofa-wechat-official-account.png" target="_blank" rel="noopener noreferrer">公众号-chaofa用代码打点酱油</a>
<ul>
<li><img src="https://yuanchaofa.com/llms-zero-to-hero/chaofa-wechat-official-account.png" alt="chaofa用代码打点酱油" loading="lazy"></li>
</ul>
</li>
<li><a href="https://space.bilibili.com/12420432" target="_blank" rel="noopener noreferrer">B站-chaofa用代码打点酱油</a></li>
<li><a href="https://www.youtube.com/@bbruceyuan" target="_blank" rel="noopener noreferrer">YouTube-chaofa用代码打点酱油</a></li>
<li><a href="https://chaofa.notion.site/11a569b3ecce49b2826d679f5e2fdb54" target="_blank" rel="noopener noreferrer">chaofa 的 notion 简介</a></li>
<li><a href="https://x.com/bbruceyuan" target="_blank" rel="noopener noreferrer">X(Twitter)-chaofa用代码打点酱油</a></li>
</ul>
<h2>附录</h2>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="footnote1" class="footnote-item"><p>大约在 21 年才关注到影视飓风，真的是一路看着他成功，以后他会更成功，真的是太羡慕了，无论是才华、认知、努力还是天生的精力。 <a href="#footnote-ref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="footnote2" class="footnote-item"><p>尽管 TIM 称自己并不是一个高能量的人，但是他所展现出来的精力，都是大多数人不可比拟的。在媒体前的表现自然会有一定的表演性质，但是只要能一直持续下去（10 年啊，人生能有几个十年），那就是常人难以企及的能量。 <a href="#footnote-ref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="footnote3" class="footnote-item"><p>我还是喜欢有温度一点的内容，不喜欢被当做数字，想要被认为是一个真正的观众，所以我永远喜欢那种真诚深度对话。备注：这个月和一个网友聊了个天还挺好的。 <a href="#footnote-ref3" class="footnote-backref">↩︎</a></p>
</li>
<li id="footnote4" class="footnote-item"><p>我的视频都特别的长，视频质量一定是远超 B 站同类视频，但是数据比较一般。我经常能在评论区有一些比较搞笑的对话，问我资料/问我代码（GitHub 链接/个人 Blog/公众号差点就怼脸上了），我有时候真的很想笑，
Google 搜一下「chaofa 用代码打点酱油」就这么难吗？ <a href="#footnote-ref4" class="footnote-backref">↩︎</a></p>
</li>
<li id="footnote5" class="footnote-item"><p>我这里并不是贬义，随着我思想的转变，我将自己也部分归类为「自媒体」，而以前我只愿意称自己为「<a href="https://yuanchaofa.com/blog/growth-strategies-for-ordinary-people-starting-from-scratch.html" target="_blank" rel="noopener noreferrer">公开表达</a>」。 <a href="#footnote-ref5" class="footnote-backref">↩︎</a></p>
</li>
<li id="footnote6" class="footnote-item"><p>备注：我觉得以 TIM的认知，他是不可能不能推测出自己家庭情况是比较有钱的，因为这东西很容易感受到，爸妈能陪你飞到国外去看看学校（校长？）一定不是 TIM 口中普通家庭可以做到的，至少不差，没 TIM 口中感受的那么差吧。 <a href="#footnote-ref6" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content:encoded>
      <enclosure url="https://cfcdn.yuanchaofa.com/blog/2025/20251102204745.webp" type="image/webp"/>
    </item>
    <item>
      <title>2025-09-合法赚钱就是高尚的（月度小结）</title>
      <link>https://yuanchaofa.com/blog/2025-09-month-summary.html</link>
      <guid>https://yuanchaofa.com/blog/2025-09-month-summary.html</guid>
      <source url="https://yuanchaofa.com/rss.xml">2025-09-合法赚钱就是高尚的（月度小结）</source>
      <description>孙宇晨的&amp;apos;合法赚钱的高尚性&amp;apos;理念，让我重新审视了自己对财富与价值的认知。本文分享我在公开表达创作与高压工作时的真实挣扎，以及如何在坚持初心与商业化之间寻找平衡，以及我对Q4人生与职业规划的坦诚反思。</description>
      <category>月度总结</category>
      <pubDate>Sat, 04 Oct 2025 22:18:00 GMT</pubDate>
      <content:encoded><![CDATA[<h2>合法赚钱的高尚性</h2>
<p>这个词还是来源于<a href="https://www.youtube.com/playlist?list=PLw3aceSTE5_VezUm4WNm6Xf_aPrWP7Fbj" target="_blank" rel="noopener noreferrer">孙宇晨的财富自由革命之路</a>，我真的被孙宇晨圈粉了，甚至可以说部分行为都受其影响。</p>
<p>我比较想提的一点是「<strong>合法赚钱的高尚性</strong>」，音频中提到大多数国人都有一个赚钱的羞耻心，当然我也有。首先需要科普一下什么叫做合法赚钱的高尚性。</p>
<ul>
<li>财富即贡献
<ul>
<li>在市场经济中，一个人能合法赚钱财富，本身意味着其产品或服务得到了市场广泛的认可，从而间接证明了对他人需求和社会的贡献。</li>
<li>依法交税本身对于社会就是一个重要贡献。很多企业家贡献了大量的税收，通过纳税、慈善和提供就业支撑起了部分社会的运转。</li>
<li>如果道理无法说服一个人，换一个地方交税本身就是最大的投票，这也就是所谓的"现实的教训比道德说教更有效"。</li>
</ul>
</li>
<li>财富即意味着个人自由
<ul>
<li>财富自由是实现人格独立自由的先决条件。财富可以让人摆脱为生存而做出的价值观妥协（如时间、注意力、情感甚至尊严），从而更纯粹地追求理想。</li>
<li>通过个人奋斗获得成功、突破阶层板结，是这个世界上最体面、最值得骄傲的事情</li>
<li>这也许是我们所有人毕生追求的目标，让自己的注意力分配到更有价值的事情上面，实现注意力自由。</li>
</ul>
</li>
</ul>
<p>我个人绝不是一个<a href="https://zh.wikipedia.org/zh-cn/%E7%A4%BE%E4%BC%9A%E8%BE%BE%E5%B0%94%E6%96%87%E4%B8%BB%E4%B9%89" target="_blank" rel="noopener noreferrer">社会达尔文主义</a>支持者，也不是优绩主义的支持者，但孙宇晨提出的合法赚钱是高尚的却击中了我。我们从小受到的教育是“只有不求汇报才是高尚的”，以至于很多人忽略了商业逻辑，只是一味的认为：</p>
<ul>
<li>满嘴谈钱是腐朽不堪的，那些企业家都是黑心的，不然赚不到那么多钱。</li>
<li>看轻赚钱的困难程度，认为只要我怎么样就可以赚到钱。</li>
</ul>
<p>而事实上要赚钱真的很难，无论是工作还是投资，都必须付出大量精力和努力才有可能有所回报。就以我自己做视频为例：一开始我是存粹的知识分享，但是后面无论是从频道未来发展，还是个人收益层面看，都需要有一定的商业化才能更健康可持续。</p>
<p>因此我个人思考逻辑也有了一定的变化，这里说两个比较好玩的例子：</p>
<h3>case 1: chaofa 做视频初衷变了吗？</h3>
<p>我在 25 年 5 月份的月度总结中提到<a href="https://yuanchaofa.com/blog/2025-05-month-summary.html#_2-%E9%87%91%E9%92%B1%E7%9A%84%E5%88%86%E9%87%8F" target="_blank" rel="noopener noreferrer">同样的金钱的有不同的分量</a>，那时候的我根本没想靠这个赚钱，说话非常的硬气，甚至前几天（2025-09-29）有一个粉丝朋友给我发消息说「我的文章有一些追求和人生理想」，我感动之余又变得有一丝惭愧。</p>
<p><img src="https://cfcdn.yuanchaofa.com/blog/2025/20251004224933.png" alt="image.png" loading="lazy"></p>
<p>原因是什么呢？</p>
<p>我最近两个视频都是广告，一个是显示器，一个是<a href="https://immersivetranslate.com/zh-Hans/" target="_blank" rel="noopener noreferrer">沉浸式翻译</a>。其中显示器广告是因为我想要换一个显示器，而沉浸式翻译虽然是我自己就想推荐的东西，说得也都是我自己想说的（甲方几乎没有任何要求），但在外人看人总归是不客观的。</p>
<p>但广告可能都是其次，核心原因是我在 Q3 期间几乎没有输入任何技术相关的内容，看起来我像是只是为了赚钱做视频。</p>
<p>出现这个问题的原因有很多：</p>
<ul>
<li>我听了孙宇晨的课程之后觉得我应该进行商业化
<ul>
<li>赚钱本身是很难的，只有尝试之后才知道要走通一次商业合作闭环才知道其他的艰难。</li>
<li>和我前面做课程付出的时间相比，这个收益虽然不值一提，但是这是我应得的合法回报。</li>
</ul>
</li>
<li>Q3 的工作实在是太忙了，根本没有时间学习输入，更不用说输出内容
<ul>
<li>7 月份我女儿出生，忙前忙后</li>
<li>8 9 月份因为项目太着急，经常出差，基本每天干到 12 点多<sup class="footnote-ref"><a href="#footnote1">[1]</a><a class="footnote-anchor" id="footnote-ref1"></a></sup><a class="footnote-anchor" id="footnote-ref1">。</a></li><a class="footnote-anchor" id="footnote-ref1">
</a></ul><a class="footnote-anchor" id="footnote-ref1">
</a></li><a class="footnote-anchor" id="footnote-ref1">
</a></ul><a class="footnote-anchor" id="footnote-ref1">
<p>回到小标题：chaofa 做视频的初衷变了吗？</p>
<p>我觉得答案是：<strong>暂时还没有变，但是等完成目标之后一定会变化的</strong>。</p>
<p>那么我做视频的初衷是什么呢？</p>
</a><p><a class="footnote-anchor" id="footnote-ref1">去年10 月份我刚开始做视频的时候，写了一篇文章</a><a href="https://yuanchaofa.com/blog/growth-strategies-for-ordinary-people-starting-from-scratch.html#_7-%E8%84%91%E5%AD%90%E9%87%8C%E9%9D%A2%E4%B8%8D%E8%A6%81%E5%8F%AA%E6%83%B3%E7%9D%80%E8%B5%9A%E9%92%B1%E7%9A%84%E4%BA%8B%E6%83%85" target="_blank" rel="noopener noreferrer">普通人从零开始做公开表达的增长策略</a>，提到，出发点主要有两个：</p>
<ul>
<li>满足自己的虚荣心
<ul>
<li>原文：做这些东西本质上是为了满足自己的虚荣心，得到他人的关注和肯定</li>
<li>例子：比如 llama_factory 的作者说我的文章写的不错，并且在要离职做事的时候主动提出要加我微信，这都是让我感到非常有成就的事情。</li>
</ul>
</li>
<li>表达能力的练习
<ul>
<li>原文: 我的目标是让更多人看到我，90% 的精力是工作，10% 写书，做视频是一种表达和总结练习。</li>
<li>例子：今年说话口癖少了一些，虽然现在还是不太好，但比以前好我已经很满足了。</li>
</ul>
</li>
</ul>
<p>所以说等我写完书<sup class="footnote-ref"><a href="#footnote2">[2]</a><a class="footnote-anchor" id="footnote-ref2"></a></sup><a class="footnote-anchor" id="footnote-ref2">之后，我一定会更多的考虑赚钱的事情，合法赚钱本身就是高尚的。这也是我听课之后思维的变化，所以孙宇晨真的牛逼，值得学习。</a></p><a class="footnote-anchor" id="footnote-ref2">
</a><h3><a class="footnote-anchor" id="footnote-ref2"></a><a class="header-anchor" href="#case-2-赚钱真的很难—粉丝上涨意味着收入增加吗"><span>case 2: 赚钱真的很难—粉丝上涨意味着收入增加吗？</span></a></h3>
<p>相对于工作，做自媒体肯定是不赚钱的，这也是我为什么在这个上面投入的时间非常的少，因此一定是工作为主，做视频依然要保持图一乐心态。</p>
<p>为什么我说赚钱很难？有两点</p>
<ul>
<li>专业性限制了视频传播性。现在公开表达的人越来越多，粉丝数量不代表播放数据，因此甲方不会因为视频的专业性就投放你，反而会因为数据或者报价 pass 你。</li>
<li>粉丝一样有「又怕兄弟苦、又怕兄弟开路虎」。因为大多粉丝朋友不知道中小 UP 真实收入，所以粉丝数上升之后，就会觉得 UP 赚钱了，只要视频有一点瑕疵可能就不点赞支持了。
<ul>
<li>这里可以说一下例子：我在 3k 粉丝的时候，还有不少人给我打赏（原来我还做了一个表达，大概有 3/400）；现在 30k 粉丝，就几乎没人给我打赏。（几乎可以说，粉丝上万之后，就没人打赏了）。</li>
</ul>
</li>
</ul>
<blockquote>
<p>2025 年，还有遍地黄金的机会吗？我想应该是没有了。</p>
</blockquote>
<h2>Q4 的规划</h2>
<ul>
<li>月度总结我会继续写下去的 （同步更新于<a href="https://yuanchaofa.com/llms-zero-to-hero/chaofa-wechat-official-account.png" target="_blank" rel="noopener noreferrer">公众号</a>））
<ul>
<li>虽然这些东西会让很多人很烦，如果有骚扰到可以屏蔽；但是我想说，我个人真的很爱看这些东西，比如
<ul>
<li>我今天（2025-10-04）刚发现的一个 UP 主——<a href="https://www.bilibili.com/video/BV1MphczLEhu/" target="_blank" rel="noopener noreferrer">久远寺千歳</a>，我把他所有总结视频都看了，我真的很佩服这种人。</li>
<li>还有我很喜欢的 blog 作者们——<a href="https://mp.weixin.qq.com/s/37J_0qqkXyIRYG4pPhRDDg" target="_blank" rel="noopener noreferrer">微扰理论</a>，<a href="https://hawstein.com/2023/07/12/five-years-of-an-indie-hacker/" target="_blank" rel="noopener noreferrer">hawstein</a>，以及各种心灵按摩类的播客，比如孟岩的<a href="https://www.xiaoyuzhoufm.com/podcast/611719d3cb0b82e1df0ad29e" target="_blank" rel="noopener noreferrer">无人知晓</a>、少楠的<a href="https://www.xiaoyuzhoufm.com/podcast/6034daea97755b8fc9c66480" target="_blank" rel="noopener noreferrer">奇想驿</a>、厚望的<a href="https://www.xiaoyuzhoufm.com/podcast/6388760f22567e8ea6ad070f" target="_blank" rel="noopener noreferrer">面基</a>等，当然还有很多很多...</li>
</ul>
</li>
<li>这些东西总能给我力量，我也想把生活、工作中的迷茫写下来，希望能把这种<a href="https://github.com/bbruceyuan/bbruceyuan.github.io/discussions/47#discussioncomment-14478259" target="_blank" rel="noopener noreferrer">力量传递下去</a>，所以我会继续写下去</li>
</ul>
</li>
</ul>
<p><img src="https://cfcdn.yuanchaofa.com/blog/2025/20251004225322.png" alt="image.png" loading="lazy"></p>
<ul>
<li>工作还要坚持努力干，但是 Q4 可预期的压力就很大了，以至于我写这篇 blog 的时候就感觉到非常的痛苦，我真的没有信心完成 Q4 定的 OKR。
<ul>
<li>但<a href="https://yuanchaofa.com/blog/2025-06-month-summary.html#_1-%E5%BF%B5%E5%A4%B4%E9%80%9A%E8%BE%BE" target="_blank" rel="noopener noreferrer">让人幸福的工作一定是存在的</a>，只是我们需要更多的思考</li>
<li>Q4 的 Chaofa 请一定「不要用战术上勤奋，掩盖战略上的懒惰」
<ul>
<li>I need more time to think about my life.</li>
</ul>
</li>
</ul>
</li>
<li>视频，也许会月更视频，「<a href="https://github.com/bbruceyuan/Hands-On-Large-Language-Models-CN" target="_blank" rel="noopener noreferrer">动手学习大模型</a>」的系列我还是会坚持更新完的。</li>
<li>写书，我要开始了。等我！</li>
</ul>
<h2>最后</h2>
<p>最后欢迎来探讨对世界的认知，基本全网同名 <a href="https://yuanchaofa.com/" target="_blank" rel="noopener noreferrer">chaofa用代码打点酱油</a> (推荐)</p>
<ul>
<li><a href="https://yuanchaofa.com/llms-zero-to-hero/chaofa-wechat-official-account.png" target="_blank" rel="noopener noreferrer">公众号-chaofa用代码打点酱油</a>
<ul>
<li><img src="https://yuanchaofa.com/llms-zero-to-hero/chaofa-wechat-official-account.png" alt="chaofa用代码打点酱油" loading="lazy"></li>
</ul>
</li>
<li><a href="https://space.bilibili.com/12420432" target="_blank" rel="noopener noreferrer">B站-chaofa用代码打点酱油</a></li>
<li><a href="https://www.youtube.com/@bbruceyuan" target="_blank" rel="noopener noreferrer">YouTube-chaofa用代码打点酱油</a></li>
<li><a href="https://chaofa.notion.site/11a569b3ecce49b2826d679f5e2fdb54" target="_blank" rel="noopener noreferrer">chaofa 的 notion 简介</a></li>
<li><a href="https://x.com/bbruceyuan" target="_blank" rel="noopener noreferrer">X(Twitter)-chaofa用代码打点酱油</a></li>
</ul>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="footnote1" class="footnote-item"><p>一般 10 点多下班后回家接着干到 12 点多，真的觉得干不完，压力很大。 <a href="#footnote-ref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="footnote2" class="footnote-item"><p>写书虽然不赚钱，但真的很酷，一直想有一本自己的出版物。 <a href="#footnote-ref2" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content:encoded>
      <enclosure url="https://cfcdn.yuanchaofa.com/blog/2025/20251004224933.png" type="image/png"/>
    </item>
    <item>
      <title>RAG 进化之路：传统 RAG 到工具与强化学习双轮驱动的 Agentic RAG</title>
      <link>https://yuanchaofa.com/post/from-native-rag-to-agentic-rag.html</link>
      <guid>https://yuanchaofa.com/post/from-native-rag-to-agentic-rag.html</guid>
      <source url="https://yuanchaofa.com/rss.xml">RAG 进化之路：传统 RAG 到工具与强化学习双轮驱动的 Agentic RAG</source>
      <description>本文深入剖析RAG技术的进化历程，从传统RAG到智能体RAG的全面升级。探索两种实现Agentic RAG的关键路径：提示工程+工具调用与强化学习驱动方法。通过解读企业级项目chatbox和Search-R1，揭示如何让大模型从&amp;quot;被动检索&amp;quot;转变为&amp;quot;主动决策&amp;quot;，实现更精准的知识获取与应用。无论你是AI研发工程师还是产品经理，这篇文章都将帮你理解RAG技术的未来发展方向，掌握构建更智能RAG系统的核心技术。</description>
      <category>hands-on-code</category>
      <pubDate>Fri, 03 Oct 2025 11:53:20 GMT</pubDate>
      <content:encoded><![CDATA[<h2>1. 阅读收获 (takeaway)</h2>
<p>本文旨在祛魅【Agentic RAG】的概念，因此本文的阅读收获包括：</p>
<ul>
<li>了解什么是传统 RAG（Native/Naive/Vanila RAG）</li>
<li>了解什么是 Agentic RAG
<ul>
<li>了解企业级项目 <a href="https://github.com/chatbox-ai/chatbox" target="_blank" rel="noopener noreferrer">chatbox</a> 的 Agentic RAG 架构和原理</li>
<li>了解如何使用强化学习训练 Agentic RAG （Search-R1）</li>
</ul>
</li>
<li>资源信息
<ul>
<li>源代码位于 Github -<a href="https://github.com/bbruceyuan/Hands-On-Large-Language-Models-CN/tree/master/chapter08" target="_blank" rel="noopener noreferrer">动手学习大模型-中文版-第八章——rag 源代码</a></li>
<li>视频解读位于 <a href="https://www.bilibili.com/video/BV1iLx6zRETu/" target="_blank" rel="noopener noreferrer">B 站</a> 和 <a href="https://youtu.be/6cuiF4Lodrs?si=e5HDOen8iliSvO89" target="_blank" rel="noopener noreferrer">YouTube</a>，包含更多个人观点类内容</li>
<li>文章同步更新于<a href="https://mp.weixin.qq.com/s/UN10QnJUrlB-Ehoi8-aOLg" target="_blank" rel="noopener noreferrer">公众号-chaofa 用代码打点酱油</a></li>
</ul>
</li>
</ul>
<h2>2. 前言</h2>
<p>如果说 2024 年，LLM（Large Language Model） 落地最广泛且最有实用价值的一项技术，那么我提名 RAG（Retrieval Augmented Generation) 应该不会有太多的反对。但 2025 年最火的概念变成 Agent，而 <strong>RAG 似乎变成了一个基础组件，提的不多却是融合到了 Agent 的日常使用中了</strong>，尤其是 <a href="https://openai.com/index/introducing-deep-research/" target="_blank" rel="noopener noreferrer">OpenAI DeepResearch</a> 的出现，让 Agentic RAG 成了 2025 年最成功的 RAG 应用之一。</p>
<p>但网络上有很多文章，把 Agentic RAG 说得玄乎，故意制造难懂的概念从而达到抬高自身的目的。但实际上我们只需要理清楚两个概念，就可以知道什么是 Agentic RAG。</p>
<ul>
<li>传统 RAG 是什么？
<ul>
<li>预先通过检索排序将知识放到 Prompt 中，然后利用 LLM 生成回复</li>
</ul>
</li>
<li>Agent 是什么？
<ul>
<li>使用具有自主决策能力的 Agent 实现的 RAG 系统就可以称为 Agentic RAG。
因此 <code>Agentic RAG</code> 实际上就是指在传统 RAG 基础上，加入了 Agent 组件的 RAG 系统，任何实现了 <code>Agentic Search</code> 能力的 RAG 系统都可以称为 <code>Agentic RAG</code>。</li>
</ul>
</li>
</ul>
<h2>3. 传统 RAG （Native RAG）</h2>
<p>传统的 RAG（Native RAG）并不是一个复杂的概念，核心概念就两个：检索（Retrieval）和生成（生成）。因此要做好 RAG 就是两件事情：</p>
<ul>
<li>怎么检索到更有用的知识？</li>
<li>怎么让模型更好的利用知识生成回复？</li>
</ul>
<p>因此 RAG 系统架构可以如下图所示：</p>
<p><img src="https://cfcdn.yuanchaofa.com/blog/2025/20251003193522.png" alt="image.png" loading="lazy"></p>
<p><code>NATIVE RAG</code>一般来说可以分成两个不同的链路：离线和在线。具体的代码可以参考：<a href="https://github.com/bbruceyuan/Hands-On-Large-Language-Models-CN/tree/master/chapter08" target="_blank" rel="noopener noreferrer">动手学习大模型-中文版-第八章-native-rag 源代码</a></p>
<div class="language-toml line-numbers-mode" data-highlighter="shiki" data-ext="toml" data-title="toml" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75">requires-python</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> = </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"&gt;=3.12"</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75">dependencies</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> = [</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">    "langchain&gt;=0.3.27"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">    "langchain-chroma&gt;=0.2.6"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">    "langchain-community&gt;=0.3.30"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">    "langchain-deepseek&gt;=0.1.4"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">    "langchain-openai&gt;=0.3.34"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">    "langgraph&gt;=0.6.8"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">]</span></span></code></pre>
<div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3>3.1 RAG 离线入库</h3>
<p>离线入库是指将文档处理成向量并存储到向量数据库中，以便后续检索使用。这个过程主要包括：文档加载、文本切分、向量化、存储。</p>
<div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> langchain_community.document_loaders </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> TextLoader</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> langchain.text_splitter </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> RecursiveCharacterTextSplitter</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> langchain_openai </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> OpenAIEmbeddings</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> langchain_chroma </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> Chroma</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># 1. 加载文档</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">loader </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF"> TextLoader</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"knowledge_base.txt"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">documents </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> loader.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF">load</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># 2. 文本切分</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">text_splitter </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF"> RecursiveCharacterTextSplitter</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    chunk_size</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">500</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># 每个文本块的大小</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    chunk_overlap</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">50</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># 文本块之间的重叠部分</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">splits </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> text_splitter.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF">split_documents</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(documents)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># 3. 向量化并存储</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">embeddings </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF"> OpenAIEmbeddings</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    base_url</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"https://api.siliconflow.cn/v1"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    model</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"Qwen/Qwen3-Embedding-0.6B"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">vectorstore </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> Chroma.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF">from_documents</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    documents</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">splits,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    embedding</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">embeddings,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    persist_directory</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"./chroma_db"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># 持久化存储路径</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2">print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"成功将 </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">{</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2">len</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(splits)</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379"> 个文本块存入向量数据库"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">)</span></span></code></pre>
<div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3>3.2 RAG 在线应用</h3>
<p>在线应用是指用户提问时，系统检索相关文档并生成回答的过程。主要包括：用户查询、检索相关文档、构建提示词、LLM 生成回答。</p>
<div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> langchain.embeddings </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> OpenAIEmbeddings</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> langchain.vectorstores </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> Chroma</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> langchain_openai </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> ChatOpenAI</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> langchain.prompts </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> PromptTemplate</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># 1. 加载已有的向量数据库</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">embeddings </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF"> OpenAIEmbeddings</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    base_url</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"https://api.siliconflow.cn/v1"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    model</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"Qwen/Qwen3-Embedding-0.6B"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">vectorstore </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF"> Chroma</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">persist_directory</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"./chroma_db"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">embedding_function</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">embeddings)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># 2. 用户提问</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">query </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379"> "什么是RAG？"</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># 3. 检索相关文档（返回最相关的 3 个）</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">docs </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> vectorstore.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF">similarity_search</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(query, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">k</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">3</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># 4. 将检索到的文档内容拼接成上下文</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">context </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379"> "</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2">\n\n</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF">join</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">([doc.page_content </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> doc </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> docs])</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># 5. 构建 Prompt 模板</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">prompt_template </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379"> """</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">你是一个专业的问答助手。请根据以下参考文档回答用户的问题。</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">如果参考文档中没有相关信息，请诚实地说不知道，不要编造答案。</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">参考文档：</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66">{context}</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">用户问题：</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">{question}</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">回答：</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"""</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">prompt </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF"> PromptTemplate</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    template</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">prompt_template,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    input_variables</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"context"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"question"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">],</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># 6. 创建 LLM 并生成回答</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">llm </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF"> ChatOpenAI</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    model</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"THUDM/glm-4-9b-chat"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    temperature</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    max_retries</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">3</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">    base_url</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"https://api.siliconflow.cn/v1"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">final_prompt </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> prompt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF">format</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">context</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">context, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic">question</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">query)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2">print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"最终的 Prompt 内容：</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">{</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">final_prompt</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">response </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF"> llm.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF">predict</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(final_prompt)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic"># 7. 输出结果</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2">print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"问题: </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">{</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">query</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2">print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"回答: </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">{</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">response</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2">print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD">f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2">\n</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">参考文档数量: </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">{</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2">len</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">(docs)</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66">}</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379">"</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF">)</span></span></code></pre>
<div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2>4. Agentic RAG</h2>
<h3>4.1 Native RAG 有哪些不够好的地方？</h3>
<ul>
<li>一次性流水线：通常“检索→拼接→生成”一步到位，没有让模型根据需要调整检索策略、递进式地钻研文档。</li>
<li>缺乏任务拆解：问题可能需要先定位文件、再选片段、再比对与总结；Native RAG 往往缺少这样的多步拆解能力。</li>
<li>工具编排不足：只会相似度检索，不会进一步查看文件元数据、选择需要阅读的 chunk，更不会在不够时换一种检索或补充查询。</li>
<li>证据利用浅：Top-K 拼接容易“糊”上下文，无法进行“先粗后细”的证据收集（coarse→fine），也不容易明确引用到具体片段。</li>
<li>适应性差：面对多跳问题（multi-hop）或信息不足的场景，通常不会回溯重试、改写查询、换路子继续找。</li>
</ul>
<h3>4.2 什么是 Agentic RAG？</h3>
<p><code>Agentic RAG</code>的核心“<strong>不是更复杂的模型</strong>”，而是“<strong>让模型学会做事</strong>”。和一次性把文档塞进 Prompt 就生成答案的 Native RAG 相比，Agentic RAG 让大模型扮演一个“决策-执行”的控制器：<strong>先制定策略，再调用工具逐步收集证据，最后基于证据作答并给出引用</strong>。</p>
<p>所以说：模型通过自主决策实现的 RAG 过程，我们就可以称之为 <code>Agentic RAG</code>。无论这个过程是发现在离线入库阶段（当然 Agentic RAG 其实可以不严格区分 offline/online 截断，都可以让 Agent 自主决策），还是 RAG 生成阶段的 <code>search query rewrite</code>，<code>rerank</code> 还是 <code>dynamic search</code>等，只要有模型的自主决策过程，那么就可以称为 <code>Agentic RAG</code>。具体的形式可以参考 Agentic RAG 流程图（将 search 能力变成一个工具，模型可以根据需要调用）：</p>
<p><img src="https://cfcdn.yuanchaofa.com/blog/2025/20251007132359.png" alt="image.png|700x264" loading="lazy"></p>
<ul>
<li>让 LLM 作为“智能体（Agent）”充当控制器，结合一组工具（检索、查看元数据、读取片段等）执行“思考→行动→观察”的循环（Reason–Act–Observe）。</li>
<li>在回答之前，按需多轮调用工具，逐步从“找到相关文件”走到“读取关键片段”，最后基于被读取的证据组织答案，并给出引用。</li>
</ul>
<blockquote>
<p>给模型更多的自主决策空间、配备合适的工具，LLM 会给你出乎意料的智能。
好处：更强的适应性（可改写查询/追加搜索）、更深的证据利用（读到再答）、更可归因（引用具体来源）。</p>
</blockquote>
<p>如果想了解更多的 <a href="https://chatboxai.app/" target="_blank" rel="noopener noreferrer"><code>Agentic RAG</code>的工业级别</a>的实现，我觉得可以参考「<a href="https://github.com/chatboxai/chatbox" target="_blank" rel="noopener noreferrer">开源项目 chatbox</a>」的实现，该项目是一个比较早的 LLM Chat 集成的项目，并且算是比较早的实现了 <code>Agentic RAG</code>。因为作为一个离线的 LLM chat 项目，对于时延等问题可以有更少的考虑，从而<strong>更激进的、更早阶段将 naive chat 变成 Agentic Chat</strong>。</p>
<h3>4.3 基于提示词和工具的 Agentic RAG</h3>
<p>ReAct 是一个常见的 Agent 实现方式，因此只要给 LLM 配备合适的 <code>Tool</code>以及适当的引导 <code>Prompt</code>，就可以将一个 <code>Native RAG</code> 转换成 <code>Agentic RAG</code>。这里我通过解读 <code>36.8k star</code>开源企业级项目——<a href="https://github.com/chatboxai/chatbox" target="_blank" rel="noopener noreferrer">chatbox</a>来讲解一个 Agentic RAG 是怎么实现的，以及为什么它在复杂场景下效果好[^1]。</p>
<p>下面是 <code>Chatbox</code> 的整体流程图，可以分为两个部分，左半部分是 <code>Agentic RAG</code>，右半部分是介于 <code>Native RAG</code> 到 <code>Agentic RAG</code>之间的 <code>Native RAG</code>。</p>
<p><img src="https://cfcdn.yuanchaofa.com/blog/2025/20251003192952.png" alt="image.png|700x889" loading="lazy"></p>
<p>因此我们重点来解读 <code>chatbox</code> 到底是怎么<a href="https://github.com/chatboxai/chatbox/blob/9e33c9f998ebf240f31bbb439a430b4d5e5bd3e0/src/renderer/packages/knowledge-base/tools.ts#L78" target="_blank" rel="noopener noreferrer">设置工具</a>，来实现更好的 <code>Agentic Search</code>，然后再给出最小示例代码：</p>
<blockquote>
<p>包括 Anthropic 的 context engineering 文章中也提到了<code>Agentic Seach</code> 对于 Agent 应用是非常重要的。</p>
</blockquote>
<ul>
<li><code>query_knowledge_base</code>
<ul>
<li>在知识库中进行语义搜索，快速找到候选文件或片段的“线索”。通常作为最基础的检索工具</li>
</ul>
</li>
<li><code>get_files_meta</code>
<ul>
<li>查看候选文件的元信息（如文件名、大小、chunk 数量），帮助模型决定“读哪几个文件的哪部分”。</li>
</ul>
</li>
<li><code>read_file_chunks</code>
<ul>
<li>按文件 <code>ID + chunkIndex</code> 精读具体片段，用于“取证”。建议一次只读少量最相关的 <code>chunk</code>，以降低噪声。</li>
</ul>
</li>
<li><code>list_files</code>
<ul>
<li>列出知识库中的文件清单，作为兜底浏览或当搜索线索不充分时的探索手段。</li>
</ul>
</li>
</ul>
<h4>4.3.1 Agentic RAG 样例</h4>
<p>这里我想通过一个例子让读者理解什么是 <code>Agentic RAG</code>。</p>
]]></content:encoded>
      <enclosure url="https://cfcdn.yuanchaofa.com/blog/2025/20251003193522.png" type="image/png"/>
    </item>
    <item>
      <title>2025-08-孙宇晨真的很值得学习（八月小结）</title>
      <link>https://yuanchaofa.com/blog/2025-08-month-summary.html</link>
      <guid>https://yuanchaofa.com/blog/2025-08-month-summary.html</guid>
      <source url="https://yuanchaofa.com/rss.xml">2025-08-孙宇晨真的很值得学习（八月小结）</source>
      <description>通过学习孙宇晨十年前的课程，我深刻反思了个人成长与认知差距。文章记录了我在高强度工作压力下，于“努力奋斗”与“渴望躺平”之间的挣扎，以及一次与同事的谈话后，对职场规则和未来职业道路产生的全新思考与迷茫。</description>
      <category>月度总结</category>
      <pubDate>Wed, 10 Sep 2025 22:18:00 GMT</pubDate>
      <content:encoded><![CDATA[<h2>白日做梦</h2>
<p>最近在听<a href="https://zh.wikipedia.org/zh-cn/%E5%AD%99%E5%AE%87%E6%99%A8" target="_blank" rel="noopener noreferrer">孙宇晨</a> 2015 年在喜马拉雅的音频课程——<a href="https://www.youtube.com/playlist?list=PLw3aceSTE5_VezUm4WNm6Xf_aPrWP7Fbj" target="_blank" rel="noopener noreferrer">财富自由革命之路</a>，我只想尊称一声（孙哥，绝不是孙割）。这里并不是说里面的课程思考在今天有多超前，而是放在十年前，孙宇晨能有这样的认知真的是太牛了，课程中展现出来的孙哥的能力我觉得有太多地方值得学习了。录课的他 25 岁，听课的我 30 岁，我觉得差距好遥远。</p>
<p>为什么我突然去听这样一个课程，一个很重要的原因是觉得工作好累，我觉得保持现在这样的状态太难太难了，很想一夜暴富，毕竟 X 圈充满了暴富神话，虽然我不参与，但是看别人暴富也能过过瘾，所以不小心点进去看了眼，然后被孙哥的才华吸引了，很需要学习这种乐观向上、持续学习、积极行动的态度，但又在「要努力」和「想躺平」之间反复横跳。</p>
<h2>我的工作</h2>
<p>最近两个月（till 2025-09-10），也许是我自工作以来最忙的时间。这里有很多原因带来的，外部、内部都有，导致我陷入了一个非常紧急的项目中，加班不计其数，内部 CodeBase 代码提交都发黑了（对应 GitHub 的清清白白<sup class="footnote-ref"><a href="#footnote1">[1]</a><a class="footnote-anchor" id="footnote-ref1"></a></sup><a class="footnote-anchor" id="footnote-ref1">），压力真的好大。</a></p><a class="footnote-anchor" id="footnote-ref1">
<p><img src="https://cfcdn.yuanchaofa.com/blog/2025/20250910235326.png" alt="image.png|700x188" loading="lazy"></p>
</a><p><a class="footnote-anchor" id="footnote-ref1">这段时间的工作让我真的意识到我可能真的不应该羡慕别人的高薪，很多同事真的挺拼的，积极有能量<sup class="footnote-ref"></sup></a><a href="#footnote2">[2]</a><a class="footnote-anchor" id="footnote-ref2">，而我持续一段时间就觉得要发疯，必须得要休息。普通人能控制的其实只有自己的努力，大多数获得不错成就的人，工作其实还是挺努力的（当然其实也包括我，只是我还没混出什么东西），然后鉴于我根本没有办法持续保持努力，我觉得我应该改变思想，不去羡慕别人的高薪和成就，我真的好像躺平啊，就等着有一天被 35 岁优化<sup class="footnote-ref"></sup></a><a href="#footnote3">[3]</a><a class="footnote-anchor" id="footnote-ref3">吧。</a></p><a class="footnote-anchor" id="footnote-ref3">
</a><h2><a class="footnote-anchor" id="footnote-ref3"></a><a class="header-anchor" href="#我的职场第一课"><span>我的职场第一课</span></a></h2>
<p>在封闭开发结束后，本以为是迫不及待想要回家带娃，却没成想错过了飞机✈️，以至于和一个产品同学一起在机场逗留了两个小时。在聊天的过程中，我发现我们的工作可能玩的不是同一个游戏，这里的游戏指的是职场规则。</p>
<p>所谓的两个游戏本质上是来自于评价体系的多元化。自学校毕业之后，社会再也不是单一维度指标（分数高？），尤其在工作中，就以绩效评价为例：大家做得事情都不一样，业务产出也很难说有同一个标准，所以造就了【行为上努力干】-&gt;【产出上干得好】-&gt;【最终收获上结果好】 并不是一个线性过程。尽管早有预期，但真听完之后还是有不小的震撼。</p>
<p>首先讲讲我以前是什么状态。我一直以来都是一个还不错的执行者，领导安排的任务我能干得不错，但和领导的沟通却很少；此外在 3 - 7 月期间，作为 Agent 方向负责同学协作几个同学一起做项目，但总觉得自己在项目排期上做得非常不好。因此整体上我是一个还不错独立贡献者，但想要真的在职场上有发展可能性不大。</p>
<p>产品同学和我聊了很多，我听到的很多关键词都是 XXX，YYY，ZZZ 等，这些 XXX 是一些大佬的人名，而我几乎都没有听过，产品整合资源做事情能力确实强。尤其是讲一些关系的时候，工作方式和行为，我就像是在听小说一样津津有味，但同时让我对职场道路更加悲观，感觉低职级搞技术的关系都太 NAIVE，还有太多东西要学习。（其实我还听佩服这个同学的，我比较佩服能出：“我觉得有意思的让我加班也行”的人，有机会其实还可以再听一次）</p>
<h2>其他</h2>
<p>怎么这次写得乱七八糟，感觉最近加班把脑子加坏了。甚至到了今天（教师节）我又久违的心脏刺痛了一下，我觉得有点慌了，想着早点走回家睡觉，但拖着拖着发现已经可以公司报销打车了。</p>
<blockquote>
<p>本文后续也会更新于 <a href="https://mp.weixin.qq.com/s/JAc2EiobA36ewbYguPJMWA" target="_blank" rel="noopener noreferrer">公众号-chaofa 用代码打点酱油</a></p>
<p>这次没时间 blog 提交了，回家半小时随便写了一篇糊弄下</p>
</blockquote>
<h2>附录</h2>
<h2>最后</h2>
<p>最后欢迎来探讨对世界的认知，基本全网同名 <a href="https://yuanchaofa.com/" target="_blank" rel="noopener noreferrer">chaofa用代码打点酱油</a> (推荐)</p>
<ul>
<li><a href="https://yuanchaofa.com/llms-zero-to-hero/chaofa-wechat-official-account.png" target="_blank" rel="noopener noreferrer">公众号-chaofa用代码打点酱油</a>
<ul>
<li><img src="https://yuanchaofa.com/llms-zero-to-hero/chaofa-wechat-official-account.png" alt="chaofa用代码打点酱油" loading="lazy"></li>
</ul>
</li>
<li><a href="https://space.bilibili.com/12420432" target="_blank" rel="noopener noreferrer">B站-chaofa用代码打点酱油</a></li>
<li><a href="https://www.youtube.com/@bbruceyuan" target="_blank" rel="noopener noreferrer">YouTube-chaofa用代码打点酱油</a></li>
<li><a href="https://chaofa.notion.site/11a569b3ecce49b2826d679f5e2fdb54" target="_blank" rel="noopener noreferrer">chaofa 的 notion 简介</a></li>
<li><a href="https://x.com/bbruceyuan" target="_blank" rel="noopener noreferrer">X(Twitter)-chaofa用代码打点酱油</a></li>
</ul>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="footnote1" class="footnote-item"><p>大多数 GitHub 的绿色都是 blog 的错误提交带来的，包括八月那个 <a href="#footnote-ref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="footnote2" class="footnote-item"><p>其实也有不少人和我讲，看我就是这样。但我其实真的好疲惫，累的不行 <a href="#footnote-ref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="footnote3" class="footnote-item"><p>人一旦停止输入学习就接近 35 岁了，这并不是一个客观年龄，而是和精神状态、能量、好奇心有关 <a href="#footnote-ref3" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content:encoded>
      <enclosure url="https://cfcdn.yuanchaofa.com/blog/2025/20250910235326.png" type="image/png"/>
    </item>
    <item>
      <title>2025-07-忙碌与充实的七月（月度小结）</title>
      <link>https://yuanchaofa.com/blog/2025-07-month-summary.html</link>
      <guid>https://yuanchaofa.com/blog/2025-07-month-summary.html</guid>
      <source url="https://yuanchaofa.com/rss.xml">2025-07-忙碌与充实的七月（月度小结）</source>
      <description>2025年7月月度总结，记录新生命的诞生、工作项目突破、投资回本与内容创作的思考。分享大模型Agent落地经验、平台化视角与自我成长感悟，助你发现</description>
      <category>月度总结</category>
      <pubDate>Sun, 10 Aug 2025 22:18:00 GMT</pubDate>
      <content:encoded><![CDATA[<h2>1. 总结</h2>
<p>7 月是今年来做忙的一个月，也是今年来最开心的一个月。</p>
<ul>
<li>最重要的是，我的女儿「袁乎乎」这个月出生了</li>
<li>然后是，工作项目也终于有了正向收益</li>
<li>再其次是，5 年后炒股终于回本了</li>
<li>最后是，<a href="https://space.bilibili.com/12420432" target="_blank" rel="noopener noreferrer">B 站的频道——chaofa 用代码打点酱油</a>也开启了首次的硬广商业化</li>
</ul>
<p>似乎所有的事情都在往上走，所以我很喜欢这个七月，哪怕是很忙碌，但我依然希望这个 7 月会更长一点。</p>
<h2>2. 袁乎乎首次与世界打招呼</h2>
<p>也许是两年前，我们就已经确定了孩子的小名，如果是男孩就是「袁滚滚」，如果是女孩就是「袁乎乎」，但是出生前一天就感觉很慌，男孩的大名还没有完全想好呢？但开门后，助产师迎接我的第一句话让我松了一口气，「是个女孩」，这意味着不用再考虑名字的事情了。</p>
<p><img src="https://cfcdn.yuanchaofa.com/blog/2025/1754838732930.webp" alt="1754838732930" loading="lazy"></p>
<p>整个产程不算慢，一共十个半小时，但是对于<strong>不能打无痛的点点</strong>就比较漫长了，点点从一开始和我欢声笑语，慢慢就只有自己咬破的嘴唇。看得我总是于心不忍，多次叫医生剖腹产，但点点总是抓着我的手拒绝，可能对她来说，最好的镇痛剂是我手上被抓的“荣誉勋章”，最后在点点的坚持下顺利顺产。（真的很不容易，包括后面哺乳吸奶的过程也非常的艰难，当爸爸的就显得轻松多了）</p>
<h2>3. 工作——柳暗花明</h2>
<p>从 2 月独自负责 Agent 项目以来，一个一直困扰我的事情是：总有人问我，那个【A 项目】为什么一直是 AB 实验负 10 个点。这个 A 项目说简单简单，半小时可以写一个 ReAct Agent Demo，但是说难也很难，从调试 Prompt 到工具建设，到换方向做 2.0 版本，一直到六月份都没有取得正向的实验收益。</p>
<p>期间已经有其他很多的 B/C/D 项目都落地上线取得了不错的收益，但由于【A 项目】启动早，因此老板们一直就在关心【A 项目】为什么没有收益，后面怎么办？我为此感到很焦虑，文档中甚至已经创建了【A 项目无收益复盘】。但由于老板们真的很关心这个项目，不得不硬着头皮做下去，无数次改 Prompt，简化执行流程，最终在 6/7 月实验中取得正向收益，幸好最终结果还不错，也有种老父亲的孩子终于成才的感觉。</p>
<p>这期间，我一直不变的看法是：<a href="https://yuanchaofa.com/blog/2025-03-month-summary.html#_4-%E5%B7%A5%E4%BD%9C" target="_blank" rel="noopener noreferrer">Agent 远没有预期的强大</a>，但是又远比预期的强大，因此我们应该多多尝试。此外，这次项目让我意识到了，产品驱动的项目其实也不一定要按照产品的想法走，业务团队还是收益为主，所谓的落地方式真不值一提。</p>
<h2>4. 炒股 5 年本金终于回来了</h2>
<p>在硕士还没毕业的时候，我就开始偶尔买买股票，想通过这种方式暴富，但是越发有这种念头，我的收益率越低。反而我放弃炒股，走定投路线之后，才慢慢把本金挣回来。</p>
<p><img src="https://cfcdn.yuanchaofa.com/blog/2025/1754840545285.webp" alt="1754840545285" loading="lazy"></p>
<p>虽然到 8 月这个时间点，我依然是负收益，但我已经不慌了，我知道一切都会回来的。持续的工作，持续的现金流才是最重要的，其他所有东西都只是辅助，工作才是最重要的，只有工作才能做到真正的持续投入，这样不管在什么行情中，才更容易拿得住。</p>
<h2>5. 视频商业化</h2>
<p>作为一个一直用爱发电的 B 站 UP 主，在 B 站和 GitHub 中做了大量的免费视频教程，期间也想过一些商业化的方式，但无论哪种方式，都是没有办法办法达到我的预期，因此慢慢觉得无法持续下去。</p>
<p>我和朋友说，现在做视频我感觉没啥意思，别人再来夸一句”UP 主视频做得真好啊“，<a href="https://www.xiaoyuzhoufm.com/episode/68024e35cdd692da1536e57f" target="_blank" rel="noopener noreferrer">似乎对我的成就感已经小了很多</a>，然后又几乎没有金钱的激励，工作事情和家庭的事情也变得越来越多，在周末做视频这件事情变得难以为继。所以开始尝试了第一次的<a href="https://www.bilibili.com/video/BV1fN4dz6Ey5/" target="_blank" rel="noopener noreferrer">硬广商业化</a>，但是不得不说，结果上这个视频做得很失败，我花了有史以来最长的剪辑，最长的准备周期（几乎两个周末的时间），但是效果上我自己也不够满意，而且内容没啥可沉淀的价值。</p>
<p>我追求的是：可持续、对他人有价值的内容，别人愿意二次观看的内容。就像苏神的 blog 一样，不会说看完一次就不可能再看第二遍了，好的东西都是具有很高的长尾价值的，但显然硬广不是的，所以以后会尽量少做这种尝试。还是希望能在做自己想要的内容上深耕，先提升自己才是关键。</p>
<blockquote>
<p>本次视频对我最大的帮助就是让我真正开始剪辑，以前视频的剪辑一般不超过 15 分钟。</p>
</blockquote>
<h2>6. 未来的规划</h2>
<p>工作第一，工作占据生活大多数的时间，我们只能尽可能的在工作去做自己喜欢的事情，这样才不至于在工作中感到痛苦。（最近和一个产品聊天感觉她就很有热情，这种状态我真的羡慕和佩服）我想要做有意思的事情，一点一点的往那个方向走，也许就能找到契合自己的位置。</p>
<p>持续做公开表达，从做视频第一天开始，我的目标也只是锻炼自己的口头表达。这里想再给自己打个鸡血，虽然这东西不赚钱，但是赚的成就感早就超过金钱本身了。一个你愿意对外表露的身份难道还不够吗？</p>
<p>开始写一本书，这是在视频之前就有想过的，尽管商业价值很低很低，但是心里价值巨高无敌。我想要做体系化有价值的东西，而不是流量的奴隶。💪</p>
<h2>7. 其他</h2>
<p><img src="https://cfcdn.yuanchaofa.com/blog/2025/1754841911729.webp" alt="1754841911729" loading="lazy"></p>
<p>从 GitHub 提交可以看出最近的周末完全没时间自己学习，不管是 blog 还是 code，后面会好起来吧？想多多混迹开源，搞点有意思的东西，比如 RL-Zero-to-Hero？尽请期待吧</p>
<p>最后欢迎来探讨对世界的认知，基本全网同名 <a href="https://yuanchaofa.com/" target="_blank" rel="noopener noreferrer">chaofa用代码打点酱油</a> (推荐)</p>
<ul>
<li><a href="https://yuanchaofa.com/llms-zero-to-hero/chaofa-wechat-official-account.png" target="_blank" rel="noopener noreferrer">公众号-chaofa用代码打点酱油</a>
<ul>
<li><img src="https://yuanchaofa.com/llms-zero-to-hero/chaofa-wechat-official-account.png" alt="chaofa用代码打点酱油" loading="lazy"></li>
</ul>
</li>
<li><a href="https://space.bilibili.com/12420432" target="_blank" rel="noopener noreferrer">B站-chaofa用代码打点酱油</a></li>
<li><a href="https://www.youtube.com/@bbruceyuan" target="_blank" rel="noopener noreferrer">YouTube-chaofa用代码打点酱油</a></li>
<li><a href="https://chaofa.notion.site/11a569b3ecce49b2826d679f5e2fdb54" target="_blank" rel="noopener noreferrer">chaofa 的 notion 简介</a></li>
<li><a href="https://x.com/bbruceyuan" target="_blank" rel="noopener noreferrer">X(Twitter)-chaofa用代码打点酱油</a></li>
</ul>
]]></content:encoded>
      <enclosure url="https://cfcdn.yuanchaofa.com/blog/2025/1754838732930.webp" type="image/webp"/>
    </item>
    <item>
      <title>Gemini 2.5 Pro 是怎么炼成的？-- gemini 2.5 技术报告阅读笔记与思考</title>
      <link>https://yuanchaofa.com/post/gemini-2.5-tech-report-reading-note.html</link>
      <guid>https://yuanchaofa.com/post/gemini-2.5-tech-report-reading-note.html</guid>
      <source url="https://yuanchaofa.com/rss.xml">Gemini 2.5 Pro 是怎么炼成的？-- gemini 2.5 技术报告阅读笔记与思考</source>
      <description>深入解读 Gemini 2.5 技术报告，分析多模态、长上下文与思考能力等核心突破，结合个人理解与行业趋势，快速掌握最新大模型技术发展。</description>
      <category>paper-reading</category>
      <pubDate>Sun, 13 Jul 2025 19:20:20 GMT</pubDate>
      <content:encoded><![CDATA[<h2>1. 收获（takeaway）</h2>
<p>Gemini 的技术报告看上去比其他家的都小气一些，透露的细节非常的少，但是从行文来看，Gemini 2.5 Pro 成功的点主要有三个</p>
<ul>
<li>多模态，其他的模型多模态能力或多或少都有所欠缺，只有 Gemini 2.5 这种模型才能有长视频的理解能力。</li>
<li>LongContext，我理解可能是在强劲的基础架构下大力出奇迹的结果。</li>
<li>思考能力，Thinking is All you Need. This is very suitable for Agent.</li>
</ul>
<h2>2. 模型结构、训练和数据</h2>
<h3>2.1 模型结构（Model Architecture）与长下文能力</h3>
<p>2.5 系列的模型是基于 MoE 的 Transformers 模型，具体做法是：每一个 token 都会动态路由到某一个 Expert 中，这种方法叫做 Sparse MoE，具体实现可以参考；<a href="https://yuanchaofa.com/llms-zero-to-hero/the-way-of-moe-model-evolution.html" target="_blank" rel="noopener noreferrer">LLM MOE的进化之路，从普通简化 MOE，到 sparse moe，再到 deepseek 使用的 share_expert sparse moe</a>。</p>
<p>文中提到模型架构的修改对于 Gemini 2.5 效果的提升具有重要的作用，加上 Google 在预训练稳定性、动态优化等技术让最终效果比上一代有巨大的提升。</p>
<p>此外，关于模型的长下文能力（long-context）并没有提到是怎么训练的（比如RoPE 做位置编码，用 YaRN，NTK 等方法做上下文扩展)，但是有一个非常重要的细节，<strong>训练数据的上下文长度就已经达到了 1M</strong>，也就是说有可能 Google 的 LongContext 能力就是硬训练出来的。这里说一下 chaofa 个人的猜测，这里可能用到了很多 Long-Video，Long-Audio 等多模型相关的数据来提升模型的 Long-Context 能力。</p>
<p>下图是一个成本曲线和能力曲线，在相同成本下 Gemini2.5 Pro 效果很好，另外非常出彩的一点是，Gemini 2.5 flash 成本非常的便宜。</p>
<p><img src="https://cfcdn.bruceyuan.com/blog/2025/gemini-tech-report-readding-notes-1752401580682.webp" alt="gemini-tech-report-readding-notes-1752401580682.webp" loading="lazy"></p>
<blockquote>
<p>gemini 2.5 开发去重验证集的污染主要通过 n-gram 方式，辅助用语义相似性和模型过滤验证集数据。</p>
</blockquote>
<h3>2.2 预训练（Pre-Training）</h3>
<p>预训练数据集是一个大规模、多样化的数据集合，涵盖广泛的领域和模态，包括公开的网页文档、代码（多种编程语言）、图像、音频（包括语音和其他类型音频）以及视频，其中2.0版本的数据截止日期为2024年6月，2.5版本为2025年1月。和上一代相比，提升了「质量过滤、去重」的能力。</p>
<blockquote>
<p>除了多模态这一点，说实话等于什么也没说🤔</p>
</blockquote>
<h3>2.3 后训练（Post-Training）</h3>
<p>PostTraining 训练数据包含包含多模态数据的集合，配有成对的指令和响应，此外还包括人类偏好和工具使用数据。所以这是现在大模型天然就是一个 Agentic Model。</p>
<p>自Gemini 1.5 首次发布以来，在监督微调（SFT）、奖励建模（RM）和强化学习（RL）各个阶段持续关注数据质量的推动下，后训练方法方面取得了重大进展。<strong>一个关键的重点是利用模型本身协助这些过程，从而实现更高效且细致的质量控制</strong>（重点的事情说三遍，自己原有模型做质量过滤、合成等）。</p>
<p>此外，还增加了用于强化学习的训练算力，使得对模型行为的深入探索和优化成为可能。这一改进结合了<strong>可验证奖励和<a href="https://yuanchaofa.com/post/deepseek-grm-paper-reading-notes.html" target="_blank" rel="noopener noreferrer">基于模型的生成奖励</a></strong> 的应用，提供了更复杂且可扩展的反馈信号。同时，对强化学习流程的算法调整也提升了长时间训练的稳定性。这些进步使 Gemini 2.5 能够从更加多样和复杂的强化学习环境中进行学习，包括那些需要<strong>多步骤操作和工具使用的环境</strong>。</p>
<h3>2.4 模型思考能力</h3>
<p><img src="https://cfcdn.bruceyuan.com/blog/2025/gemini-tech-report-readding-notes-1752402585776.webp" alt="gemini-tech-report-readding-notes-1752402585776.webp" loading="lazy"></p>
<p>从上图可以先得出一个结论，有 Thinking 比没有更好，2.5 的<a href="https://yuanchaofa.com/post/slow-fast-thinking-from-qwen3-thinking-mixed-to-adacot-to-adathinking.html" target="_blank" rel="noopener noreferrer">动态 Thinking</a> 效果更好，这里的动态思考的提升不仅仅是来自于动态思考本身，还有数据质量的提升，以及更多领域上的思考训练，而不仅仅是数学代码等领域。</p>
<p>思维能力可以和 Gemini 其他功能进行整合，包括原生多模态输入（图像、文本、视频、音频）和 Long-Context（超过100万个token）。对于这些功能中的任何一个，模型会自行决定在给出答案之前需要思考多长时间。我们还提供了设置思维预算的能力，限制模型在指定的token数量内作出回应。如下图所示，增加这一预算可以使模型提升其性能，并显著提高准确率。</p>
<p><img src="https://cfcdn.bruceyuan.com/blog/2025/gemini-tech-report-readding-notes-1752402901438.webp" alt="gemini-tech-report-readding-notes-1752402901438.webp" loading="lazy"></p>
<h3>2.5 其他特定能力的提升</h3>
<p>从论文的描述看，这里的提升原来于两个方面；</p>
<ul>
<li>配备合适的数据和工具</li>
<li>提供更有指导的优化目标（类似于 Shunyu Yao 提出的 <a href="https://ysymyth.github.io/The-Second-Half/" target="_blank" rel="noopener noreferrer">The Second Half</a>）</li>
</ul>
<h4>代码（Code）</h4>
<p>可能是看到 Claude 成功，Google 战略性的改变，也就是需要提升模型 Code 能力。自 Gemini 1.5 以来，gemini 在预训练和后续训练阶段都进行了协同努力。</p>
<p>在预训练方面，加强了从代码仓库和网络来源中纳入<strong>更大数量和更多样化代码数据</strong>的力度，<strong>「从而迅速扩展了覆盖范围」</strong>，并推动了更高效计算模型的发展。此外，gemini 还大幅增强了用于评估与下游应用场景相匹配代码能力的评测指标体系，同时提升了准确预测模型性能的能力。</p>
<p>在后续训练阶段，开发了融合推理能力的全新训练技术，并精心挑选了一组多样化的工程任务，旨在为 Gemini 配备解决现代工程挑战所必需的高效问题解决技能。展现这些进步的关键应用包括 IDE 功能、针对完整代码仓库中复杂多步骤操作的代码代理用例，以及端到端网页和移动应用开发等多模态交互场景。</p>
<blockquote>
<p>核心观点是：更贴近实际开发的训练数据和目标。</p>
</blockquote>
<h4>事实性（Factuality）</h4>
<p>增强模型的世界知识及其根据提示中提供的上下文内容进行忠实回答的能力，为了满足这些新需求，Gemini 2.0 实现了重大突破，成为我们首个原生集成工具调用能力的模型家族，例如可直接调用Google Search，从而能够构造精准的查询语句，并结合最新信息与来源进行综合回答。在此基础上，Gemini 2.5进一步融合了高级推理能力，使其能够在内部思维过程与搜索功能之间灵活切换，以应对复杂的多跳查询并执行长期任务。该模型已掌握使用搜索及其他工具的方法，能对工具输出进行推理，并提出进一步、详细的后续查询，以扩展可用信息并验证回答的事实准确性。</p>
<blockquote>
<p>内在的 Search Tool 调用能力，能够切换内在思考与搜索工具。</p>
</blockquote>
<h4>长上下文 (LongContext)</h4>
<p>建模和数据方面的进展帮助我们提升了模型在使用百万级上下文窗口时对查询的响应质量，同时我们也重新设计了内部评估体系，使其更具挑战性，以更好地指导建模研究方向。在优化过程中，我们将目标设定为具有挑战性的检索任务（如LOFT，Lee等人，2024）、长上下文推理任务（如MRCR-V2，Vodrahalli等人，2024）以及多模态任务（如VideoMME，Fu等人，2025）。根据表6中的结果，新的2.5版本模型相比之前的Gemini 1.5模型实现了显著提升，并在所有这些任务上达到了业界领先水平。其中一个展示视频回忆能力提升的示例可以体现这些进步。</p>
<h4>多语言能力（Multilinguality）</h4>
<p>对预训练和微调数据质量的精细优化、分词技术的提升、核心建模方法的创新以及有针对性的能力迭代优化。改进效果在印度语系以及中日韩语系中尤为显著，这些语言通过数据质量和评估方面的专项优化，实现了质量和解码速度的大幅提升。因此，用户能够享受到更出色的语言适配性，即输出内容更加忠实于所请求的目标语言，同时在多种语言中的生成质量和事实准确性也得到了有力增强，进一步巩固了 Gemini 在多样语言环境下的可靠性。</p>
<h4>音频（Audio）</h4>
<p>Gemini 1.5 主要专注于原生音频理解任务，如转录、翻译、摘要和问答，而在 Gemini 2.5 中，模型进一步具备了音频生成能力，例如文本到语音合成，以及从原生音视频中生成对话音频。为了实现低延迟的流式对话，我们引入了因果音频表示方法，使得音频可以以流式方式输入和输出 Gemini 2.5。这些能力得益于覆盖超过 200 种语言的大量预训练数据，以及更优化的后训练方法。最终，通过改进后的后训练流程，我们将思考能力、情感对话、情境感知和工具使用等高级功能集成到了 Gemini 的原生音频模型中。</p>
<h4>视频（Video）</h4>
<p>大幅扩展了预训练和后训练阶段的视频理解数据，从而提升了模型对音视频内容及时间维度的理解能力。同时优化了模型训练，使其每帧仅需使用 66 个视觉标记，而非原有的 258 个，使得在1M标记上下文窗口中可处理约3小时的视频内容，而不是原来的1小时。这些改进催生了两项此前无法实现的新应用：一是从视频中创建交互式应用程序（例如用于测试学生对视频内容理解的小测验），二是生成p5.js动画以展示视频中的关键概念。</p>
<h4>Agent（Deep Research）</h4>
<p>Gemini Deep Research是一个基于Gemini 2.5 Pro模型构建的智能体，旨在战略性地浏览网络，为即使是最细分的用户查询提供有依据的回答。该智能体经过优化，能够进行任务优先级排序，并能在浏览过程中识别何时已进入死胡同。</p>
<h2>3. 其他</h2>
<p>最后欢迎来探讨对世界的认知，基本全网同名 <a href="https://yuanchaofa.com/" target="_blank" rel="noopener noreferrer">chaofa用代码打点酱油</a> (推荐)</p>
<ul>
<li><a href="https://yuanchaofa.com/llms-zero-to-hero/chaofa-wechat-official-account.png" target="_blank" rel="noopener noreferrer">公众号-chaofa用代码打点酱油</a>
<ul>
<li><img src="https://yuanchaofa.com/llms-zero-to-hero/chaofa-wechat-official-account.png" alt="chaofa用代码打点酱油" loading="lazy"></li>
</ul>
</li>
<li><a href="https://space.bilibili.com/12420432" target="_blank" rel="noopener noreferrer">B站-chaofa用代码打点酱油</a></li>
<li><a href="https://www.youtube.com/@bbruceyuan" target="_blank" rel="noopener noreferrer">YouTube-chaofa用代码打点酱油</a></li>
<li><a href="https://chaofa.notion.site/11a569b3ecce49b2826d679f5e2fdb54" target="_blank" rel="noopener noreferrer">chaofa 的 notion 简介</a></li>
<li><a href="https://x.com/bbruceyuan" target="_blank" rel="noopener noreferrer">X(Twitter)-chaofa用代码打点酱油</a></li>
</ul>
]]></content:encoded>
      <enclosure url="https://cfcdn.bruceyuan.com/blog/2025/gemini-tech-report-readding-notes-1752401580682.webp" type="image/webp"/>
    </item>
  </channel>
</rss>