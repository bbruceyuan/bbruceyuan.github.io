---
title: "RAG è¿›åŒ–ä¹‹è·¯ï¼šä¼ ç»Ÿ RAG åˆ°å·¥å…·ä¸å¼ºåŒ–å­¦ä¹ åŒè½®é©±åŠ¨çš„ Agentic RAG"
date: 2025-10-03 11:53:20
tag:
  - agent
  - LLM
category:
  - hands-on-code
description: æœ¬æ–‡æ·±å…¥å‰–æRAGæŠ€æœ¯çš„è¿›åŒ–å†ç¨‹ï¼Œä»ä¼ ç»ŸRAGåˆ°æ™ºèƒ½ä½“RAGçš„å…¨é¢å‡çº§ã€‚æ¢ç´¢ä¸¤ç§å®ç°Agentic RAGçš„å…³é”®è·¯å¾„ï¼šæç¤ºå·¥ç¨‹+å·¥å…·è°ƒç”¨ä¸å¼ºåŒ–å­¦ä¹ é©±åŠ¨æ–¹æ³•ã€‚é€šè¿‡è§£è¯»ä¼ä¸šçº§é¡¹ç›®chatboxå’ŒSearch-R1ï¼Œæ­ç¤ºå¦‚ä½•è®©å¤§æ¨¡å‹ä»"è¢«åŠ¨æ£€ç´¢"è½¬å˜ä¸º"ä¸»åŠ¨å†³ç­–"ï¼Œå®ç°æ›´ç²¾å‡†çš„çŸ¥è¯†è·å–ä¸åº”ç”¨ã€‚æ— è®ºä½ æ˜¯AIç ”å‘å·¥ç¨‹å¸ˆè¿˜æ˜¯äº§å“ç»ç†ï¼Œè¿™ç¯‡æ–‡ç« éƒ½å°†å¸®ä½ ç†è§£RAGæŠ€æœ¯çš„æœªæ¥å‘å±•æ–¹å‘ï¼ŒæŒæ¡æ„å»ºæ›´æ™ºèƒ½RAGç³»ç»Ÿçš„æ ¸å¿ƒæŠ€æœ¯ã€‚
publish: true
permalink: /post/from-native-rag-to-agentic-rag.html
---


## 1. é˜…è¯»æ”¶è· (takeaway)
æœ¬æ–‡æ—¨åœ¨ç¥›é­…ã€Agentic RAGã€‘çš„æ¦‚å¿µï¼Œå› æ­¤æœ¬æ–‡çš„é˜…è¯»æ”¶è·åŒ…æ‹¬ï¼š
- äº†è§£ä»€ä¹ˆæ˜¯ä¼ ç»Ÿ RAGï¼ˆNative RAGï¼‰
- äº†è§£ä»€ä¹ˆæ˜¯ Agentic RAG
    - äº†è§£ä¼ä¸šçº§é¡¹ç›® [chatbox](https://github.com/chatbox-ai/chatbox) çš„ Agentic RAG æ¶æ„å’ŒåŸç†
    - äº†è§£å¦‚ä½•ä½¿ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒ Agentic RAG ï¼ˆSearch-R1ï¼‰

## 2. å‰è¨€

å¦‚æœè¯´ 2024 å¹´ï¼ŒLLMï¼ˆLarge Language Modelï¼‰ è½åœ°æœ€å¹¿æ³›ä¸”æœ€æœ‰å®ç”¨ä»·å€¼çš„ä¸€é¡¹æŠ€æœ¯ï¼Œé‚£ä¹ˆæˆ‘æå RAGï¼ˆRetrieval Augmented Generation) åº”è¯¥ä¸ä¼šæœ‰å¤ªå¤šçš„åå¯¹ã€‚ä½† 2025 å¹´æœ€ç«çš„æ¦‚å¿µå˜æˆ Agentï¼Œè€Œ **RAG ä¼¼ä¹å˜æˆäº†ä¸€ä¸ªåŸºç¡€ç»„ä»¶ï¼Œæçš„ä¸å¤šå´æ˜¯èåˆåˆ°äº† Agent çš„æ—¥å¸¸ä½¿ç”¨ä¸­äº†**ï¼Œå°¤å…¶æ˜¯ [OpenAI DeepResearch](https://openai.com/index/introducing-deep-research/) çš„å‡ºç°ï¼Œè®© Agentic RAG æˆäº† 2025 å¹´æœ€æˆåŠŸçš„ RAG åº”ç”¨ä¹‹ä¸€ã€‚

ä½†ç½‘ç»œä¸Šæœ‰å¾ˆå¤šæ–‡ç« ï¼ŒæŠŠ Agentic RAG è¯´å¾—ç„ä¹ï¼Œæ•…æ„åˆ¶é€ éš¾æ‡‚çš„æ¦‚å¿µä»è€Œè¾¾åˆ°æŠ¬é«˜è‡ªèº«çš„ç›®çš„ã€‚ä½†å®é™…ä¸Šæˆ‘ä»¬åªéœ€è¦ç†æ¸…æ¥šä¸¤ä¸ªæ¦‚å¿µï¼Œå°±å¯ä»¥çŸ¥é“ä»€ä¹ˆæ˜¯ Agentic RAGã€‚
- ä¼ ç»Ÿ RAG æ˜¯ä»€ä¹ˆï¼Ÿ
	- é¢„å…ˆé€šè¿‡æ£€ç´¢æ’åºå°†çŸ¥è¯†æ”¾åˆ° Prompt ä¸­ï¼Œç„¶ååˆ©ç”¨ LLM ç”Ÿæˆå›å¤
- Agent æ˜¯ä»€ä¹ˆï¼Ÿ
	- ä½¿ç”¨å…·æœ‰è‡ªä¸»å†³ç­–èƒ½åŠ›çš„ Agent å®ç°çš„ RAG ç³»ç»Ÿå°±å¯ä»¥ç§°ä¸º Agentic RAGã€‚
å› æ­¤ `Agentic RAG` å®é™…ä¸Šå°±æ˜¯æŒ‡åœ¨ä¼ ç»Ÿ RAG åŸºç¡€ä¸Šï¼ŒåŠ å…¥äº† Agent ç»„ä»¶çš„ RAG ç³»ç»Ÿï¼Œä»»ä½•å®ç°äº† `Agentic Search` èƒ½åŠ›çš„ RAG ç³»ç»Ÿéƒ½å¯ä»¥ç§°ä¸º `Agentic RAG`ã€‚

## 3. ä¼ ç»Ÿ RAG ï¼ˆNative RAGï¼‰

ä¼ ç»Ÿçš„ RAGï¼ˆNative RAGï¼‰å¹¶ä¸æ˜¯ä¸€ä¸ªå¤æ‚çš„æ¦‚å¿µï¼Œæ ¸å¿ƒæ¦‚å¿µå°±ä¸¤ä¸ªï¼šæ£€ç´¢ï¼ˆRetrievalï¼‰å’Œç”Ÿæˆï¼ˆç”Ÿæˆï¼‰ã€‚å› æ­¤è¦åšå¥½ RAG å°±æ˜¯ä¸¤ä»¶äº‹æƒ…ï¼š
- æ€ä¹ˆæ£€ç´¢åˆ°æ›´æœ‰ç”¨çš„çŸ¥è¯†ï¼Ÿ
- æ€ä¹ˆè®©æ¨¡å‹æ›´å¥½çš„åˆ©ç”¨çŸ¥è¯†ç”Ÿæˆå›å¤ï¼Ÿ

å› æ­¤ RAG ç³»ç»Ÿæ¶æ„å¯ä»¥å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![[Excalidraw/from-native-rag-to-agentic-rag|from-native-rag-to-agentic-rag]]

`NATIVE RAG`ä¸€èˆ¬æ¥è¯´å¯ä»¥åˆ†æˆä¸¤ä¸ªä¸åŒçš„é“¾è·¯ï¼šç¦»çº¿å’Œåœ¨çº¿ã€‚å…·ä½“çš„ä»£ç å¯ä»¥å‚è€ƒï¼š[åŠ¨æ‰‹å­¦ä¹ å¤§æ¨¡å‹-ä¸­æ–‡ç‰ˆ-ç¬¬å…«ç« -native-rag æºä»£ç ](https://github.com/bbruceyuan/Hands-On-Large-Language-Models-CN/tree/master/chapter08)

```toml
requires-python = ">=3.12"
dependencies = [
    "langchain>=0.3.27",
    "langchain-chroma>=0.2.6",
    "langchain-community>=0.3.30",
    "langchain-deepseek>=0.1.4",
    "langchain-openai>=0.3.34",
    "langgraph>=0.6.8",
]
```

### 3.1 RAG ç¦»çº¿å…¥åº“

ç¦»çº¿å…¥åº“æ˜¯æŒ‡å°†æ–‡æ¡£å¤„ç†æˆå‘é‡å¹¶å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“ä¸­ï¼Œä»¥ä¾¿åç»­æ£€ç´¢ä½¿ç”¨ã€‚è¿™ä¸ªè¿‡ç¨‹ä¸»è¦åŒ…æ‹¬ï¼šæ–‡æ¡£åŠ è½½ã€æ–‡æœ¬åˆ‡åˆ†ã€å‘é‡åŒ–ã€å­˜å‚¨ã€‚

```python
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma

# 1. åŠ è½½æ–‡æ¡£
loader = TextLoader("knowledge_base.txt")
documents = loader.load()

# 2. æ–‡æœ¬åˆ‡åˆ†
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,  # æ¯ä¸ªæ–‡æœ¬å—çš„å¤§å°
    chunk_overlap=50,  # æ–‡æœ¬å—ä¹‹é—´çš„é‡å éƒ¨åˆ†
)
splits = text_splitter.split_documents(documents)

# 3. å‘é‡åŒ–å¹¶å­˜å‚¨
embeddings = OpenAIEmbeddings(
    base_url="https://api.siliconflow.cn/v1",
    model="Qwen/Qwen3-Embedding-0.6B",
)
vectorstore = Chroma.from_documents(
    documents=splits,
    embedding=embeddings,
    persist_directory="./chroma_db",  # æŒä¹…åŒ–å­˜å‚¨è·¯å¾„
)

print(f"æˆåŠŸå°† {len(splits)} ä¸ªæ–‡æœ¬å—å­˜å…¥å‘é‡æ•°æ®åº“")

```

### 3.2 RAG åœ¨çº¿åº”ç”¨

åœ¨çº¿åº”ç”¨æ˜¯æŒ‡ç”¨æˆ·æé—®æ—¶ï¼Œç³»ç»Ÿæ£€ç´¢ç›¸å…³æ–‡æ¡£å¹¶ç”Ÿæˆå›ç­”çš„è¿‡ç¨‹ã€‚ä¸»è¦åŒ…æ‹¬ï¼šç”¨æˆ·æŸ¥è¯¢ã€æ£€ç´¢ç›¸å…³æ–‡æ¡£ã€æ„å»ºæç¤ºè¯ã€LLM ç”Ÿæˆå›ç­”ã€‚

```python
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate

# 1. åŠ è½½å·²æœ‰çš„å‘é‡æ•°æ®åº“
embeddings = OpenAIEmbeddings(
    base_url="https://api.siliconflow.cn/v1",
    model="Qwen/Qwen3-Embedding-0.6B",
)
vectorstore = Chroma(persist_directory="./chroma_db", embedding_function=embeddings)

# 2. ç”¨æˆ·æé—®
query = "ä»€ä¹ˆæ˜¯RAGï¼Ÿ"

# 3. æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼ˆè¿”å›æœ€ç›¸å…³çš„ 3 ä¸ªï¼‰
docs = vectorstore.similarity_search(query, k=3)

# 4. å°†æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹æ‹¼æ¥æˆä¸Šä¸‹æ–‡
context = "\n\n".join([doc.page_content for doc in docs])

# 5. æ„å»º Prompt æ¨¡æ¿
prompt_template = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é—®ç­”åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹å‚è€ƒæ–‡æ¡£å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
å¦‚æœå‚è€ƒæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®åœ°è¯´ä¸çŸ¥é“ï¼Œä¸è¦ç¼–é€ ç­”æ¡ˆã€‚

å‚è€ƒæ–‡æ¡£ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

å›ç­”ï¼š
"""

prompt = PromptTemplate(
    template=prompt_template,
    input_variables=["context", "question"],
)

# 6. åˆ›å»º LLM å¹¶ç”Ÿæˆå›ç­”
llm = ChatOpenAI(
    model="THUDM/glm-4-9b-chat",
    temperature=0,
    max_retries=3,
    base_url="https://api.siliconflow.cn/v1",
)
final_prompt = prompt.format(context=context, question=query)

print(f"æœ€ç»ˆçš„ Prompt å†…å®¹ï¼š{final_prompt}")
response = llm.predict(final_prompt)

# 7. è¾“å‡ºç»“æœ
print(f"é—®é¢˜: {query}")
print(f"å›ç­”: {response}")
print(f"\nå‚è€ƒæ–‡æ¡£æ•°é‡: {len(docs)}")

```

## 4. Agentic RAG 

`Agentic RAG`çš„æ ¸å¿ƒâ€œ**ä¸æ˜¯æ›´å¤æ‚çš„æ¨¡å‹**â€ï¼Œè€Œæ˜¯â€œ**è®©æ¨¡å‹å­¦ä¼šåšäº‹**â€ã€‚å’Œä¸€æ¬¡æ€§æŠŠæ–‡æ¡£å¡è¿› Prompt å°±ç”Ÿæˆç­”æ¡ˆçš„ Native RAG ç›¸æ¯”ï¼ŒAgentic RAG è®©å¤§æ¨¡å‹æ‰®æ¼”ä¸€ä¸ªâ€œå†³ç­–-æ‰§è¡Œâ€çš„æ§åˆ¶å™¨ï¼š**å…ˆåˆ¶å®šç­–ç•¥ï¼Œå†è°ƒç”¨å·¥å…·é€æ­¥æ”¶é›†è¯æ®ï¼Œæœ€ååŸºäºè¯æ®ä½œç­”å¹¶ç»™å‡ºå¼•ç”¨**ã€‚

æ‰€ä»¥è¯´ï¼šæ¨¡å‹é€šè¿‡è‡ªä¸»å†³ç­–å®ç°çš„ RAG è¿‡ç¨‹ï¼Œæˆ‘ä»¬å°±å¯ä»¥ç§°ä¹‹ä¸º `Agentic RAG`ã€‚æ— è®ºè¿™ä¸ªè¿‡ç¨‹æ˜¯å‘ç°åœ¨ç¦»çº¿å…¥åº“é˜¶æ®µï¼ˆå½“ç„¶ Agentic RAG å…¶å®å¯ä»¥ä¸ä¸¥æ ¼åŒºåˆ† offline/online æˆªæ–­ï¼Œéƒ½å¯ä»¥è®© Agent è‡ªä¸»å†³ç­–ï¼‰ï¼Œè¿˜æ˜¯ RAG ç”Ÿæˆé˜¶æ®µçš„ `search query rewrite`ï¼Œ`rerank` è¿˜æ˜¯ `dynamic search`ç­‰ï¼Œåªè¦æœ‰æ¨¡å‹çš„è‡ªä¸»å†³ç­–è¿‡ç¨‹ï¼Œé‚£ä¹ˆå°±å¯ä»¥ç§°ä¸º `Agentic RAG`ã€‚

å¦‚æœæƒ³äº†è§£æ›´å¤šçš„ [`Agentic RAG`çš„å·¥ä¸šçº§åˆ«](https://github.com/chatboxai/chatbox)çš„å®ç°ï¼Œæˆ‘è§‰å¾—å¯ä»¥å‚è€ƒã€Œ[å¼€æºé¡¹ç›® chatbox](https://github.com/chatboxai/chatbox)ã€çš„å®ç°ï¼Œè¯¥é¡¹ç›®æ˜¯ä¸€ä¸ªæ¯”è¾ƒæ—©çš„ LLM Chat é›†æˆçš„é¡¹ç›®ï¼Œå¹¶ä¸”ç®—æ˜¯æ¯”è¾ƒæ—©çš„å®ç°äº† `Agentic RAG`ã€‚å› ä¸ºä½œä¸ºä¸€ä¸ªç¦»çº¿çš„ LLM chat é¡¹ç›®ï¼Œå¯¹äºæ—¶å»¶ç­‰é—®é¢˜å¯ä»¥æœ‰æ›´å°‘çš„è€ƒè™‘ï¼Œä»è€Œ**æ›´æ¿€è¿›çš„ã€æ›´æ—©é˜¶æ®µå°† naive chat å˜æˆ Agentic Chat**ã€‚

> ç»™æ¨¡å‹æ›´å¤šçš„è‡ªä¸»å†³ç­–ç©ºé—´ã€é…å¤‡åˆé€‚çš„å·¥å…·ï¼ŒLLM ä¼šç»™ä½ å‡ºä¹æ„æ–™çš„æ™ºèƒ½ã€‚

### 4.1 Native RAG æœ‰å“ªäº›ä¸å¤Ÿå¥½çš„åœ°æ–¹ï¼Ÿ

- ä¸€æ¬¡æ€§æµæ°´çº¿ï¼šé€šå¸¸â€œæ£€ç´¢â†’æ‹¼æ¥â†’ç”Ÿæˆâ€ä¸€æ­¥åˆ°ä½ï¼Œæ²¡æœ‰è®©æ¨¡å‹æ ¹æ®éœ€è¦è°ƒæ•´æ£€ç´¢ç­–ç•¥ã€é€’è¿›å¼åœ°é’»ç ”æ–‡æ¡£ã€‚
- ç¼ºä¹ä»»åŠ¡æ‹†è§£ï¼šé—®é¢˜å¯èƒ½éœ€è¦å…ˆå®šä½æ–‡ä»¶ã€å†é€‰ç‰‡æ®µã€å†æ¯”å¯¹ä¸æ€»ç»“ï¼›Native RAG å¾€å¾€ç¼ºå°‘è¿™æ ·çš„å¤šæ­¥æ‹†è§£èƒ½åŠ›ã€‚
- å·¥å…·ç¼–æ’ä¸è¶³ï¼šåªä¼šç›¸ä¼¼åº¦æ£€ç´¢ï¼Œä¸ä¼šè¿›ä¸€æ­¥æŸ¥çœ‹æ–‡ä»¶å…ƒæ•°æ®ã€é€‰æ‹©éœ€è¦é˜…è¯»çš„ chunkï¼Œæ›´ä¸ä¼šåœ¨ä¸å¤Ÿæ—¶æ¢ä¸€ç§æ£€ç´¢æˆ–è¡¥å……æŸ¥è¯¢ã€‚
- è¯æ®åˆ©ç”¨æµ…ï¼šTop-K æ‹¼æ¥å®¹æ˜“â€œç³Šâ€ä¸Šä¸‹æ–‡ï¼Œæ— æ³•è¿›è¡Œâ€œå…ˆç²—åç»†â€çš„è¯æ®æ”¶é›†ï¼ˆcoarseâ†’fineï¼‰ï¼Œä¹Ÿä¸å®¹æ˜“æ˜ç¡®å¼•ç”¨åˆ°å…·ä½“ç‰‡æ®µã€‚
- é€‚åº”æ€§å·®ï¼šé¢å¯¹å¤šè·³é—®é¢˜ï¼ˆmulti-hopï¼‰æˆ–ä¿¡æ¯ä¸è¶³çš„åœºæ™¯ï¼Œé€šå¸¸ä¸ä¼šå›æº¯é‡è¯•ã€æ”¹å†™æŸ¥è¯¢ã€æ¢è·¯å­ç»§ç»­æ‰¾ã€‚

### 4.2 ä»€ä¹ˆæ˜¯ Agentic RAGï¼Ÿ

- è®© LLM ä½œä¸ºâ€œæ™ºèƒ½ä½“ï¼ˆAgentï¼‰â€å……å½“æ§åˆ¶å™¨ï¼Œç»“åˆä¸€ç»„å·¥å…·ï¼ˆæ£€ç´¢ã€æŸ¥çœ‹å…ƒæ•°æ®ã€è¯»å–ç‰‡æ®µç­‰ï¼‰æ‰§è¡Œâ€œæ€è€ƒâ†’è¡ŒåŠ¨â†’è§‚å¯Ÿâ€çš„å¾ªç¯ï¼ˆReasonâ€“Actâ€“Observeï¼‰ã€‚
- åœ¨å›ç­”ä¹‹å‰ï¼ŒæŒ‰éœ€å¤šè½®è°ƒç”¨å·¥å…·ï¼Œé€æ­¥ä»â€œæ‰¾åˆ°ç›¸å…³æ–‡ä»¶â€èµ°åˆ°â€œè¯»å–å…³é”®ç‰‡æ®µâ€ï¼Œæœ€ååŸºäºè¢«è¯»å–çš„è¯æ®ç»„ç»‡ç­”æ¡ˆï¼Œå¹¶ç»™å‡ºå¼•ç”¨ã€‚
- å¥½å¤„ï¼šæ›´å¼ºçš„é€‚åº”æ€§ï¼ˆå¯æ”¹å†™æŸ¥è¯¢/è¿½åŠ æœç´¢ï¼‰ã€æ›´æ·±çš„è¯æ®åˆ©ç”¨ï¼ˆè¯»åˆ°å†ç­”ï¼‰ã€æ›´å¯å®¡è®¡ï¼ˆå¼•ç”¨å…·ä½“æ¥æºï¼‰ã€‚

### 4.3 åŸºäºæç¤ºè¯å’Œå·¥å…·çš„ Agentic RAG

ReAct æ˜¯ä¸€ä¸ªå¸¸è§çš„ Agent å®ç°æ–¹å¼ï¼Œå› æ­¤åªè¦ç»™ LLM é…å¤‡åˆé€‚çš„ `Tool`ä»¥åŠé€‚å½“çš„å¼•å¯¼ `Prompt`ï¼Œå°±å¯ä»¥å°†ä¸€ä¸ª `Native RAG` è½¬æ¢æˆ `Agentic RAG`ã€‚è¿™é‡Œæˆ‘é€šè¿‡è§£è¯» `36.8k star`å¼€æºä¼ä¸šçº§é¡¹ç›®â€”â€”[chatbox](https://github.com/chatboxai/chatbox)æ¥è®²è§£ä¸€ä¸ª Agentic RAG æ˜¯æ€ä¹ˆå®ç°çš„ï¼Œä»¥åŠä¸ºä»€ä¹ˆå®ƒåœ¨å¤æ‚åœºæ™¯ä¸‹æ•ˆæœå¥½[^1]ã€‚

ä¸‹é¢æ˜¯ `Chatbox` çš„æ•´ä½“æµç¨‹å›¾ï¼Œå¯ä»¥åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼Œå·¦åŠéƒ¨åˆ†æ˜¯ `Agentic RAG`ï¼Œå³åŠéƒ¨åˆ†æ˜¯ä»‹äº `Native RAG` åˆ° `Agentic RAG`ä¹‹é—´çš„ `Native RAG`ã€‚

![image.png|700x889](https://cfcdn.yuanchaofa.com/blog/2025/20251003192952.png)


```mermaid
graph TB
    A[ç”¨æˆ·å‘é€æ¶ˆæ¯] --> B{æ¨¡å‹æ˜¯å¦æ”¯æŒå·¥å…·è°ƒç”¨?}
    
    %% æ”¯æŒå·¥å…·è°ƒç”¨çš„åˆ†æ”¯
    B -->|æ”¯æŒ| C[æ³¨å†ŒçŸ¥è¯†åº“å·¥å…·é›†]
    C --> D[æ·»åŠ ç³»ç»Ÿæç¤º:<br/>Knowledge base is available]
    D --> E[æ¨¡å‹è‡ªä¸»å†³å®šæ˜¯å¦ä½¿ç”¨å·¥å…·]
    E --> F[å¯èƒ½ä½¿ç”¨çš„å·¥å…·:]
    F --> G[query_knowledge_base<br/>è¯­ä¹‰æœç´¢]
    F --> H[list_files<br/>æµè§ˆæ–‡ä»¶åˆ—è¡¨]
    F --> I[read_file_chunks<br/>è¯»å–å…·ä½“å†…å®¹]
    F --> J[get_files_meta<br/>è·å–æ–‡ä»¶ä¿¡æ¯]
    G --> K[åŸºäºå·¥å…·ç»“æœç”Ÿæˆå›å¤]
    H --> K
    I --> K
    J --> K
    
    %% ä¸æ”¯æŒå·¥å…·è°ƒç”¨çš„åˆ†æ”¯
    B -->|ä¸æ”¯æŒ| L[å‘é€åˆ¤æ–­ Prompt ç»™ LLM]
    L --> M["ç³»ç»Ÿ Prompt:<br/>As a professional knowledge base researcher,<br/>determine if searching would help..."]
    M --> N[LLM åˆ†æç”¨æˆ·é—®é¢˜]
    N --> O{LLM åˆ¤æ–­ç»“æœ}
    
    O -->|action: 'proceed'| P[ç›´æ¥å›ç­”ï¼Œä¸æœç´¢]
    O -->|action: 'search'| Q[æ‰§è¡ŒçŸ¥è¯†åº“è¯­ä¹‰æœç´¢]
    Q --> R[è·å–ç›¸ä¼¼æ–‡æ¡£ç‰‡æ®µ]
    R --> S{æ˜¯å¦æœ‰é‡æ’åºæ¨¡å‹?}
    S -->|æœ‰| T[ä½¿ç”¨ Rerank æ¨¡å‹é‡æ’åº]
    S -->|æ— | U[ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦æ’åº]
    T --> V[å°†æœç´¢ç»“æœæ³¨å…¥åˆ°å¯¹è¯ä¸­]
    U --> V
    V --> W["æ„å»ºå¢å¼º Prompt:<br/>[document 1 begin]...[document 1 end]<br/>User Message: ..."]
    W --> X[åŸºäºæœç´¢ç»“æœç”Ÿæˆå›ç­”]
    
    %% æœ€ç»ˆè¾“å‡º
    K --> Y[è¿”å›æœ€ç»ˆå›å¤]
    P --> Y
    X --> Y
    
    %% æ ·å¼
    classDef userAction fill:#e1f5fe
    classDef toolSupported fill:#e8f5e8
    classDef toolNotSupported fill:#f3e5f5
    classDef decision fill:#fff3e0
    classDef output fill:#fce4ec
    
    class A userAction
    class C,D,E,F,G,H,I,J,K toolSupported
    class L,M,N,Q,R,S,T,U,V,W,X toolNotSupported
    class B,O decision
    class P,Y output

```

å› æ­¤æˆ‘ä»¬é‡ç‚¹æ¥è§£è¯» `chatbox` åˆ°åº•æ˜¯æ€ä¹ˆ[è®¾ç½®å·¥å…·](https://github.com/chatboxai/chatbox/blob/9e33c9f998ebf240f31bbb439a430b4d5e5bd3e0/src/renderer/packages/knowledge-base/tools.ts#L78)ï¼Œæ¥å®ç°æ›´å¥½çš„ `Agentic Search`ï¼Œç„¶åå†ç»™å‡ºæœ€å°ç¤ºä¾‹ä»£ç ï¼š

> åŒ…æ‹¬ Anthropic çš„ context engineering æ–‡ç« ä¸­ä¹Ÿæåˆ°äº†`Agentic Seach` å¯¹äº Agent åº”ç”¨æ˜¯éå¸¸é‡è¦çš„ã€‚

- `query_knowledge_base`
	- åœ¨çŸ¥è¯†åº“ä¸­è¿›è¡Œè¯­ä¹‰æœç´¢ï¼Œå¿«é€Ÿæ‰¾åˆ°å€™é€‰æ–‡ä»¶æˆ–ç‰‡æ®µçš„â€œçº¿ç´¢â€ã€‚é€šå¸¸ä½œä¸ºæœ€åŸºç¡€çš„æ£€ç´¢å·¥å…·
- `get_files_meta`
	- æŸ¥çœ‹å€™é€‰æ–‡ä»¶çš„å…ƒä¿¡æ¯ï¼ˆå¦‚æ–‡ä»¶åã€å¤§å°ã€chunk æ•°é‡ï¼‰ï¼Œå¸®åŠ©æ¨¡å‹å†³å®šâ€œè¯»å“ªå‡ ä¸ªæ–‡ä»¶çš„å“ªéƒ¨åˆ†â€ã€‚
- `read_file_chunks`
	- æŒ‰æ–‡ä»¶ `ID + chunkIndex` ç²¾è¯»å…·ä½“ç‰‡æ®µï¼Œç”¨äºâ€œå–è¯â€ã€‚å»ºè®®ä¸€æ¬¡åªè¯»å°‘é‡æœ€ç›¸å…³çš„ `chunk`ï¼Œä»¥é™ä½å™ªå£°ã€‚
- `list_files`
	- åˆ—å‡ºçŸ¥è¯†åº“ä¸­çš„æ–‡ä»¶æ¸…å•ï¼Œä½œä¸ºå…œåº•æµè§ˆæˆ–å½“æœç´¢çº¿ç´¢ä¸å……åˆ†æ—¶çš„æ¢ç´¢æ‰‹æ®µã€‚

ä¸€ä¸ªå…¸å‹çš„ Agentic RAG ç­–ç•¥æ˜¯ï¼šå…ˆç²—åç»† â†’ å…ˆæ‰¾å€™é€‰ï¼ˆquery_knowledge_base / list_filesï¼‰â†’ çœ‹å…ƒä¿¡æ¯ï¼ˆget_files_metaï¼‰â†’ ç²¾è¯»ç‰‡æ®µï¼ˆread_file_chunksï¼‰â†’ åŸºäºè¯æ®ç»„ç»‡ç­”æ¡ˆå¹¶ç»™å‡ºå¼•ç”¨ã€‚å…·ä½“ä»£ç å¯ä»¥è§ï¼š[åŠ¨æ‰‹å­¦ä¹ å¤§æ¨¡å‹-ä¸­æ–‡ç‰ˆ-ç¬¬å…«ç« -agentic-rag æºä»£ç ](https://github.com/bbruceyuan/Hands-On-Large-Language-Models-CN/tree/master/chapter08)

```python
from typing import List, Dict, Any
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent

# å‡è®¾ kb_controller ç”±ä½ çš„å¹³å°æä¾›ï¼Œå…·å¤‡ï¼š
# - search(kb_id, query)
# - getFilesMeta(kb_id, file_ids)
# - readFileChunks(kb_id, chunks)
# - listFilesPaginated(kb_id, page, page_size)
kb_controller = ...  # TODO: æ›¿æ¢ä¸ºä½ çš„å¹³å°å®ä¾‹
knowledge_base_id = 42

@tool("query_knowledge_base")
def query_knowledge_base(query: str) -> Any:
    """Query a knowledge base"""
    return kb_controller.search(knowledge_base_id, query)

@tool("get_files_meta")
def get_files_meta(fileIds: List[int]) -> Any:
    """Get metadata for files in the current knowledge base."""
    if not fileIds:
        return "Please provide an array of file IDs."
    return kb_controller.getFilesMeta(knowledge_base_id, fileIds)

@tool("read_file_chunks")
def read_file_chunks(chunks: List[Dict[str, int]]) -> Any:
    """Read content chunks from specified files in the current knowledge base."""
    if not chunks:
        return "Please provide an array of chunks to read."
    return kb_controller.readFileChunks(knowledge_base_id, chunks)

@tool("list_files")
def list_files(page: int, pageSize: int) -> Any:
    """List all files in the current knowledge base. Returns file ID, filename, and chunk count for each file."""
    files = kb_controller.listFilesPaginated(knowledge_base_id, page, pageSize)
    return [
        {"id": f["id"], "filename": f["filename"], "chunkCount": f.get("chunk_count", 0)}
        for f in files
        if f.get("status") == "done"
    ]

# å·¥å…·æ¸…å•
tools = [query_knowledge_base, get_files_meta, read_file_chunks, list_files]

# è¡Œä¸ºç­–ç•¥ï¼ˆç³»ç»Ÿæç¤ºï¼‰
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ª Agentic RAG åŠ©æ‰‹ã€‚è¯·éµå¾ªï¼š
- å…ˆç”¨ query_knowledge_base æœç´¢ï¼›å¿…è¦æ—¶ä½¿ç”¨ get_files_meta æŸ¥çœ‹æ–‡ä»¶ä¿¡æ¯ï¼Œæˆ–ç”¨ list_files æµè§ˆå¤‡é€‰ã€‚
- æœ€ç»ˆå¿…é¡»ç”¨ read_file_chunks è¯»å–å°‘é‡æœ€ç›¸å…³çš„ç‰‡æ®µï¼Œå†åŸºäºç‰‡æ®µå†…å®¹ä½œç­”ã€‚
- ä¸è¦ç¼–é€ ï¼›è‹¥è¯æ®ä¸è¶³è¯·è¯´æ˜ä¸è¶³å¹¶å»ºè®®ä¸‹ä¸€æ­¥ã€‚
- å›ç­”æœ«å°¾ç”¨â€œå¼•ç”¨ï¼šâ€åˆ—å‡ºä½ å®é™…è¯»å–è¿‡çš„ fileId å’Œ chunkIndexï¼ˆæˆ–æ–‡ä»¶åï¼‰ã€‚
"""

# æ¨¡å‹ä¸ Agent
llm = ChatOpenAI(
    model="THUDM/glm-4-9b-chat",
    temperature=0,
    max_retries=3,
    base_url="https://api.siliconflow.cn/v1",
)
agent = create_react_agent(llm, tools, state_modifier=SYSTEM_PROMPT)

# è°ƒç”¨ä¸€æ¬¡
question = "è¯·åŸºäºçŸ¥è¯†åº“ï¼Œæ¦‚è¿° RAG çš„ä¼˜ç¼ºç‚¹ï¼Œå¹¶ç»™å‡ºå¼•ç”¨ã€‚"
result = agent.invoke({"messages": [("user", question)]})
final_answer = result["messages"][-1].content
print("ç­”æ¡ˆ:\n", final_answer)
```

### 4.4 åŸºäºå¼ºåŒ–å­¦ä¹ çš„ Agentic RAG

è¿™ä¸€æ–¹å‘é€šå¸¸ç”¨äºè®© Agent å­¦ä¼šæ›´å¥½çš„"æ£€ç´¢-å–è¯ç­–ç•¥"ï¼ˆå¦‚ä½•æ—¶æ”¹å†™æŸ¥è¯¢ã€ä½•æ—¶è¿½åŠ è¯»å–ç­‰ï¼‰ï¼Œè€Œä¸æ˜¯ä¾èµ–äººå·¥è®¾è®¡çš„æç¤ºè¯å’Œè§„åˆ™ã€‚å‰é¢ä»‹ç»çš„åŸºäºæç¤ºè¯çš„ Agentic RAG è™½ç„¶æœ‰æ•ˆï¼Œä½†ä»ç„¶å­˜åœ¨ä¸€äº›å±€é™æ€§ï¼š

1. ä¾èµ–äººå·¥è®¾è®¡çš„æç¤ºè¯å’Œè§„åˆ™ï¼Œéš¾ä»¥é€‚åº”å¤æ‚å¤šå˜çš„åœºæ™¯
2. ç¼ºä¹å¯¹æœç´¢è¡Œä¸ºçš„ç³»ç»Ÿæ€§ä¼˜åŒ–ï¼Œæ— æ³•ä»ç»éªŒä¸­å­¦ä¹ å’Œæ”¹è¿›
3. éš¾ä»¥å¤„ç†å¤šè½®äº¤äº’å¼æœç´¢çš„å¤æ‚å†³ç­–è¿‡ç¨‹

è‡ª OpenAI-DeepResearch ä»¥åŠ DeepSeek-R1 å‘å¸ƒä¹‹åï¼Œä½¿ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ¥å¢å¼ºæ¨¡å‹èƒ½åŠ›å·²ç»æ˜¯ä¸€ä¸ªå¸¸è§çš„åšæ³•ï¼Œå…¶ä¸­ä¸€ä¸ªå¤ç° DeepSearch çš„ä»£è¡¨æ€§å·¥ä½œæ˜¯ [Search-R1](https://arxiv.org/pdf/2503.09516)ï¼Œå®ƒé€šè¿‡ RL è®­ç»ƒ LLM å­¦ä¼šåœ¨æ¨ç†è¿‡ç¨‹ä¸­è‡ªä¸»ç”Ÿæˆæœç´¢æŸ¥è¯¢å¹¶åˆ©ç”¨å®æ—¶æ£€ç´¢ç»“æœã€‚

#### 4.4.1 Search-R1ï¼šåŸºäº RL çš„æ¨ç†ä¸æœç´¢äº¤ç»‡å¼ LLM

Search-R1 æ˜¯ä¸€ä¸ªåŸºäºå¼ºåŒ–å­¦ä¹ çš„æ¡†æ¶ï¼Œä¸“ä¸ºè®­ç»ƒå…·å¤‡æ¨ç†å’Œæœç´¢èƒ½åŠ›çš„å¤§è¯­è¨€æ¨¡å‹è€Œè®¾è®¡ã€‚ä¸ä¼ ç»Ÿ RAG æˆ–åŸºäºæç¤ºè¯çš„ Agentic RAG ä¸åŒï¼ŒSearch-R1 è®©æ¨¡å‹é€šè¿‡å¼ºåŒ–å­¦ä¹ æŒæ¡"ä½•æ—¶æœç´¢"ã€"æœç´¢ä»€ä¹ˆ"ä»¥åŠ"å¦‚ä½•åˆ©ç”¨æœç´¢ç»“æœ"çš„èƒ½åŠ›ã€‚

![image.png](https://cfcdn.yuanchaofa.com/blog/2025/20251003193047.png)

```mermaid
graph TB
    A[ç”¨æˆ·é—®é¢˜] --> B[LLM æ¨ç†]
    B --> C{éœ€è¦æœç´¢?}
    C -->|æ˜¯| D[ç”Ÿæˆæœç´¢æŸ¥è¯¢]
    D --> E[æ‰§è¡Œæœç´¢]
    E --> F[è·å–æœç´¢ç»“æœ]
    F --> G[ç»§ç»­æ¨ç†]
    G --> C
    C -->|å¦| H[ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ]
    
    classDef default fill:#f9f9f9,stroke:#333,stroke-width:1px;
    classDef decision fill:#e1f5fe,stroke:#333,stroke-width:1px;
    classDef action fill:#e8f5e9,stroke:#333,stroke-width:1px;
    
    class A,H default;
    class B,D,E,F,G action;
    class C decision;
```

Search-R1 çš„æ ¸å¿ƒç‰¹ç‚¹åŒ…æ‹¬ï¼š

1. **æ¨ç†ä¸æœç´¢çš„äº¤ç»‡**ï¼šæ¨¡å‹å¯ä»¥åœ¨æ¨ç†è¿‡ç¨‹ä¸­å¤šæ¬¡ç”Ÿæˆæœç´¢æŸ¥è¯¢ï¼Œè·å–ä¿¡æ¯åç»§ç»­æ¨ç†ï¼Œå½¢æˆ"æ¨ç†-æœç´¢-æ¨ç†"çš„å¾ªç¯
2. **è‡ªä¸»å†³ç­–**ï¼šæ¨¡å‹è‡ªä¸»å†³å®šä½•æ—¶éœ€è¦æœç´¢ã€æœç´¢ä»€ä¹ˆå†…å®¹ï¼Œè€Œä¸æ˜¯æŒ‰ç…§å›ºå®šæµç¨‹æ‰§è¡Œ
3. **å¤šè½®æœç´¢äº¤äº’**ï¼šæ”¯æŒåœ¨å•æ¬¡æ¨ç†è¿‡ç¨‹ä¸­è¿›è¡Œå¤šè½®æœç´¢ï¼Œæ¯è½®æœç´¢éƒ½åŸºäºå½“å‰çš„æ¨ç†çŠ¶æ€
4. **æ£€ç´¢ä»¤ç‰Œæ©ç **ï¼šä½¿ç”¨æ£€ç´¢ä»¤ç‰Œæ©ç æŠ€æœ¯ç¡®ä¿ RL è®­ç»ƒçš„ç¨³å®šæ€§
5. **åŸºäºç»“æœçš„å¥–åŠ±å‡½æ•°**ï¼šé‡‡ç”¨ç®€å•çš„åŸºäºç»“æœçš„å¥–åŠ±å‡½æ•°ï¼Œé¼“åŠ±æ¨¡å‹ç”Ÿæˆæ­£ç¡®ç­”æ¡ˆ

#### 4.4.2 å¼ºåŒ–å­¦ä¹ è®­ç»ƒæµç¨‹

Search-R1 çš„è®­ç»ƒæµç¨‹ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤ï¼š

![image.png|700x507](https://cfcdn.yuanchaofa.com/blog/2025/20251003173454.png)

1. **åˆå§‹åŒ–**ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„ LLM ä½œä¸ºèµ·ç‚¹ï¼ˆå¦‚ Qwen2.5-7Bã€Llama3 ç­‰ï¼‰
2. **è½¨è¿¹ç”Ÿæˆ**ï¼šæ¨¡å‹ç”ŸæˆåŒ…å«æ¨ç†æ­¥éª¤å’Œæœç´¢æ“ä½œçš„è½¨è¿¹ã€‚
    - æŒ‰ç…§ç‰¹å®šçš„æ ¼å¼ç”Ÿæˆï¼Œå…·ä½“å¯ä»¥å‚è€ƒ Example æ ·ä¾‹ã€‚
3. **å¥–åŠ±è®¡ç®—**ï¼šåŸºäºæœ€ç»ˆç­”æ¡ˆçš„æ­£ç¡®æ€§è®¡ç®—å¥–åŠ±ï¼ˆåªæœ€ç»ˆç­”æ¡ˆï¼‰
4. **ç­–ç•¥ä¼˜åŒ–**ï¼šä½¿ç”¨ RL ç®—æ³•ï¼ˆå¦‚ PPOã€GRPOï¼‰ä¼˜åŒ–æ¨¡å‹ç­–ç•¥

å…·ä½“çš„æ ·ä¾‹å¯ä»¥å‚è€ƒï¼š

![image.png|700x839](https://cfcdn.yuanchaofa.com/blog/2025/20251003173534.png)


```python
# Search-R1 è®­ç»ƒä¼ªä»£ç 
def train_search_r1(model, optimizer, dataset, search_engine, epochs):
    for epoch in range(epochs):
        for question, ground_truth in dataset:
            # ç”Ÿæˆè½¨è¿¹
            trajectory, actions, log_probs = generate_trajectory(model, question, search_engine)
            
            # è®¡ç®—å¥–åŠ±
            final_answer = trajectory[-1]
            reward = compute_reward(final_answer, ground_truth)
            
            # ç­–ç•¥ä¼˜åŒ–ï¼Œ ä¹Ÿå¯ä»¥æ˜¯ conpute_grpo_loss()
            loss = compute_policy_gradient_loss(log_probs, reward)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
    
    return model

def generate_trajectory(model, question, search_engine):
    trajectory = []
    actions = []
    log_probs = []
    state = question
    done = False
    
    while not done:
        # æ¨¡å‹æ¨ç†
        output, action_prob = model(state)  # è¿”å›è¾“å‡ºå’ŒåŠ¨ä½œæ¦‚ç‡
        trajectory.append(output)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æœç´¢
        if "<search>" in output:
            # è®°å½•æœç´¢åŠ¨ä½œå’Œæ¦‚ç‡
            actions.append("search")
            log_probs.append(action_prob)
            
            # æå–æœç´¢æŸ¥è¯¢
            query = extract_search_query(output)
            
            # æ‰§è¡Œæœç´¢
            search_results = search_engine.search(query)
            
            # æ›´æ–°çŠ¶æ€
            state = state + output + search_results
        else:
            # è®°å½•ç”Ÿæˆç­”æ¡ˆåŠ¨ä½œå’Œæ¦‚ç‡
            actions.append("answer")
            log_probs.append(action_prob)
            
            # ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
            done = True
    
    return trajectory, actions, log_probs
```

#### 4.4.3 æœ€å°å®ç°ç¤ºä¾‹

ä»¥ä¸‹æ˜¯ Search-R1 çš„ç®€åŒ–å®ç°ç¤ºä¾‹ï¼Œå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒ Agentic RAG æ¨¡å‹ï¼šå½“ç„¶å®é™…ä¸Š Search-R1 ä½¿ç”¨çš„ `GRPO` ç®—æ³•ï¼Œæˆ‘è¿™é‡Œç”¨ policy gradient æ¥æ¼”ç¤ºã€‚

```python
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from torch.optim import Adam

model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen2.5-7B")
tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-7B")

class SearchEngine:
    def search(self, query):
        # å®ç°æœç´¢é€»è¾‘ï¼Œè¿”å›æœç´¢ç»“æœ
        # å¯ä»¥æ˜¯æœ¬åœ°æ£€ç´¢å™¨æˆ–åœ¨çº¿æœç´¢å¼•æ“
        pass

def generate_trajectory(model, tokenizer, question, search_engine):
    trajectory = []
    actions = []
    log_probs = []
    state = question
    done = False
    
    while not done:
        # æ¨¡å‹æ¨ç†
        inputs = tokenizer(state, return_tensors="pt")
        outputs = model.generate(**inputs, max_new_tokens=100, output_scores=True, return_dict_in_generate=True)
        
        # è·å–è¾“å‡ºæ–‡æœ¬å’Œæ¦‚ç‡
        step_output = tokenizer.decode(outputs.sequences[0])
        action_prob = torch.softmax(outputs.scores[-1], dim=-1).max().item()  # ç®€åŒ–å¤„ç†
        
        trajectory.append(step_output)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æœç´¢
        if "<search>" in step_output:
            # è®°å½•æœç´¢åŠ¨ä½œå’Œæ¦‚ç‡
            actions.append("search")
            log_probs.append(action_prob)
            
            # æå–æœç´¢æŸ¥è¯¢
            query = extract_search_query(step_output)
            
            # æ‰§è¡Œæœç´¢
            search_results = search_engine.search(query)
            
            # æ›´æ–°çŠ¶æ€
            state = state + step_output + search_results
        else:
            # è®°å½•ç”Ÿæˆç­”æ¡ˆåŠ¨ä½œå’Œæ¦‚ç‡
            actions.append("answer")
            log_probs.append(action_prob)
            
            # ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
            done = True
    
    return trajectory, actions, torch.tensor(log_probs)

# å®šä¹‰ RL è®­ç»ƒå‡½æ•°
def train_rl(model, dataset, search_engine, epochs=3, lr=1e-5):
    optimizer = Adam(model.parameters(), lr=lr)
    
    for epoch in range(epochs):
        for question, answer in dataset:
            # ç”ŸæˆåŒ…å«æœç´¢æ“ä½œçš„è½¨è¿¹
            with torch.no_grad():
                trajectory, actions, log_probs = generate_trajectory(
                    model, tokenizer, question, search_engine
                )
            
            # è®¡ç®—å¥–åŠ±
            final_answer = trajectory[-1]
            reward = compute_reward(final_answer, answer)
            
            # è®¡ç®—ç­–ç•¥æ¢¯åº¦æŸå¤±
            policy_loss = -torch.mean(log_probs * reward)
            
            # æ›´æ–°æ¨¡å‹
            optimizer.zero_grad()
            policy_loss.backward()
            optimizer.step()
    
    return model

# ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ¨ç†
def inference(model, tokenizer, question, search_engine):
    state = question
    done = False
    steps = []
    
    while not done and len(steps) < 10:
        inputs = tokenizer(state, return_tensors="pt")
        outputs = model.generate(**inputs, max_new_tokens=100)
        step_output = tokenizer.decode(outputs[0])
        steps.append(step_output)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æœç´¢
        if "<search>" in step_output:
            # æå–æœç´¢æŸ¥è¯¢
            query = extract_search_query(step_output)
            
            # æ‰§è¡Œæœç´¢
            search_results = search_engine.search(query)
            
            # æ›´æ–°çŠ¶æ€
            state = state + step_output + search_results
        else:
            # ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
            done = True
    
    return steps[-1]  # è¿”å›æœ€ç»ˆç­”æ¡ˆ

# è¾…åŠ©å‡½æ•°ï¼šæå–æœç´¢æŸ¥è¯¢
def extract_search_query(text):
    # ä»æ–‡æœ¬ä¸­æå–æœç´¢æŸ¥è¯¢
    # å‡è®¾æŸ¥è¯¢æ ¼å¼ä¸º <search>æŸ¥è¯¢å†…å®¹</search>
    start_tag = "<search>"
    end_tag = "</search>"
    start_idx = text.find(start_tag) + len(start_tag)
    end_idx = text.find(end_tag)
    
    if start_idx >= len(start_tag) and end_idx > start_idx:
        return text[start_idx:end_idx].strip()
    return ""

# è¾…åŠ©å‡½æ•°ï¼šè®¡ç®—å¥–åŠ±
def compute_reward(prediction, ground_truth):

    if prediction == ground_truth:
        return 1.0
    return 0.0
```

## 5 æ€»ç»“æ¯”è¾ƒ

ç›¸æ¯”äºåŸºäºæç¤ºè¯çš„ Agentic RAG å’Œä¼ ç»Ÿ RAGï¼ŒåŸºäºå¼ºåŒ–å­¦ä¹ çš„ Agentic RAG æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š

| æ–¹æ³• | å†³ç­–æœºåˆ¶ | æœç´¢èƒ½åŠ› | é€‚åº”æ€§ | å®ç°å¤æ‚åº¦ |
|------|---------|---------|--------|------------|
| ä¼ ç»Ÿ RAG | å›ºå®šæµç¨‹ | å•æ¬¡æ£€ç´¢ | ä½ | ä½ |
| åŸºäºæç¤ºè¯çš„ Agentic RAG | åŸºäºè§„åˆ™ | å¤šæ¬¡æ£€ç´¢ | ä¸­ | ä¸­ |
| åŸºäº RL çš„ Agentic RAG | å­¦ä¹ ä¼˜åŒ– | è‡ªé€‚åº”å¤šæ¬¡æ£€ç´¢ | é«˜ | é«˜ |

å½“ç„¶ï¼ŒåŸºäºå¼ºåŒ–å­¦ä¹ çš„ Agentic RAG ä¹Ÿæœ‰ä¸€äº›æŒ‘æˆ˜ï¼Œä¾‹å¦‚è®­ç»ƒæˆæœ¬é«˜ã€æ•°æ®ä¾èµ–ç­‰ï¼Œä½†ç›®å‰ï¼ˆ2025-10-03ï¼‰æ¥çœ‹ï¼ŒåŸºäºå¼ºåŒ–å­¦ä¹ çš„ Agent åº”ç”¨ï¼ˆåŒ…æ‹¬ Agentic RAGï¼‰ä»ç„¶æ˜¯æœ€ä¸»æµçš„ä¸€ç§ä½¿ç”¨æ–¹å¼ã€‚


## 6. Ref

[^1]: ä»¥å‰æœ‰è¿‡å¥½å¥‡ğŸ¤”ä¸ºä»€ä¹ˆ Chatbox çš„ RAG æ•ˆæœåœ¨å¤æ‚åœºæ™¯ä¸‹çš„ RAG æ•ˆæœæ¯”å…¶ä»–çš„ chatbox ç±»äº§å“æ•ˆæœæ›´å¥½ï¼Œåé¢é˜…è¯»æºç ä¹‹åæ‰å‘ç°ï¼šchatbox é’ˆå¯¹äº `file` ç›¸å…³çš„å·¥å…·åšäº†ä¼˜åŒ–ï¼Œå¹¶ä¸”å› ä¸ºä¸ç”¨è€ƒè™‘æ—¶å»¶ç­‰é—®é¢˜ï¼Œå¾ˆå¤šå†³ç­–éƒ½é€šè¿‡ `LLM` å®Œæˆã€‚